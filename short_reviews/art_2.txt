void setup() {
  // put your setup code here, to run once:

}

void loop() {
  // put your main code here, to run repeatedly:

}Art is a diverse range of human activities in creating visual, auditory or 
performing artifacts , artworks, expressing the author's imaginative or 
technical skill, intended to be
appreciated for their beauty or emotional power.[1][2] In their most general 
form these activities include the production of works of art, the criticism of 
art, the study of the 
history of art, and the aesthetic dissemination of art.

The oldest form of art are visual arts, which include creation of images or 
objects in fields including painting, sculpture, printmaking, photography, and 
other visual media. 
Architecture is often included as one of the visual arts; however, like the 
decorative arts, it involves the creation of objects where the practical 
considerations of use are 
essential,in a way that they usually are not in a painting, for example. Music, 
theatre, film, dance, and other performing arts, as well as literature and 
other media such 
as interactive media, are included in a broader definition of art or the arts.[1]
[3] Until the 17th century, art referred to any skill or mastery and was not 
differentiated from 
crafts or sciences. In modern usage after the 17th century, where aesthetic 
considerations are paramount, the fine arts are separated and distinguished 
from acquired 
skills in general, such as the decorative or applied arts.

Art may be characterized in terms of mimesis (its representation of reality), 
expression, communication of emotion, or other qualities. During the 
Romantic period, art 
came to be seen as "a special faculty of the human mind to be classified 
with religion and science".[4] Though the definition of what constitutes art is 
disputed[5][6][7] and 
has changed over time, general descriptions mention an idea of imaginative 
or technical skill stemming from human agency[8] and creation.[9]

The nature of art, and related concepts such as creativity and interpretation, 
are explored in a branch of philosophy known as aesthetics.[10]

In the perspective of the history of art,[9] artistic works have existed for 
almost as long as humankind: from early pre historic art to contemporary art; 
however, some 
theories restrict the concept of "artistic works" to modern Western societies.
[11] One early sense of the definition of art is closely related to the older 
Latin meaning, which 
roughly translates to "skill" or "craft," as associated with words such as 
"artisan." English words derived from this meaning include artifact, artificial, 
artifice, medical arts, 
and military arts. However, there are many other colloquial uses of the word, 
all with some relation to its etymology.


20th century Rwandan bottle. Artistic works may serve practical functions, in 
addition to their decorative value.
Few modern scholars have been more divided than Plato and Aristotle on 
the question concerning the importance of art, with Aristotle strongly 
supporting art in general 
and Plato generally being opposed to its relative importance. Several 
dialogues in Plato tackle questions about art: Socrates says that poetry is 
inspired by the muses, and 
is not rational. He speaks approvingly of this, and other forms of divine 
madness (drunkenness, eroticism, and dreaming) in the Phaedrus (265a,c), 
and yet in the
Republic wants to outlaw Homer's great poetic art, and laughter as well. In 
Ion, Socrates gives no hint of the disapproval of Homer that he expresses in 
the Republic. The 
dialogue Ion suggests that Homer's Iliad functioned in the ancient Greek 
world as the Bible does today in the modern Christian world: as divinely 
inspired literary art that 
can provide moral guidance, if only it can be properly interpreted. With 
regards to the literary art and the musical arts, Aristotle considered epic 
poetry, tragedy, comedy, 
dithyrambic poetry and music to be mimetic or imitative art, each varying in 
imitation by medium, object, and manner.[12] For example, music imitates 
with the media of 
rhythm and harmony, whereas dance imitates with rhythm alone, and poetry 
with language. The forms also differ in their object of imitation. Comedy, for 
instance, is a 
dramatic imitation of men worse than average; whereas tragedy imitates men 
slightly better than average. Lastly, the forms differ in their manner of 
imitation , through
narrative or character, through change or no change, and through drama or 
no drama.[13] Aristotle believed that imitation is natural to mankind and 
constitutes one of 
mankind's advantages over animals.[14]

The second, and more recent, sense of the word art as an abbreviation for 
creative art or fine art emerged in the early 17th century.[15] Fine art refers 
to a skill used to 
express the artist's creativity, or to engage the audience's aesthetic 
sensibilities, or to draw the audience towards consideration of more refined 
or finer work of art.

Within this latter sense, the word art may refer to several things: (i) a study 
of a creative skill, (ii) a process of using the creative skill, (iii) a product of the 
creative skill, or 
(iv) the audience's experience with the creative skill. The creative arts (art as 
discipline) are a collection of disciplines which produce artworks (art as 
objects) that are 
compelled by a personal drive (art as activity) and convey a message, mood, 
or symbolism for the perceiver to interpret (art as experience). Art is 
something that 
stimulates an individual's thoughts, emotions, beliefs, or ideas through the 
senses. Works of art can be explicitly made for this purpose or interpreted 
on the basis of 
images or objects. For some scholars, such as Kant, the sciences and the 
arts could be distinguished by taking science as representing the domain of 
knowledge and the 
arts as representing the domain of the freedom of artistic expression.

Often, if the skill is being used in a common or practical way, people will 
consider it a craft instead of art. Likewise, if the skill is being used in a 
commercial or industrial 
way, it may be considered commercial art instead of fine art. On the other 
hand, crafts and design are sometimes considered applied art. Some art 
followers have argued 
that the difference between fine art and applied art has more to do with 
value judgments made about the art than any clear definitional difference.
[16] However, even fine 
art often has goals beyond pure creativity and self expression. The purpose 
of works of art may be to communicate ideas, such as in politically, 
spiritually, or 
philosophically motivated art; to create a sense of beauty (see aesthetics); to 
explore the nature of perception; for pleasure; or to generate strong 
emotions. The purpose 
may also be seemingly nonexistent.

The nature of art has been described by philosopher Richard Wollheim as 
"one of the most elusive of the traditional problems of human culture".[17] 
Art has been defined 
as a vehicle for the expression or communication of emotions and ideas, a 
means for exploring and appreciating formal elements for their own sake, 
and as mimesis or 
representation. Art as mimesis has deep roots in the philosophy of Aristotle.
[18] Leo Tolstoy identified art as a use of indirect means to communicate 
from one person to 
another.[18] Benedetto Croce and R.G. Collingwood advanced the idealist 
view that art expresses emotions, and that the work of art therefore 
essentially exists in the mind 
of the creator.[19][20] The theory of art as form has its roots in the 
philosophy of Immanuel Kant, and was developed in the early twentieth 
century by Roger Fry and Clive 
Bell. More recently, thinkers influenced by Martin Heidegger have interpreted 
art as the means by which a community develops for itself a medium for self 
expression and 
interpretation.[21] George Dickie has offered an institutional theory of art that 
defines a work of art as any artifact upon which a qualified person or 
persons acting on 
behalf of the social institution commonly referred to as "the art world" has 
conferred "the status of candidate for appreciation".[22] Larry Shiner has 
described fine art as 
"not an essence or a fate but something we have made. Art as we have 
generally understood it is a European invention barely two hundred years 
old. [23]
Sculptures, cave paintings, rock paintings and petroglyphs from the Upper 
Paleolithic dating to roughly 40,000 years ago have been found,[24] but the 
precise meaning of 
such art is often disputed because so little is known about the cultures that 
produced them. The oldest art objects in the world,a series of tiny, drilled 
snail shells about 
75,000 years old,were discovered in a South African cave.[25] Containers 
that may have been used to hold paints have been found dating as far back 
as 100,000 
years.[26] Etched shells by Homo erectus from 430,000 and 540,000 years 
ago were discovered in 2014.[27]


Cave painting of a horse from the Lascaux caves, circa 16,000 BP
Many great traditions in art have a foundation in the art of one of the great 
ancient civilizations: Ancient Egypt, Mesopotamia, Persia, India, China, 
Ancient Greece, Rome, 
as well as Inca, Maya, and Olmec. Each of these centers of early civilization 
developed a unique and characteristic style in its art. Because of the size 
and duration of 
these civilizations, more of their art works have survived and more of their 
influence has been transmitted to other cultures and later times. Some also 
have provided the 
first records of how artists worked. For example, this period of Greek art saw 
a veneration of the human physical form and the development of equivalent 
skills to show 
musculature, poise, beauty, and anatomically correct proportions.

In Byzantine and Medieval art of the Western Middle Ages, much art focused 
on the expression of subjects about Biblical and religious culture, and used 
styles that 
showed the higher glory of a heavenly world, such as the use of gold in the 
background of paintings, or glass in mosaics or windows, which also 
presented figures in 
idealized, patterned (flat) forms. Nevertheless, a classical realist tradition 
persisted in small Byzantine works, and realism steadily grew in the art of 
Catholic Europe.

Renaissance art had a greatly increased emphasis on the realistic depiction 
of the material world, and the place of humans in it, reflected in the 
corporeality of the human 
body, and development of a systematic method of graphical perspective to 
depict recession in a three dimensional picture space.


The stylized signature of Sultan Mahmud II of the Ottoman Empire was 
written in Islamic calligraphy. It reads Mahmud Khan son of Abdulhamid is 
forever victorious.

The Great Mosque of Kairouan in Tunisia, also called the Mosque of Uqba, 
is one of the finest, most significant and best preserved artistic and 
architectural examples of 
early great mosques. Dated in its present state from the 9th century, it is the 
ancestor and model of all the mosques in the western Islamic lands.[28]
In the east, Islamic art's rejection of iconography led to emphasis on 
geometric patterns, calligraphy, and architecture. Further east, religion 
dominated artistic styles and 
forms too. India and Tibet saw emphasis on painted sculptures and dance, 
while religious painting borrowed many conventions from sculpture and 
tended to bright 
contrasting colors with emphasis on outlines. China saw the flourishing of 
many art forms: jade carving, bronzework, pottery (including the stunning 
terracotta army of 
Emperor Qin), poetry, calligraphy, music, painting, drama, fiction, etc. 
Chinese styles vary greatly from era to era and each one is traditionally 
named after the ruling 
dynasty. So, for example, Tang dynasty paintings are monochromatic and 
sparse, emphasizing idealized landscapes, but Ming Dynasty paintings are 
busy and colorful, 
and focus on telling stories via setting and composition. Japan names its 
styles after imperial dynasties too, and also saw much interplay between the 
styles of calligraphy 
and painting. Woodblock printing became important in Japan after the 17th 
century.


Painting by Song dynasty artist Ma Lin, circa 1250. 24.8   25.2 cm
The western Age of Enlightenment in the 18th century saw artistic depictions 
of physical and rational certainties of the clockwork universe, as well as 
politically 
revolutionary visions of a post monarchist world, such as Blake's portrayal of 
Newton as a divine geometer, or David's propagandistic paintings. This led 
to Romantic 
rejections of this in favor of pictures of the emotional side and individuality of 
humans, exemplified in the novels of Goethe. The late 19th century then 
saw a host of artistic 
movements, such as academic art, Symbolism, impressionism and fauvism 
among others.

The history of twentieth century art is a narrative of endless possibilities and 
the search for new standards, each being torn down in succession by the 
next. Thus the 
parameters of Impressionism, Expressionism, Fauvism, Cubism, Dadaism, 
Surrealism, etc. cannot be maintained very much beyond the time of their 
invention. Increasing 
global interaction during this time saw an equivalent influence of other 
cultures into Western art. Thus, Japanese woodblock prints (themselves 
influenced by Western 
Renaissance draftsmanship) had an immense influence on Impressionism 
and subsequent development. Later, African sculptures were taken up by 
Picasso and to some 
extent by Matisse. Similarly, in the 19th and 20th centuries the West has had 
huge impacts on Eastern art with originally western ideas like Communism 
and Post 
Modernism exerting a powerful influence.

Modernism, the idealistic search for truth, gave way in the latter half of the 
20th century to a realization of its unattainability. Theodor W. Adorno said in 
1970, "It is now 
taken for granted that nothing which concerns art can be taken for granted 
any more: neither art itself, nor art in relationship to the whole, nor even the 
right of art to 
exist."[29] Relativism was accepted as an unavoidable truth, which led to the 
period of contemporary art and postmodern criticism, where cultures of the 
world and of 
history are seen as changing forms, which can be appreciated and drawn 
from only with skepticism and irony. Furthermore, the separation of cultures 
is increasingly 
blurred and some argue it is now more appropriate to think in terms of a 
global culture, rather than of regional ones.

Forms, genres, media, and styles
Main article: The arts

Detail of Leonardo da Vinci's Mona Lisa, showing the painting technique of 
sfumato
The creative arts are often divided into more specific categories, each related 
to its technique, or medium, such as decorative arts, plastic arts, performing 
arts, or 
literature. Unlike scientific fields, art is one of the few subjects that are 
academically organized according to technique. An artistic medium is the 
substance or material the 
artistic work is made from, and may also refer to the technique used. For 
example, paint is a medium used in painting, and paper is a medium used in 
drawing.

An art form is the specific shape, or quality an artistic expression takes. The 
media used often influence the form. For example, the form of a sculpture 
must exist in space 
in three dimensions, and respond to gravity. The constraints and limitations 
of a particular medium are thus called its formal qualities. To give another 
example, the formal 
qualities of painting are the canvas texture, color, and brush texture. The 
formal qualities of video games are non linearity, interactivity and virtual 
presence. The form of a 
particular work of art is determined by the formal qualities of the media, and 
is not related to the intentions of the artist or the reactions of the audience in 
any way 
whatsoever as these properties are related to content rather than form.[30]

A genre is a set of conventions and styles within a particular medium. For 
instance, well recognized genres in film are western, horror and romantic 
comedy. Genres in 
music include death metal and trip hop. Genres in painting include still life 
and pastoral landscape. A particular work of art may bend or combine 
genres but each genre 
has a recognizable group of conventions, clich s and tropes. (One note: the 
word genre has a second older meaning within painting; genre painting was 
a phrase used in 
the 17th to 19th centuries to refer specifically to paintings of scenes of 
everyday life and is still used in this way.)


The Great Wave off Kanagawa by Hokusai (Japanese, 1760,1849), colored 
woodcut print
The style of an artwork, artist, or movement is the distinctive method and 
form followed by the respective art. Any loose brushy, dripped or poured 
abstract painting is 
called expressionistic. Often a style is linked with a particular historical 
period, set of ideas, and particular artistic movement. So Jackson Pollock is 
called an Abstract 
Expressionist.

A particular style may have specific cultural meanings. For example, Roy 
Lichtenstein,a painter associated with the American Pop art movement of the 
1960s,was not a 
pointillist, despite his use of dots. Lichtenstein used evenly spaced Ben Day 
dots (the type used to reproduce color in comic strips) as a style to question 
the "high" art of 
painting with the "low" art of comics, thus commenting on class distinctions 
in culture. Pointillism, a technique in late Impressionism (1880s) developed 
especially by the 
artist Georges Seurat, employs dots to create variation in color and depth in 
an attempt to approximate the way people really see color. Both artists use 
dots, but the 
particular style and technique relate to the artistic movement adopted by 
each artist.

These are all ways of beginning to define a work of art, to narrow it down.

Imagine you are an art critic whose mission is to compare the meanings you 
find in a wide range of individual artworks. How would you proceed with your 
task  One way 
to begin is to examine the materials each artist selected in making an object, 
image video, or event. The decision to cast a sculpture in bronze, for 
instance, inevitably 
effects its meaning; the work becomes something different from how it might 
be if it had been cast in gold or plastic or chocolate, even if everything else 
about the artwork 
remains the same. Next, you might examine how the materials in each 
artwork have become an arrangement of shapes, colors, textures, and lines. 
These, in turn, are 
organized into various patterns and compositional structures. In your 
interpretation, you would comment on how salient features of the form 
contribute to the overall 
meaning of the finished artwork. [But in the end] the meaning of most 
artworks ... is not exhausted by a discussion of materials, techniques, and 
form. Most interpretations 
also include a discussion of the ideas and feelings the artwork engenders.
[31]

Skill and craft

Adam. Detail from Michelangelo's fresco in the Sistine Chapel (1511)
See also: Conceptual Art and Artistic Skill
Art can connote a sense of trained ability or mastery of a medium. Art can 
also simply refer to the developed and efficient use of a language to convey 
meaning with 
immediacy and or depth. Art is an act of expressing feelings, thoughts, and 
observations.[32] There is an understanding that is reached with the material 
as a result of 
handling it, which facilitates one's thought processes. A common view is that 
the epithet "art", particular in its elevated sense, requires a certain level of 
creative expertise 
by the artist, whether this be a demonstration of technical ability, an 
originality in stylistic approach, or a combination of these two. Traditionally 
skill of execution was 
viewed as a quality inseparable from art and thus necessary for its success; 
for Leonardo da Vinci, art, neither more nor less than his other endeavors, 
was a 
manifestation of skill. Rembrandt's work, now praised for its ephemeral 
virtues, was most admired by his contemporaries for its virtuosity. At the turn 
of the 20th century, 
the adroit performances of John Singer Sargent were alternately admired 
and viewed with skepticism for their manual fluency, yet at nearly the same 
time the artist who 
would become the era's most recognized and peripatetic iconoclast, Pablo 
Picasso, was completing a traditional academic training at which he 
excelled.

A common contemporary criticism of some modern art occurs along the lines 
of objecting to the apparent lack of skill or ability required in the production 
of the artistic 
object. In conceptual art, Marcel Duchamp's "Fountain" is among the first 
examples of pieces wherein the artist used found objects ("ready made") 
and exercised no 
traditionally recognised set of skills. Tracey Emin's My Bed, or Damien Hirst's 
The Physical Impossibility of Death in the Mind of Someone Living follow this 
example and 
also manipulate the mass media. Emin slept (and engaged in other 
activities) in her bed before placing the result in a gallery as work of art. Hirst 
came up with the 
conceptual design for the artwork but has left most of the eventual creation 
of many works to employed artisans. Hirst's celebrity is founded entirely on 
his ability to 
produce shocking concepts. The actual production in many conceptual and 
contemporary works of art is a matter of assembly of found objects. 
However, there are many 
modernist and contemporary artists who continue to excel in the skills of 
drawing and painting and in creating hands on works of art.

Purpose of art

A Navajo rug made circa 1880

Mozarabic Beatus miniature. Spain, late 10th century
Art has had a great number of different functions throughout its history, 
making its purpose difficult to abstract or quantify to any single concept. 
This does not imply that 
the purpose of Art is "vague", but that it has had many unique, different 
reasons for being created. Some of these functions of Art are provided in the 
following outline. The 
different purposes of art may be grouped according to those that are non 
motivated, and those that are motivated (L vi Strauss).

Non motivated functions of art
The non motivated purposes of art are those that are integral to being 
human, transcend the individual, or do not fulfill a specific external purpose. 
In this sense, Art, as 
creativity, is something humans must do by their very nature (i.e., no other 
species creates art), and is therefore beyond utility.

Basic human instinct for harmony, balance, rhythm. Art at this level is not an 
action or an object, but an internal appreciation of balance and harmony 
(beauty), and 
therefore an aspect of being human beyond utility.
"Imitation, then, is one instinct of our nature. Next, there is the instinct for 
'harmony' and rhythm, meters being manifestly sections of rhythm. Persons, 
therefore, starting 
with this natural gift developed by degrees their special aptitudes, till their 
rude improvisations gave birth to Poetry."  Aristotle[33]

Experience of the mysterious. Art provides a way to experience one's self in 
relation to the universe. This experience may often come unmotivated, as 
one appreciates art, 
music or poetry.
"The most beautiful thing we can experience is the mysterious. It is the 
source of all true art and science."  Albert Einstein[34]

Expression of the imagination. Art provides a means to express the 
imagination in non grammatic ways that are not tied to the formality of 
spoken or written language. 
Unlike words, which come in sequences and each of which have a definite 
meaning, art provides a range of forms, symbols and ideas with meanings 
that are malleable.
"Jupiter's eagle [as an example of art] is not, like logical (aesthetic) attributes 
of an object, the concept of the sublimity and majesty of creation, but rather 
something else ,
something that gives the imagination an incentive to spread its flight over a 
whole host of kindred representations that provoke more thought than 
admits of expression in a 
concept determined by words. They furnish an aesthetic idea, which serves 
the above rational idea as a substitute for logical presentation, but with the 
proper function, 
however, of animating the mind by opening out for it a prospect into a field of 
kindred representations stretching beyond its ken."  Immanuel Kant[35]

Ritualistic and symbolic functions. In many cultures, art is used in rituals, 
performances and dances as a decoration or symbol. While these often have 
no specific 
utilitarian (motivated) purpose, anthropologists know that they often serve a 
purpose at the level of meaning within a particular culture. This meaning is 
not furnished by 
any one individual, but is often the result of many generations of change, 
and of a cosmological relationship within the culture.
"Most scholars who deal with rock paintings or objects recovered from 
prehistoric contexts that cannot be explained in utilitarian terms and are thus 
categorized as 
decorative, ritual or symbolic, are aware of the trap posed by the term 'art'."  
Silva Tomaskova[36]

Motivated functions of art
Motivated purposes of art refer to intentional, conscious actions on the part 
of the artists or creator. These may be to bring about political change, to 
comment on an 
aspect of society, to convey a specific emotion or mood, to address personal 
psychology, to illustrate another discipline, to (with commercial arts) to sell a 
product, or 
simply as a form of communication.

Communication. Art, at its simplest, is a form of communication. As most 
forms of communication have an intent or goal directed toward another 
individual, this is a 
motivated purpose. Illustrative arts, such as scientific illustration, are a form 
of art as communication. Maps are another example. However, the content 
need not be 
scientific. Emotions, moods and feelings are also communicated through art.
"[Art is a set of] artefacts or images with symbolic meanings as a means of 
communication."  Steve Mithen[37]

Art as entertainment. Art may seek to bring about a particular emotion or 
mood, for the purpose of relaxing or entertaining the viewer. This is often the 
function of the art 
industries of Motion Pictures and Video Games.[citation needed]
The Avante Garde. Art for political change. One of the defining functions of 
early twentieth century art has been to use visual images to bring about 
political change. Art 
movements that had this goal,Dadaism, Surrealism, Russian constructivism, 
and Abstract Expressionism, among others,are collectively referred to as the 
avante garde 
arts.
"By contrast, the realistic attitude, inspired by positivism, from Saint Thomas 
Aquinas to Anatole France, clearly seems to me to be hostile to any 
intellectual or moral 
advancement. I loathe it, for it is made up of mediocrity, hate, and dull 
conceit. It is this attitude which today gives birth to these ridiculous books, 
these insulting plays. It 
constantly feeds on and derives strength from the newspapers and stultifies 
both science and art by assiduously flattering the lowest of tastes; clarity 
bordering on 
stupidity, a dog's life."  Andr  Breton (Surrealism)[38]

Art as a "free zone", removed from the action of the social censure. Unlike 
the avant garde movements, which wanted to erase cultural differences in 
order to produce 
new universal values, contemporary art has enhanced its tolerance towards 
cultural differences as well as its critical and liberating functions (social 
inquiry, activism, 
subversion, deconstruction ...), becoming a more open place for research 
and experimentation.[39]
Art for social inquiry, subversion and/or anarchy. While similar to art for 
political change, subversive or deconstructivist art may seek to question 
aspects of society 
without any specific political goal. In this case, the function of art may be 
simply to criticize some aspect of society.

Spray paint graffiti on a wall in Rome
Graffiti art and other types of street art are graphics and images that are 
spray painted or stencilled on publicly viewable walls, buildings, buses, 
trains, and bridges, 
usually without permission. Certain art forms, such as graffiti, may also be 
illegal when they break laws (in this case vandalism).
Art for social causes. Art can be used to raise awareness for a large variety 
of causes. A number of art activities were aimed at raising awareness of 
autism,[40][41][42] 
cancer,[43][44][45] human trafficking,[46][47] and a variety of other topics, 
such as ocean conservation,[48] human rights in Darfur,[49] murdered and 
missing Aboriginal 
women,[50] elder abuse,[51] and pollution.[52] Trashion, using trash to 
make fashion, practiced by artists such as Marina DeBris is one example of 
using art to raise 
awareness about pollution.
Art for psychological and healing purposes. Art is also used by art 
therapists, psychotherapists and clinical psychologists as art therapy. The 
Diagnostic Drawing Series, 
for example, is used to determine the personality and emotional functioning 
of a patient. The end product is not the principal goal in this case, but rather 
a process of 
healing, through creative acts, is sought. The resultant piece of artwork may 
also offer insight into the troubles experienced by the subject and may 
suggest suitable 
approaches to be used in more conventional forms of psychiatric therapy.
Art for propaganda, or commercialism. Art is often utilized as a form of 
propaganda, and thus can be used to subtly influence popular conceptions 
or mood. In a similar 
way, art that tries to sell a product also influences mood and emotion. In 
both cases, the purpose of art here is to subtly manipulate the viewer into a 
particular emotional or 
psychological response toward a particular idea or object.[53]
Art as a fitness indicator. It has been argued that the ability of the human 
brain by far exceeds what was needed for survival in the ancestral 
environment. One evolutionary 
psychology explanation for this is that the human brain and associated traits 
(such as artistic ability and creativity) are the human equivalent of the 
peacock's tail. The 
purpose of the male peacock's extravagant tail has been argued to be to 
attract females (see also Fisherian runaway and handicap principle). 
According to this theory 
superior execution of art was evolutionary important because it attracted 
mates.[54]
The functions of art described above are not mutually exclusive, as many of 
them may overlap. For example, art for the purpose of entertainment may 
also seek to sell a 
product, i.e. the movie or video game.

Public access

Versailles: Louis Le Vau opened up the interior court to create the expansive 
entrance cour d'honneur, later copied all over Europe.
Since ancient times, much of the finest art has represented a deliberate 
display of wealth or power, often achieved by using massive scale and 
expensive materials. Much 
art has been commissioned by rulers or religious establishments, with more 
modest versions only available to the most wealthy in society. Nevertheless, 
there have been 
many periods where art of very high quality was available, in terms of 
ownership, across large parts of society, above all in cheap media such as 
pottery, which persists in 
the ground, and perishable media such as textiles and wood. In many 
different cultures, the ceramics of indigenous peoples of the Americas are 
found in such a wide 
range of graves that they were clearly not restricted to a social elite, though 
other forms of art may have been. Reproductive methods such as moulds 
made mass 
production easier, and were used to bring high quality Ancient Roman 
pottery and Greek Tanagra figurines to a very wide market. Cylinder seals 
were both artistic and 
practical, and very widely used by what can be loosely called the middle 
class in the Ancient Near East. Once coins were widely used these also 
became an art form that 
reached the widest range of society. Another important innovation came in 
the 15th century in Europe, when printmaking began with small woodcuts, 
mostly religious, that 
were often very small and hand colored, and affordable even by peasants 
who glued them to the walls of their homes. Printed books were initially very 
expensive, but fell 
steadily in price until by the 19th century even the poorest could afford some 
with printed illustrations. Popular prints of many different sorts have 
decorated homes and 
other places for centuries.

Public buildings and monuments, secular and religious, by their nature 
normally address the whole of society, and visitors as viewers, and display to 
the general public has 
long been an important factor in their design. Egyptian temples are typical in 
that the most largest and most lavish decoration was placed on the parts 
that could be seen 
by the general public, rather than the areas seen only by the priests. Many 
areas of royal palaces, castles and the houses of the social elite were often 
generally 
accessible, and large parts of the art collections of such people could often 
be seen, either by anybody, or by those able to pay a small price, or those 
wearing the correct 
clothes, regardless of who they were, as at the Palace of Versailles, where 
the appropriate extra accessories (silver shoe buckles and a sword) could be 
hired from shops 
outside.

Special arrangements were made to allow the public to see many royal or 
private collections placed in galleries, as with the Orleans Collection mostly 
housed in a wing of 
the Palais Royal in Paris, which could be visited for most of the 18th century. 
In Italy the art tourism of the Grand Tour became a major industry from the 
Renaissance 
onwards, and governments and cities made efforts to make their key works 
accessible. The British Royal Collection remains distinct, but large donations 
such as the Old 
Royal Library were made from it to the British Museum, established in 1753. 
The Uffizi in Florence opened entirely as a gallery in 1765, though this 
function had been 
gradually taking the building over from the original civil servants' offices for a 
long time before. The building now occupied by the Prado in Madrid was 
built before the 
French Revolution for the public display of parts of the royal art collection, 
and similar royal galleries open to the public existed in Vienna, Munich and 
other capitals. The 
opening of the Mus e du Louvre during the French Revolution (in 1793) as a 
public museum for much of the former French royal collection certainly 
marked an important 
stage in the development of public access to art, transferring ownership to a 
republican state, but was a continuation of trends already well established.

Most modern public museums and art education programs for children in 
schools can be traced back to this impulse to have art available to everyone. 
Museums in the 
United States tend to be gifts from the very rich to the masses (The 
Metropolitan Museum of Art in New York City, for example, was created by 
John Taylor Johnston, a 
railroad executive whose personal art collection seeded the museum.) But 
despite all this, at least one of the important functions of art in the 21st 
century remains as a 
marker of wealth and social status.


Performance by Joseph Beuys, 1978: Everyone an artist , On the way to the 
libertarian form of the social organism
There have been attempts by artists to create art that can not be bought by 
the wealthy as a status object. One of the prime original motivators of much 
of the art of the late 
1960s and 1970s was to create art that could not be bought and sold. It is 
"necessary to present something more than mere objects"[55] said the major 
post war German 
artist Joseph Beuys. This time period saw the rise of such things as 
performance art, video art, and conceptual art. The idea was that if the 
artwork was a performance 
that would leave nothing behind, or was simply an idea, it could not be 
bought and sold. "Democratic precepts revolving around the idea that a work 
of art is a commodity 
impelled the aesthetic innovation which germinated in the mid 1960s and 
was reaped throughout the 1970s. Artists broadly identified under the 
heading of Conceptual art 
... substituting performance and publishing activities for engagement with 
both the material and materialistic concerns of painted or sculptural form ... 
[have] endeavored to 
undermine the art object qua object."[56]

In the decades since, these ideas have been somewhat lost as the art 
market has learned to sell limited edition DVDs of video works,[57] invitations 
to exclusive 
performance art pieces, and the objects left over from conceptual pieces. 
Many of these performances create works that are only understood by the 
elite who have been 
educated as to why an idea or video or piece of apparent garbage may be 
considered art. The marker of status becomes understanding the work 
instead of necessarily 
owning it, and the artwork remains an upper class activity. "With the 
widespread use of DVD recording technology in the early 2000s, artists, and 
the gallery system that 
derives its profits from the sale of artworks, gained an important means of 
controlling the sale of video and computer artworks in limited editions to 
collectors."[58]

Controversies

Th odore G ricault's Raft of the Medusa, circa 1820
Art has long been controversial, that is to say disliked by some viewers, for a 
wide variety of reasons, though most pre modern controversies are dimly 
recorded, or 
completely lost to a modern view. Iconoclasm is the destruction of art that is 
disliked for a variety of reasons, including religious ones. Aniconism is a 
general dislike of 
either all figurative images, or often just religious ones, and has been a 
thread in many major religions. It has been a crucial factor in the history of 
Islamic art, where 
depictions of Muhammad remain especially controversial. Much art has been 
disliked purely because it depicted or otherwise stood for unpopular rulers, 
parties or other 
groups. Artistic conventions have often been conservative and taken very 
seriously by art critics, though often much less so by a wider public. The 
iconographic content of 
art could cause controversy, as with late medieval depictions of the new 
motif of the Swoon of the Virgin in scenes of the Crucifixion of Jesus. The 
Last Judgment by 
Michelangelo was controversial for various reasons, including breaches of 
decorum through nudity and the Apollo like pose of Christ.

The content of much formal art through history was dictated by the patron or 
commissioner rather than just the artist, but with the advent of Romanticism, 
and econonomic 
changes in the production of art, the artists' vision became the usual 
determinant of the content of his art, increasing the incidence of 
controversies, though often reducing 
their significance. Strong incentives for perceived originality and publicity 
also encouraged artists to court controversy. Th odore G ricault's Raft of the 
Medusa (c. 1820), 
was in part a political commentary on a recent event.  douard Manet's Le D 
jeuner sur l'Herbe (1863), was considered scandalous not because of the 
nude woman, but 
because she is seated next to men fully dressed in the clothing of the time, 
rather than in robes of the antique world. John Singer Sargent's Madame 
Pierre Gautreau 
(Madam X) (1884), caused a controversy over the reddish pink used to color 
the woman's ear lobe, considered far too suggestive and supposedly ruining 
the high society 
model's reputation.

The gradual abandonment of naturalism and the depiction of realistic 
representations of the visual appearance of subjects in the 19th and 20th 
centuries led to a rolling 
controversy lasting for over a century. In the twentieth century, Pablo 
Picasso's Guernica (1937) used arresting cubist techniques and stark 
monochromatic oils, to depict 
the harrowing consequences of a contemporary bombing of a small, ancient 
Basque town. Leon Golub's Interrogation III (1981), depicts a female nude, 
hooded detainee 
strapped to a chair, her legs open to reveal her sexual organs, surrounded 
by two tormentors dressed in everyday clothing. Andres Serrano's Piss 
Christ (1989) is a 
photograph of a crucifix, sacred to the Christian religion and representing 
Christ's sacrifice and final suffering, submerged in a glass of the artist's own 
urine. The 
resulting uproar led to comments in the United States Senate about public 
funding of the arts.

Theory
Main article: Aesthetics
In the nineteenth century, artists were primarily concerned with ideas of truth 
and beauty. The aesthetic theorist John Ruskin, who championed what he 
saw as the 
naturalism of J. M. W. Turner, saw art's role as the communication by artifice 
of an essential truth that could only be found in nature.[59]

The definition and evaluation of art has become especially problematic since 
the 20th century. Richard Wollheim distinguishes three approaches to 
assessing the 
aesthetic value of art: the Realist, whereby aesthetic quality is an absolute 
value independent of any human view; the Objectivist, whereby it is also an 
absolute value, but is 
dependent on general human experience; and the Relativist position, 
whereby it is not an absolute value, but depends on, and varies with, the 
human experience of 
different humans.[60]

Arrival of Modernism

Composition II in Red, Blue, and Yellow (1930) by Piet Mondrian (Dutch, 
1872,1944)
The arrival of Modernism in the late nineteenth century lead to a radical 
break in the conception of the function of art,[61] and then again in the late 
twentieth century with 
the advent of postmodernism. Clement Greenberg's 1960 article "Modernist 
Painting" defines modern art as "the use of characteristic methods of a 
discipline to criticize 
the discipline itself".[62] Greenberg originally applied this idea to the 
Abstract Expressionist movement and used it as a way to understand and 
justify flat (non illusionistic) 
abstract painting:

Realistic, naturalistic art had dissembled the medium, using art to conceal 
art; modernism used art to call attention to art. The limitations that constitute 
the medium of 
painting,the flat surface, the shape of the support, the properties of the 
pigment,,were treated by the Old Masters as negative factors that could be 
acknowledged only 
implicitly or indirectly. Under Modernism these same limitations came to be 
regarded as positive factors, and were acknowledged openly.[62]

After Greenberg, several important art theorists emerged, such as Michael 
Fried, T. J. Clark, Rosalind Krauss, Linda Nochlin and Griselda Pollock 
among others. Though 
only originally intended as a way of understanding a specific set of artists, 
Greenberg's definition of modern art is important to many of the ideas of art 
within the various 
art movements of the 20th century and early 21st century.

Pop artists like Andy Warhol became both noteworthy and influential through 
work including and possibly critiquing popular culture, as well as the art 
world. Artists of the 
1980s, 1990s, and 2000s expanded this technique of self criticism beyond 
high art to all cultural image making, including fashion images, comics, 
billboards and 
pornography.

Duchamp once proposed that art is any activity of any kind  everything. 
However, the way that only certain activities are classified today as art is a 
social construction.
[63] There is evidence that there may be an element of truth to this. The 
Invention of Art: A Cultural History is an art history book which examines the 
construction of the 
modern system of the arts i.e. Fine Art. Shiner finds evidence that the older 
system of the arts before our modern system (fine art) held art to be any 
skilled human activity 
i.e. Ancient Greek society did not possess the term art but techne. Techne 
can be understood neither as art or craft, the reason being that the 
distinctions of art and craft 
are historical products that came later on in human history. Techne included 
painting, sculpting and music but also; cooking, medicine, horsemanship, 
geometry, 
carpentry, prophecy and farming etc.

New Criticism and the "Intentional Fallacy"
Following Duchamp during the first half of the twentieth century, a significant 
shift to general aesthetic theory took place which attempted to apply 
aesthetic theory between 
various forms of art, including the literary arts and the visual arts, to each 
other. This resulted in the rise of the New Criticism school and debate 
concerning the intentional 
fallacy. At issue was the question of whether the aesthetic intentions of the 
artist in creating the work of art, whatever its specific form, should be 
associated with the 
criticism and evaluation of the final product of the work of art, or, if the work 
of art should be evaluated on its own merits independent of the intentions of 
the artist.

In 1946, William K. Wimsatt and Monroe Beardsley published a classic and 
controversial New Critical essay entitled "The Intentional Fallacy", in which 
they argued 
strongly against the relevance of an author's intention, or "intended 
meaning" in the analysis of a literary work. For Wimsatt and Beardsley, the 
words on the page were all 
that mattered; importation of meanings from outside the text was considered 
irrelevant, and potentially distracting.

In another essay, "The Affective Fallacy," which served as a kind of sister 
essay to "The Intentional Fallacy" Wimsatt and Beardsley also discounted 
the reader's 
personal/emotional reaction to a literary work as a valid means of analyzing a 
text. This fallacy would later be repudiated by theorists from the reader 
response school of 
literary theory. Ironically, one of the leading theorists from this school, 
Stanley Fish, was himself trained by New Critics. Fish criticizes Wimsatt and 
Beardsley in his 
essay "Literature in the Reader" (1970).[64]

As summarized by Gaut and Livingston in their essay "The Creation of Art": 
"Structuralist and post structuralists theorists and critics were sharply critical 
of many aspects 
of New Criticism, beginning with the emphasis on aesthetic appreciation and 
the so called autonomy of art, but they reiterated the attack on biographical 
criticisms's 
assumption that the artist's activities and experience were a privileged critical 
topic."[65] These authors contend that: "Anti intentionalists, such as 
formalists, hold that the 
intentions involved in the making of art are irrelevant or peripheral to 
correctly interpreting art. So details of the act of creating a work, though 
possibly of interest in 
themselves, have no bearing on the correct interpretation of the work."[66]

Gaut and Livingston define the intentionalists as distinct from formalists 
stating that: "Intentionalists, unlike formalists, hold that reference to 
intentions is essential in fixing 
the correct interpretation of works." They quote Richard Wollheim as stating 
that, "The task of criticism is the reconstruction of the creative process, 
where the creative 
process must in turn be thought of as something not stopping short of, but 
terminating on, the work of art itself."[66]

"Linguistic turn" and its debate
The end of the 20th century fostered an extensive debate known as the 
linguistic turn controversy, or the "innocent eye debate", and generally 
referred to as the 
structuralism poststructuralism debate in the philosophy of art. This debate 
discussed the encounter of the work of art as being determined by the 
relative extent to which 
the conceptual encounter with the work of art dominates over the perceptual 
encounter with the work of art.[67] Decisive for the linguistic turn debate in 
art history and the 
humanities were the works of yet another tradition, namely the structuralism 
of Ferdinand de Saussure and the ensuing movement of poststructuralism. 
In 1981, the artist 
Mark Tansey created a work of art titled "The Innocent Eye" as a criticism of 
the prevailing climate of disagreement in the philosophy of art during the 
closing decades of 
the 20th century. Influential theorists include Judith Butler, Luce Irigaray, 
Julia Kristeva, Michel Foucault and Jacques Derrida. The power of 
language, more specifically 
of certain rhetorical tropes, in art history and historical discourse was 
explored by Hayden White. The fact that language is not a transparent 
medium of thought had been 
stressed by a very different form of philosophy of language which originated 
in the works of Johann Georg Hamann and Wilhelm von Humboldt.[68] 
Ernst Gombrich and 
Nelson Goodman in his book Languages of Art: An Approach to a Theory of 
Symbols came to hold that the conceptual encounter with the work of art 
predominated 
exclusively over the perceptual and visual encounter with the work of art 
during the 1960s and 1970s.[69] He was challenged on the basis of 
research done by the Nobel 
prize winning psychologist Roger Sperry who maintained that the human 
visual encounter was not limited to concepts represented in language alone 
(the linguistic turn) 
and that other forms of psychological representations of the work of art were 
equally defensible and demonstrable. Sperry's view eventually prevailed by 
the end of the 
20th century with aesthetic philosophers such as Nick Zangwill strongly 
defending a return to moderate aesthetic formalism among other 
alternatives.[70]

Classification disputes
Main article: Classificatory disputes about art

The original Fountain by Marcel Duchamp, 1917, photographed by Alfred 
Stieglitz at the 291 after the 1917 Society of Independent Artists exhibit. 
Stieglitz used a 
backdrop of The Warriors by Marsden Hartley to photograph the urinal. The 
exhibition entry tag can be clearly seen.[71]
Disputes as to whether or not to classify something as a work of art are 
referred to as classificatory disputes about art.

Classificatory disputes in the 20th century have included cubist and 
impressionist paintings, Duchamp's Fountain, the movies, superlative 
imitations of banknotes, 
conceptual art, and video games.[72]

Philosopher David Novitz has argued that disagreement about the definition 
of art are rarely the heart of the problem. Rather, "the passionate concerns 
and interests that 
humans vest in their social life" are "so much a part of all classificatory 
disputes about art" (Novitz, 1996). According to Novitz, classificatory 
disputes are more often 
disputes about societal values and where society is trying to go than they 
are about theory proper. For example, when the Daily Mail criticized Hirst's 
and Emin's work by 
arguing "For 1,000 years art has been one of our great civilising forces. 
Today, pickled sheep and soiled beds threaten to make barbarians of us all" 
they are not 
advancing a definition or theory about art, but questioning the value of 
Hirst's and Emin's work.[73] In 1998, Arthur Danto, suggested a thought 
experiment showing that 
"the status of an artifact as work of art results from the ideas a culture 
applies to it, rather than its inherent physical or perceptible qualities. 
Cultural interpretation (an art 
theory of some kind) is therefore constitutive of an object's arthood."[74][75]

Anti art is a label for art that intentionally challenges the established 
parameters and values of art;[76] it is term associated with Dadaism and 
attributed to Marcel Duchamp 
just before World War I,[76] when he was making art from found objects.[76] 
One of these, Fountain (1917), an ordinary urinal, has achieved 
considerable prominence 
and influence on art.[76] Anti art is a feature of work by Situationist 
International,[77] the lo fi Mail art movement, and the Young British Artists,
[76] though it is a form still 
rejected by the Stuckists,[76] who describe themselves as anti anti art.[78]
[79]

Value judgment

Aboriginal hollow log tombs. National Gallery, Canberra, Australia
Somewhat in relation to the above, the word art is also used to apply 
judgments of value, as in such expressions as "that meal was a work of art" 
(the cook is an artist), or 
"the art of deception", (the highly attained level of skill of the deceiver is 
praised). It is this use of the word as a measure of high quality and high 
value that gives the term 
its flavor of subjectivity.

Making judgments of value requires a basis for criticism. At the simplest 
level, a way to determine whether the impact of the object on the senses 
meets the criteria to be 
considered art is whether it is perceived to be attractive or repulsive. Though 
perception is always colored by experience, and is necessarily subjective, it 
is commonly 
understood that what is not somehow aesthetically satisfying cannot be art. 
However, "good" art is not always or even regularly aesthetically appealing 
to a majority of 
viewers. In other words, an artist's prime motivation need not be the pursuit 
of the aesthetic. Also, art often depicts terrible images made for social, 
moral, or thought 
provoking reasons. For example, Francisco Goya's painting depicting the 
Spanish shootings of 3rd of May 1808 is a graphic depiction of a firing squad 
executing several 
pleading civilians. Yet at the same time, the horrific imagery demonstrates 
Goya's keen artistic ability in composition and execution and produces fitting 
social and political 
outrage. Thus, the debate continues as to what mode of aesthetic 
satisfaction, if any, is required to define 'art'.

The assumption of new values or the rebellion against accepted notions of 
what is aesthetically superior need not occur concurrently with a complete 
abandonment of the 
pursuit of what is aesthetically appealing. Indeed, the reverse is often true, 
that the revision of what is popularly conceived of as being aesthetically 
appealing allows for a 
re invigoration of aesthetic sensibility, and a new appreciation for the 
standards of art itself. Countless schools have proposed their own ways to 
define quality, yet they all 
seem to agree in at least one point: once their aesthetic choices are 
accepted, the value of the work of art is determined by its capacity to 
transcend the limits of its 
chosen medium to strike some universal chord by the rarity of the skill of the 
artist or in its accurate reflection in what is termed the zeitgeist.

Art is often intended to appeal to and connect with human emotion. It can 
arouse aesthetic or moral feelings, and can be understood as a way of 
communicating these 
feelings. Artists express something so that their audience is aroused to some 
extent, but they do not have to do so consciously. Art may be considered an 
exploration of 
the human condition; that is, what it is to be human.[80]
An art movement is a tendency or style in art with a specific common 
philosophy or goal, followed by a group of artists during a restricted period 
of time, (usually a few 
months, years or decades) or, at least, with the heyday of the movement 
defined within a number of years. Art movements were especially important 
in modern art, when 
each consecutive movement was considered as a new avant garde.Concept
[edit]
According to theories associated with modernism and the concept of 
postmodernism, art movements are especially important during the period of 
time corresponding to 
modern art.[1] The period of time called "modern art" is posited to have 
changed approximately half way through the 20th century and art made 
afterward is generally 
called contemporary art. Postmodernism in visual art begins and functions 
as a parallel to late modernism[2] and refers to that period after the 
"modern" period called 
contemporary art.[3] The postmodern period began during late modernism 
(which is a contemporary continuation of modernism), and according to 
some theorists 
postmodernism ended in the 21st century.[4][5] During the period of time 
corresponding to "modern art" each consecutive movement was often 
considered a new avant 
garde.[4]

Also during the period of time referred to as "modern art" each movement 
was seen corresponding to a somewhat grandiose rethinking of all that came 
before it, 
concerning the visual arts. Generally there was a commonality of visual style 
linking the works and artists included in an art movement. Verbal expression 
and explanation 
of movements has come from the artists themselves, sometimes in the form 
of an art manifesto,[6][7] and sometimes from art critics and others who may 
explain their 
understanding of the meaning of the new art then being produced.

In the visual arts, many artists, theorists, art critics, art collectors, art dealers 
and others mindful of the unbroken continuation of modernism and the 
continuation of 
modern art even into the contemporary era, ascribe to and welcome new 
philosophies of art as they appear.[8][9] Postmodernist theorists posit that 
the idea of art 
movements are no longer as applicable, or no longer as discernible, as the 
notion of art movements had been before the postmodern era.[10][11] There 
are many theorists 
however who doubt as to whether or not such an era was actually a fact;[4] 
or just a passing fad.[5][12]

The term refers to tendencies in visual art, novel ideas and architecture, and 
sometimes literature. In music it is more common to speak about genres and 
styles instead. 
See also cultural movement, a term with a broader connotation.

As the names of many art movements use the  ism suffix (for example 
cubism and futurism), they are sometimes referred to as isms.

19th  and 20th century art movements[edit]
19th century[edit]

Jacques Louis David, The Coronation of Napoleon, (1806), Mus e du Louvre, 
History painting
 

Eug ne Delacroix, Liberty Leading the People 1830, Romanticism
 

Thomas Cole, The Course of Empire: The Savage State 1836, Hudson River 
School
 

Gustave Courbet, Stone Breakers, 1849, Realist School
 

Jean Baptiste Camille Corot, c. 1867, Ville d'Avray National Gallery of Art, 
Washington, DC, Barbizon School[13]
 

Claude Monet, Haystacks, (sunset), 1890 1891, Museum of Fine Arts, 
Boston, Impressionism
 

Vincent van Gogh, The Starry Night, 1889, Post Impressionism
 

Edvard Munch, 1893, early example of Expressionism
Academic, c. 16th century 20th century
Aesthetic Movement
American Barbizon school
American Impressionism
Amsterdam Impressionism
Art Nouveau, c. 1890 1910
Arts and Crafts Movement, founded 1860s
Barbizon school, c. 1830s 1870s
Biedermeier, c. 1815 1848
Cloisonnism, c. 1888 1900s (decade)
Danish Golden Age
Decadent movement
Divisionism, c. 1880s 1910s
D sseldorf School
Etching revival
Expressionism, c. 1890s 1930s
German Romanticism, c. 1790s 1850s
Gr nderzeit
Hague School, c. 1860s 1890s
Heidelberg School, c. 1880s 1900s (decade)
History painting, c. 15th century 20th century
Hoosier Group
Hudson River School, c. 1820s 1900s (decade)
Impressionism, c. 1860s 1920s
Incoherents, c. 1882 1890s
Jugendstil
Les Nabis, c. 1890s 1900s (decade)
Les Vingt
Luminism
Lyon School
Macchiaioli c. 1850s 1900s (decade)
Mir iskusstva, founded 1898
Modernism, c. 1860s ongoing
Naturalism
Nazarene, c. 1810s 1830
Neo Classicism, c. 1780s 1900s (decade)
Neo impressionism, c. 1880s 1910s
Norwegian romantic nationalism, c. 1840 1867
Norwich School, founded 1803
Orientalism
Peredvizhniki
Pointillism, c. 1880s 1910s
Pont Aven School, c. 1850s 1890s
Post Impressionism, c. 1880s 1900s (decade)
Pre Raphaelite Brotherhood
Realism, c. 1850s 1900s (decade)
Realism, c. 1850s 1900s (decade)
Romanticism, c. 1750s 1890s
Secession Groups, c. 1890s 1910s
Society of American Artists, c. 1877 1906
Spanish Eclecticism, c. 1845 1890s
Symbolism
Synthetism, c. 1877 1900s (decade)
Tonalism, c. 1880 1915
Vienna Secession, founded 1897
White Mountain art, c. 1820s 1870s
20th century[edit]
1900 1918[edit]

Wassily Kandinsky, 1903, Der Blaue Reiter 21.1 cm   54.6 cm (8.3 in   21.5 
in)
 

Pablo Picasso, Family of Saltimbanques, 1905, Picasso's Rose Period
 

Henri Matisse 1905, Fauvism
 

Pablo Picasso 1907, Proto Cubism
 

Georges Braque 1910, Analytic Cubism
 

Piet Mondrian, 1912, early De Stijl
 

Kazimir Malevich, (Supremus No. 58), Museum of Art, 1916, Suprematism
 

Marcel Duchamp, Fountain, 1917, photograph by Alfred Stieglitz, Dada
Academic, c. 1900s (decade) ongoing
American realism, c. 1890s 1920s
Analytic Cubism, c. 1909 1912
Art Deco, c. 1920s 1940s
Ashcan School, c. 1890s 1920s
Berliner Sezession, founded 1898
Bloomsbury Group, c. 1900s (decade) 1960s
Camden Town Group, c. 1911 1913
Constructivism, c. 1920 1922, 1920s 1940s
Cubism, c. 1906 1919
Cubo Futurism, c. 1912 1918
Czech Cubism, c. 1910 1914
Dada, c. 1916 1922
Der Blaue Reiter, c. 1911 1914
De Stijl, c. 1917 1931
Deutscher Werkbund, founded 1907
Die Br cke, founded 1905
Expressionism c. 1890s 1930s
Fauvism, c. 1900 1910
Futurism, c. 1909 1916
German Expressionism, c. 1913 1930
Group of Seven (Canada), c. 1913 1930s
Jack of Diamonds, founded 1909
Luminism (Impressionism), c. 1900s (decade) 1930s
Modernism, c. 1860s ongoing
Neo Classicism, c. 1900s (decade) ongoing
Neo primitivism, from 1913
Neue K nstlervereinigung M nchen
Novembergruppe, founded 1918
Objective Abstraction, c. 1933 1936
Orphism, c. 1910 1913
Photo Secession, founded c. 1902
Picasso's Blue Period, c. 1901 1904
Picasso's Rose Period, c. 1904 1906
Picasso's African Period, 1906 1909
Pittura Metafisica, c. 1911 1920
Proto Cubism, c. 1906 1908
Purism, c. 1917 1930s
Rayonism
Section d'Or, c. 1912 1914
Suprematism, formed c. 1915 1916
Synchromism, founded 1912
Synthetic Cubism, c. 1912 1919
The Eight, c. 1909 1918
The Ten, c. 1897 1920
Vorticism, founded 1914
1918 1945[edit]

Theo van Doesburg, Composition XX, 1920, De Stijl
 

Max Ernst, The Elephant Celebes (1921), Tate, Surrealism
 

Charles Demuth, I Saw the Figure 5 in Gold, 1928, Metropolitan Museum of 
Art, Precisionism
 

Grant Wood, American Gothic, 1930, Social Realism
American Scene painting, c. 1920s 1950s
Arbeitsrat f r Kunst
Art Deco
Bauhaus, c. 1919 1933
Concrete art
Der Ring
De Stijl, c. 1917 1931
Ecole de Paris
Geometric abstraction
Gruppo 7
International Style, c. 1920s 1970s
Kapists, c. 1930s
Magic Realism
Neo Romanticism
Neue Sachlichkeit
Novecento Italiano
Novembergruppe, founded 1918
Precisionism, c. 1918 1940s
Regionalism (art), c. 1930s 1940s
Return to order, 1918 1922
Scuola Romana, c. 1928 1945
Social Realism, c. 1920s 1960s
Socialist Realism
Surrealism, c. 1920s 1960s
1940 1965[edit]

Arshile Gorky, The Liver is the Cock's Comb (1944), oil on canvas, 731 4   
98" (186   249 cm) Albright Knox Art Gallery, Buffalo, New York. Gorky was 
an Armenian born 
American painter who had a seminal influence on Abstract Expressionism. 
De Kooning said: "I met a lot of artists , but then I met Gorky... He had an 
extraordinary gift 
for hitting the nail on the head; remarkable. So I immediately attached 
myself to him and we became very good friends."[14]
Abstract expressionism
Action painting
Arte Povera
Art Informel
Assemblage
Beatnik art
Chicago Imagists
CoBrA, c. 1948 1951
Color Field painting
Combine painting
De collage
Fluxus
Happening
Hard Edge Painting
Kinetic Art
Kitchen Sink School
Lettrism
Lyrical abstraction
Neo Dada
New Brutalism
Northwest School
Nouveau R alisme
Op Art
Organic abstraction
Outsider Art
Panic Movement
Pop Art
Post painterly abstraction
Public art
Retro art
Serial art
Shaped canvas
Situationist International
Tachism
Video art
1965 2000[edit]
Abstract Illusionism
Appropriation
Arte Povera
Art Photography
Body Art
Classical Realism
Conceptual Art
Dogme 95
Earth Art
Figuration Libre
Funk art
Graffiti art
Hyperrealism
Installation art
Internet Art
Land art
Late modernism
Light and Space
Lowbrow
Lyrical Abstraction
Massurrealism
Minimalism
Neo Expressionism
Neo figurative
Neo pop
Performance Art
Postminimalism
Postmodernism
Photorealism
Psychedelic art
Relational art
Site specific art
Sound Art
Steampunk
Transavanguardia
Young British Artists
21st century[edit]
Algorithmic art
Altermodernism
Computer art
Computer graphics
Digital art
Electronic Art
Environmental art
Excessivism
Intentism
Internet art
Intervention art
Maximalism
Metamodernism
Neo minimalism
New Media Art
Post postmodernism
Relational art
Remodernism
SoFlo Superflat
Stuckism International
Superflat
Superstroke
Transgressive art
Virtual art
See also[edit]
List of art movements
Post expressionism
20th century Western painting
Western art history
art periods
Modern art includes artistic work produced during the period extending 
roughly from the 1860s to the 1970s, and denotes the style and philosophy 
of the art produced 
during that era.[1] The term is usually associated with art in which the 
traditions of the past have been thrown aside in a spirit of experimentation.
[2] Modern artists 
experimented with new ways of seeing and with fresh ideas about the nature 
of materials and functions of art. A tendency away from the narrative, which 
was 
characteristic for the traditional arts, toward abstraction is characteristic of 
much modern art. More recent artistic production is often called 
contemporary art or 
postmodern art.

Modern art begins with the heritage of painters like Vincent van Gogh, Paul 
C zanne, Paul Gauguin, Georges Seurat and Henri de Toulouse  Lautrec all 
of whom were 
essential for the development of modern art. At the beginning of the 20th 
century Henri Matisse and several other young artists including the pre  
cubists Georges Braque, 
Andr  Derain, Raoul Dufy, Jean Metzinger and Maurice de Vlaminck 
revolutionized the Paris art world with "wild", multi  colored, expressive 
landscapes and figure 
paintings that the critics called Fauvism. Henri Matisse's two versions of The 
Dance signified a key point in his career and in the development of modern 
painting.[3] It 
reflected Matisse's incipient fascination with primitive art: the intense warm 
color of the figures against the cool blue  green background and the 
rhythmical succession of 
the dancing nudes convey the feelings of emotional liberation and 
hedonism.

Initially influenced by Toulouse  Lautrec, Gauguin and other late 19th 
century innovators, Pablo Picasso made his first cubist paintings based on C 
zanne's idea that all 
depiction of nature can be reduced to three solids: cube, sphere and cone. 
With the painting Les Demoiselles d'Avignon (1907), Picasso dramatically 
created a new and 
radical picture depicting a raw and primitive brothel scene with five 
prostitutes, violently painted women, reminiscent of African tribal masks and 
his own new Cubist 
inventions. Analytic cubism was jointly developed by Pablo Picasso and 
Georges Braque, exemplified by Violin and Candlestick, Paris, from about 
1908 through 1912. 
Analytic cubism, the first clear manifestation of cubism, was followed by 
Synthetic cubism, practiced by Braque, Picasso, Fernand L ger, Juan Gris, 
Albert Gleizes, 
Marcel Duchamp and several other artists into the 1920s. Synthetic cubism 
is characterized by the introduction of different textures, surfaces, collage 
elements, papier 
coll  and a large variety of merged subject matter.Roots in the 19th century
[edit]
Multi  colored portrait of a far eastern cortesan with elaborate hair 
ornamentation, colorful robelike garment, and a border depicting marshland 
waters and reeds.
Vincent van Gogh, Courtesan (after Eisen) (1887), Van Gogh Museum
Portrait of a tree with blossoms and with far eastern alphabet letters both in 
the portrait and along the left and right borders.
Vincent van Gogh, The Blooming Plumtree (after Hiroshige) (1887), Van 
Gogh Museum
Portrait of a man of a bearded man facing forward, holding his own hands in 
his lap; wearing a hat, blue coat, beige collared shirt and brown pants; 
sitting in front of a 
background with various tiles of far eastern and nature themed art.
Vincent van Gogh, Portrait of P re Tanguy (1887), Mus e Rodin
Although modern sculpture and architecture are reckoned to have emerged 
at the end of the 19th century, the beginnings of modern painting can be 
located earlier.[5] 
The date perhaps most commonly identified as marking the birth of modern 
art is 1863,[6] the year that  douard Manet showed his painting Le d jeuner 
sur l'herbe in the 
Salon des Refus s in Paris. Earlier dates have also been proposed, among 
them 1855 (the year Gustave Courbet exhibited The Artist's Studio) and 1784 
(the year 
Jacques  Louis David completed his painting The Oath of the Horatii).[6] In 
the words of art historian H. Harvard Arnason: "Each of these dates has 
significance for the 
development of modern art, but none categorically marks a completely new 
beginning .... A gradual metamorphosis took place in the course of a 
hundred years."[6]

The strands of thought that eventually led to modern art can be traced back 
to the Enlightenment, and even to the 17th century.[7] The important 
modern art critic Clement 
Greenberg, for instance, called Immanuel Kant "the first real Modernist" but 
also drew a distinction: "The Enlightenment criticized from the outside ... . 
Modernism 
criticizes from the inside."[8] The French Revolution of 1789 uprooted 
assumptions and institutions that had for centuries been accepted with little 
question and 
accustomed the public to vigorous political and social debate. This gave rise 
to what art historian Ernst Gombrich called a "self  consciousness that made 
people select the 
style of their building as one selects the pattern of a wallpaper."[9]

The pioneers of modern art were Romantics, Realists and Impressionists.[10] 
By the late 19th century, additional movements which were to be influential 
in modern art had 
begun to emerge: post  Impressionism as well as Symbolism.

Influences upon these movements were varied: from exposure to Eastern 
decorative arts, particularly Japanese printmaking, to the coloristic 
innovations of Turner and 
Delacroix, to a search for more realism in the depiction of common life, as 
found in the work of painters such as Jean  Fran ois Millet. The advocates of 
realism stood 
against the idealism of the tradition  bound academic art that enjoyed public 
and official favor.[11] The most successful painters of the day worked either 
through 
commissions or through large public exhibitions of their own work. There 
were official, government  sponsored painters' unions, while governments 
regularly held public 
exhibitions of new fine and decorative arts.

The Impressionists argued that people do not see objects but only the light 
which they reflect, and therefore painters should paint in natural light (en 
plein air) rather than 
in studios and should capture the effects of light in their work.[12] 
Impressionist artists formed a group, Soci t  Anonyme Coop rative des 
Artistes Peintres, Sculpteurs, 
Graveurs ("Association of Painters, Sculptors, and Engravers") which, 
despite internal tensions, mounted a series of independent exhibitions.[13] 
The style was adopted 
by artists in different nations, in preference to a "national" style. These 
factors established the view that it was a "movement". These 
traits,establishment of a working 
method integral to the art, establishment of a movement or visible active core 
of support, and international adoption,would be repeated by artistic 
movements in the Modern 
period in art.

Early 20th century[edit]

Pablo Picasso Les Demoiselles d'Avignon 1907, Museum of Modern Art, New 
York

Henri Matisse, The Dance I, 1909, Museum of Modern Art, New York
Among the movements which flowered in the first decade of the 20th century 
were Fauvism, Cubism, Expressionism, and Futurism.

During the years between 1910 and the end of World War I and after the 
heyday of cubism, several movements emerged in Paris. Giorgio de Chirico 
moved to Paris in 
July 1911, where he joined his brother Andrea (the poet and painter known 
as Alberto Savinio). Through his brother he met Pierre Laprade, a member of 
the jury at the 
Salon d'Automne where he exhibited three of his dreamlike works: Enigma of 
the Oracle, Enigma of an Afternoon and Self  Portrait. During 1913 he 
exhibited his work at 
the Salon des Ind pendants and Salon d  Automne, and his work was 
noticed by Pablo Picasso, Guillaume Apollinaire, and several others. His 
compelling and mysterious 
paintings are considered instrumental to the early beginnings of Surrealism. 
Song of Love (1914) is one of the most famous works by de Chirico and is an 
early example 
of the surrealist style, though it was painted ten years before the movement 
was "founded" by Andr  Breton in 1924.

World War I brought an end to this phase but indicated the beginning of a 
number of anti  art movements, such as Dada, including the work of Marcel 
Duchamp, and of 
Surrealism. Artist groups like de Stijl and Bauhaus developed new ideas 
about the interrelation of the arts, architecture, design, and art education.

Modern art was introduced to the United States with the Armory Show in 
1913 and through European artists who moved to the U.S. during World War 
I.

After World War II[edit]
It was only after World War II, however, that the U.S. became the focal point 
of new artistic movements.[14] The 1950s and 1960s saw the emergence of 
Abstract 
Expressionism, Color field painting, Pop art, Op art, Hard  edge painting, 
Minimal art, Lyrical Abstraction, Fluxus, Happening, Video art, 
Postminimalism, Photorealism and 
various other movements. In the late 1960s and the 1970s, Land art, 
Performance art, Conceptual art, and other new art forms had attracted the 
attention of curators and 
critics, at the expense of more traditional media.[15] Larger installations and 
performances became widespread.

By the end of the 1970s, when cultural critics began speaking of "the end of 
painting" (the title of a provocative essay written in 1981 by Douglas Crimp), 
new media art 
had become a category in itself, with a growing number of artists 
experimenting with technological means such as video art.[16] Painting 
assumed renewed importance in 
the 1980s and 1990s, as evidenced by the rise of neo  expressionism and 
the revival of figurative painting.[17]

Towards the end of the 20th century, a number of artists and architects 
started questioning the idea of "the modern" and created typically 
Postmodern works.[18]

Art movements and artist groups[edit]
(Roughly chronological with representative artists listed.)

19th century[edit]
Romanticism and the Romantic movement   Francisco de Goya, J. M. W. 
Turner, Eug ne Delacroix
Realism   Gustave Courbet, Camille Corot, Jean  Fran ois Millet, Rosa 
Bonheur
Impressionism   Fr d ric Bazille, Gustave Caillebotte, Mary Cassatt, Edgar 
Degas, Armand Guillaumin,  douard Manet, Claude Monet, Berthe Morisot, 
Pierre  Auguste 
Renoir, Camille Pissarro, Alfred Sisley
Post  impressionism   Georges Seurat, Paul C zanne, Paul Gauguin, Vincent 
van Gogh, Henri de Toulouse  Lautrec, Henri Rousseau, Henri  Jean 
Guillaume Martin, Albert 
Lebourg, Robert Antoine Pinchon
Symbolism   Gustave Moreau, Odilon Redon, Edvard Munch, James 
Whistler, James Ensor
Les Nabis   Pierre Bonnard,  douard Vuillard, F lix Vallotton, Maurice Denis, 
Paul Serusier
Art Nouveau and variants   Jugendstil, Modern Style, Modernisme   Aubrey 
Beardsley, Alphonse Mucha, Gustav Klimt,
Art Nouveau architecture and design   Antoni Gaud , Otto Wagner, Wiener 
Werkst tte, Josef Hoffmann, Adolf Loos, Koloman Moser
Divisionism   Jean Metzinger, Robert Delaunay, Paul Signac, Henri  Edmond 
Cross
Early Modernist sculptors   Aristide Maillol, Auguste Rodin
Early 20th century (before World War I)[edit]
Abstract art   Francis Picabia, Wassily Kandinsky, Franti ek Kupka, Robert 
Delaunay, L opold Survage, Piet Mondrian
Fauvism   Andr  Derain, Henri Matisse, Maurice de Vlaminck, Georges 
Braque
Expressionism and related   Die Br cke, Der Blaue Reiter    Ernst Ludwig 
Kirchner, Wassily Kandinsky, Franz Marc, Egon Schiele, Oskar Kokoschka, 
Emil Nolde, Axel 
T rneman, Karl Schmidt  Rottluff, Max Pechstein
Futurism   Giacomo Balla, Umberto Boccioni, Carlo Carr , Gino Severini, 
Natalia Goncharova, Mikhail Larionov
Cubism   Pablo Picasso, Georges Braque, Jean Metzinger, Albert Gleizes, 
Fernand L ger, Robert Delaunay, Henri Le Fauconnier, Marcel Duchamp, 
Jacques Villon, 
Francis Picabia, Juan Gris
Sculpture   Pablo Picasso, Henri Matisse, Constantin Br ncu i, Joseph 
Csaky, Alexander Archipenko, Raymond Duchamp  Villon, Jacques Lipchitz, 
Ossip Zadkine
Orphism   Robert Delaunay, Sonia Delaunay, Franti ek Kupka
Photography   Pictorialism, Straight photography
Suprematism   Kasimir Malevich, Alexander Rodchenko, El Lissitzky
Synchromism   Stanton MacDonald  Wright, Morgan Russell
Vorticism   Wyndham Lewis
Dada   Jean Arp, Marcel Duchamp, Max Ernst, Francis Picabia, Kurt 
Schwitters
World War I to World War II[edit]
Pittura Metafisica   Giorgio de Chirico, Carlo Carr , Giorgio Morandi
De Stijl   Theo van Doesburg, Piet Mondrian
Expressionism   Egon Schiele, Amedeo Modigliani, Chaim Soutine
New Objectivity   Max Beckmann, Otto Dix, George Grosz
Figurative painting   Henri Matisse, Pierre Bonnard
American Modernism   Stuart Davis, Arthur G. Dove, Marsden Hartley, 
Georgia O'Keeffe
Constructivism   Naum Gabo, Gustav Klutsis, L szl  Moholy  Nagy, El 
Lissitzky, Kasimir Malevich, Vadim Meller, Alexander Rodchenko, Vladimir 
Tatlin
Surrealism   Marc Chagall, Ren  Magritte, Jean Arp, Salvador Dal , Max 
Ernst, Giorgio de Chirico, Andr  Masson, Joan Mir 
Bauhaus   Wassily Kandinsky, Paul Klee, Josef Albers
Sculpture   Alexander Calder, Alberto Giacometti, Gaston Lachaise, Henry 
Moore, Pablo Picasso, Julio Gonzalez
Scottish Colourists   Francis Cadell, Samuel Peploe, Leslie Hunter, John 
Duncan Fergusson
Suprematism   Kazimir Malevich, Aleksandra Ekster, Olga Rozanova, 
Nadezhda Udaltsova, Ivan Kliun, Lyubov Popova, Nikolai Suetin, Nina Genke 
 Meller, Ivan Puni, 
Ksenia Boguslavskaya
Precisionism   Charles Sheeler, Charles Demuth
After World War II[edit]
Figuratifs   Bernard Buffet, Jean Carzou, Maurice Boitel, Daniel du 
Janerand, Claude  Max Lochu
Sculpture   Henry Moore, David Smith, Tony Smith, Alexander Calder, Isamu 
Noguchi,[19] Alberto Giacometti, Sir Anthony Caro, Jean Dubuffet, Isaac 
Witkin, Ren  Ich , 
Marino Marini, Louise Nevelson, Albert Vrana
Abstract expressionism   Willem de Kooning, Jackson Pollock, Hans 
Hofmann, Franz Kline, Robert Motherwell, Clyfford Still, Lee Krasner, Joan 
Mitchell
American Abstract Artists   Ilya Bolotowsky, Ibram Lassaw, Ad Reinhardt, 
Josef Albers, Burgoyne Diller
Art Brut   Adolf W lfli, August Natterer, Ferdinand Cheval, Madge Gill, Paul 
Salvator Goldengreen
Arte Povera   Jannis Kounellis, Luciano Fabro, Mario Merz, Piero Manzoni, 
Alighiero Boetti
Color field painting   Barnett Newman, Mark Rothko, Adolph Gottlieb, Sam 
Francis, Morris Louis, Kenneth Noland, Jules Olitski, Helen Frankenthaler
Tachisme   Jean Dubuffet, Pierre Soulages, Hans Hartung, Ludwig Merwart
COBRA   Pierre Alechinsky, Karel Appel, Asger Jorn
De  collage   Wolf Vostell, Mimmo Rotella
Neo  Dada   Robert Rauschenberg, Jasper Johns, John Chamberlain, 
Joseph Beuys, Lee Bontecou, Edward Kienholz
Figurative Expressionism    Larry Rivers, Grace Hartigan, Elaine de Kooning, 
Robert De Niro, Sr., Lester Johnson, George McNeil, Earle M. Pilgrim, Jan M 
ller, Robert 
Beauchamp, Bob Thompson
Fluxus   George Maciunas, Joseph Beuys, Wolf Vostell, Nam June Paik, 
Daniel Spoerri, Dieter Roth, Carolee Schneeman, Alison Knowles, Charlotte 
Moorman, Dick 
Higgins
Happening   Allan Kaprow, Joseph Beuys, Wolf Vostell, Claes Oldenburg, 
Jim Dine, Red Grooms, Nam June Paik, Charlotte Moorman, Robert 
Whitman, Yoko Ono
Dau  al  Set   founded in Barcelona by poet/artist Joan Brossa,   Antoni T 
pies
Grupo El Paso   founded in Madrid by artists Antonio Saura, Pablo Serrano
Geometric abstraction   Wassily Kandinsky, Kazimir Malevich, Nadir Afonso, 
Manlio Rho, Mario Radice, Mino Argento
Hard  edge painting   John McLaughlin, Ellsworth Kelly, Frank Stella, Al 
Held, Ronald Davis
Kinetic art   George Rickey, Getulio Alviani
Land art   Christo, Richard Long, Robert Smithson, Michael Heizer
Les Automatistes   Claude Gauvreau, Jean  Paul Riopelle, Pierre Gauvreau, 
Fernand Leduc, Jean  Paul Mousseau, Marcelle Ferron
Minimal art   Sol LeWitt, Donald Judd, Dan Flavin, Richard Serra, Agnes 
Martin
Postminimalism   Eva Hesse, Bruce Nauman, Lynda Benglis
Lyrical abstraction   Ronnie Landfield, Sam Gilliam, Larry Zox, Dan 
Christensen, Natvar Bhavsar, Larry Poons
Neo  figurative art   Fernando Botero, Antonio Berni
Neo  expressionism   Georg Baselitz, Anselm Kiefer, J rg Immendorff, Jean  
Michel Basquiat
Transavanguardia   Francesco Clemente, Mimmo Paladino, Sandro Chia, 
Enzo Cucchi
Figuration libre   Herv  Di Rosa, Fran ois Boisrond, Robert Combas
New realism   Yves Klein, Pierre Restany, Arman
Op art   Victor Vasarely, Bridget Riley, Richard Anuszkiewicz, Jeffrey Steele
Outsider art   Howard Finster, Grandma Moses, Bob Justin
Photorealism   Audrey Flack, Chuck Close, Duane Hanson, Richard Estes, 
Malcolm Morley
Pop art   Richard Hamilton, Robert Indiana, Jasper Johns, Roy Lichtenstein, 
Robert Rauschenberg, Andy Warhol, Ed Ruscha, David Hockney
Postwar European figurative painting   Lucian Freud, Francis Bacon, Frank 
Auerbach, Gerhard Richter
New European Painting   Luc Tuymans, Marlene Dumas, Neo Rauch, 
Bracha Ettinger, Micha l Borremans, Chris Ofili
Shaped canvas   Frank Stella, Kenneth Noland, Ron Davis, Robert Mangold.
Soviet art   Aleksandr Deyneka, Aleksandr Gerasimov, Ilya Kabakov, Komar & 
Melamid, Alexandr Zhdanov, Leonid Sokov
Spatialism   Lucio Fontana
Video art   Nam June Paik, Wolf Vostell, Joseph Beuys, Bill Viola
Visionary art   Ernst Fuchs, Paul Laffoley, Michael BowenThe history of art is 
the history of any activity or product made by humans in a visual form for 
aesthetical or communicative purposes, expressing ideas, emotions or, in 
general, a worldview. Over time visual art has been classified in diverse 
ways, from the medieval distinction between liberal arts and mechanical arts, 
to the modern distinction between fine arts and applied arts, or to the many 
contemporary definitions, which define art as a manifestation of human 
creativity. The subsequent expansion of the list of principal arts in the 20th 
century reached to nine: architecture, dance, sculpture, music, painting, 
poetry (described broadly as a form of literature with aesthetic purpose or 
function, which also includes the distinct genres of theatre and narrative), 
film, photography and graphic arts. In addition to the old forms of artistic 
expression such as fashion and gastronomy, new modes of expression are 
being considered as arts such as video, computer art, performance, 
advertising, animation, television and videogames.

The history of art is a multidisciplinary branch of the arts and sciences, 
seeking an objective examination of art throughout time, classifying cultures, 
establishing periodizations, and observing the distinctive and influential 
characteristics of art.[1] The study of the history of art was initially developed 
during the Renaissance, with its limited scope being the artistic production of 
Western civilization. However, as time has passed, it has imposed a broader 
view of artistic history, seeking a comprehensive overview of all the 
civilizations and analysis of their artistic production in terms of their own 
cultural values (cultural relativism), and not just western art history.

Today, art enjoys a wide network of study, dissemination and preservation of 
all the artistic legacy of mankind throughout history. The 20th century has 
seen the proliferation of institutions, foundations, art museums and galleries, 
in both the public and private sectors, dedicated to the analysis and 
cataloging of works of art as well as exhibitions aimed at a mainstream 
audience. The rise of media has been crucial in improving the study and 
dissemination of art. International events and exhibitions like the Whitney 
Biennial and biennales of Venice and S o Paulo or the Documenta of Kassel 
have helped the development of new styles and trends. Prizes such as the 
Turner of the Tate Gallery, the Wolf Prize in Arts, the Pritzker Prize of 
architecture, the Pulitzer of photography and the Oscar of cinema also 
promote the best creative work on an international level. Institutions like 
UNESCO, with the establishment of the World Heritage Site lists, also help 
the conservation of the major monuments of the planet.[2]Historical 
development[edit]

The Sakyamuni Buddha, by Zhang Shengwen, c. 1173   1176 CE, Chinese 
Song Dynasty period
Main article: Art history   Historical development
The field of "art history" was developed in the West, and originally dealt 
exclusively with European art history, with the High Renaissance (and its 
Greek precedent) as the defining standard. Gradually, over the course of the 
20th century, a wider vision of art history has developed. This expanded 
version includes societies from across the globe, and it usually attempts to 
analyze artifacts in terms of the cultural values in which they were created. 
Thus, art history is now seen to encompass all visual art, from the megaliths 
of Western Europe to the paintings of the Tang Dynasty in China.

The history of art is often told as a chronology of masterpieces created in 
each civilization. It can thus be framed as a story of high culture, epitomized 
by the Wonders of the World. On the other hand, vernacular art expressions 
can also be integrated into art historical narratives, in which case they are 
usually referred to as folk arts or craft. The more closely that an art historian 
engages with these latter forms of low culture, the more likely it is that they 
will identify their work as examining visual culture or material culture, or as 
contributing to fields related to art history, such as anthropology or 
archeology. In the latter cases art objects may be referred to as 
archeological artifacts.

Prehistory and ancient history background[edit]
A useful way to examine how art history is organized is through the major 
survey textbooks, which reflect an encyclopedic view of great art. Frequently 
consulted textbooks published in English are Ernst Gombrich  s Story of Art, 
Marilyn Stokstad  s Art History, Anthony Janson  s History of Art, David 
Wilkins, Bernard Schultz, and Katheryn M. Linduff  s Art Past, Art Present, 
Helen Gardner  s Art Through the Ages, Hugh Honour and John Flemming  
s A World History of Art, and Laurie Schneider Adams  s Art Across Time. 
One of the best places to find information on canonical art history is the 
Heilbrunn Timeline of Art History, sponsored by the Metropolitan Museum of 
Art in New York.


Ludovisi Battle sarcophagus (250,260 CE), with battle between Roman 
soldiers and barbarians. The general may be Hostilian, Emperor Decius' son 
(died 252 CE).
Global Prehistory[edit]

Venus of Willendorf, Naturhistorisches Museum
Main article: Prehistoric art
The first tangible artifacts of human art are found from the Stone Age (Upper 
Paleolithic, Mesolithic and Neolithic), periods when the first demonstrations 
that can be considered art by humans, appear. During the Paleolithic (25000 
 8000 BCE), man practiced hunting and lived in caves, where cave painting 
was developed.[3] After a transitional period (Mesolithic, 8000 6000 BCE), in 
the Neolithic period (6000 3000 BCE), when man became sedentary and 
engaged in agriculture, with societies becoming increasingly complex and 
religion gaining importance, the production of handicrafts commenced. 
Finally, in the Bronze Age (c. 3000   1000 BCE), the first protohistoric 
civilizations arise.

Paleolithic[edit]
Main articles: Paleolithic art and List of Stone Age art
The Paleolithic had its first artistic manifestation on 25,000 BCE, reaching its 
peak in the Magdalenian period ( 15,000  8000 BCE). The first traces of man  
made objects appear in southern Africa, the Western Mediterranean, Central 
and Eastern Europe (Adriatic Sea), Siberia (Baikal Lake), India and Australia. 
These first traces are generally worked stone (flint, obsidian), wood or bone 
tools. To paint in red, iron oxide was used, in black, manganese oxide and in 
ochre, clay.[4] Surviving art from this period is small carvings in stone or 
bone and cave painting, this especially from in the Franco  Cantabrian 
region; there are pictures with magical  religious character and also pictures 
with a naturalistic sense, which depict animals, notably the caves of 
Altamira, Trois Fr res, Chauvet and Lascaux. Sculpture is represented by the 
so  called Venus figurines, feminine figures which were probably used in 
fertility cults, such as the Venus of Willendorf.[5] Other representative works 
of this period are the Man from Brno[6] and the Venus of Brassempouy.[7]

Neolithic[edit]
Main article: Neolithic

Cave painting at Roca dels Moros, in El Cogul
This period from c. 8000 BCE in the Near East was a profound change for 
the ancient man, who became sedentary and engaged in agriculture and 
animal husbandry, new forms of social coexistence and religion developed.
[8] The rock art of the Iberian Mediterranean Basin dated between Mesolithic 
and Neolithic contained small, schematic human and figures, with notable 
examples in El Cogul, Valltorta, Alpera and Minateda. This kind of painting 
was also similar in northern Africa (Atlas, Sahara) and in the area of modern 
Zimbabwe. Neolithic painting was schematic, reduced to basic strokes (man 
in the form of a cross and woman in a triangular shape). There are equally 
noteworthy cave paintings in Pinturas River in Argentina, especially the 
Cueva de las Manos. In portable art, the Cardium Pottery was produced, 
decorated with imprints of seashells. New materials were produced like 
amber, crystal of rock, quartz, jasper, etc. In this period there appear the first 
traces of urbanistic planimetry, noting the remains in Tell as  Sultan 
(Jericho), Jarmo (Iraq) and  atalh y k (Anatolia).[9]

Metal Age[edit]

Megalithic complex of Stonehenge
The last prehistoric phase is the Metal Age, as the use of elements such as 
copper, bronze and iron proved to be a great material transformation for 
these ancient societies. In the Chalcolithic (also called Copper Age) the 
Megalith emerged, monuments of stone, i.e. the dolmen and menhir or the 
English cromlech, as in the complexes at Newgrange and Stonehenge.[8] In 
Spain the Los Millares culture was formed, characterized by the Beaker 
culture and pictured human figures with big eyes. In Malta, noteworthy are 
the temple complexes of  a ar Qim, Mnajdra, Tarxien and  gantija. In the 
Balearic Islands notable megalithic cultures developed, with different types 
of monuments: the naveta, a tomb shaped like a truncated pyramid, with an 
elongated burial chamber; the taula, two large stones, one put vertically and 
the other horizontally above each other; and the talaiot, a tower with a 
covered chamber and a false dome.[10]

In the Iron Age the cultures of Hallstatt (Austria) and La Tene (Switzerland) 
mark the significant phases in Europe. The first was developed between the 
7th and 5th century BCE by the necropoleis with tumular tombs and a 
wooden burial chamber in the form of a house, often accompanied by a four  
wheel cart. The pottery was polychromic, with geometric decorations and 
applications of metallic ornaments. La Tene was developed between the 5th 
and 4th century BCE, and is more popularly known as early Celtic art. It 
produced many iron objects such as swords and spears, which have not 
survived well, but bronze continued to be used for highly decorated shields, 
fibulas, and other objects, with different stages of evolution of the style (La 
Tene I, II and III). Decoration was influenced by Greek, Etruscan and 
Scythian art.[11] In most of the continent conquest by the Roman Empire 
brought the style to an end.


Venus of Brassempouy, Mus e des Antiquit s Nationales, Saint  Germain  en  
Laye
 

Menhir in the region of Brittany (France)
 

Circular talaiot in the island of Mallorca (Spain)
 

Solar cart of Trundholm (Denmark)
Ancient Mediterranean Art[edit]

Splint on Flood myth, of the Epic of Gilgamesh
Main article: Ancient art
Art, in the first period of history, began with the invention of writing, founded 
by the great civilizations of Near East: Egypt and Mesopotamia. This period 
also differed from others because artistic manifestations occurred in every 
culture of all the continents. In this period appear the first great cities in the 
main big rivers: Nile, Tigris and Euphrates, Indus and Yellow River.

One of the great advances of this period was writing, generated primarily by 
the need to keep records of economical and commercial nature. The first 
writing code was the cuneiform script, which emerged in Mesopotamia c. 
3500 BCE, written on clay tablets. It was based on pictographic and 
ideographic elements, while later Sumerians developed syllables for writing, 
reflecting the phonology and syntax of the Sumerian language. In Egypt 
hieroglyphic writing was developed, with the first sample being the Narmer 
Palette (3100 BCE). The Hebrew language was one of the first languages to 
utilize the method of writing with an alphabet (Abjad, c. 1800 BCE), which 
relates a unique symbol for each phoneme; the Greek and the Latin 
alphabet derive from it.[12]

Mesopotamia[edit]
Main article: Mesopotamian art

Diorite Statue I, patesi of Lagash (2120 BCE), Louvre Museum, Paris
Mesopotamian art was developed in the area between Tigris and Euphrates 
(modern day Syria and Iraq), where from the 4th millennium BCE many 
different cultures existed such as Sumer, Akkad, Amorite, Chaldea, etc. 
Mesopotamian architecture was characterized by the use of brick, lintel and 
the introduction of construction elements like arc and vault. Notable are the 
ziggurats, large temples with the form of a terraced step pyramid, from 
which we have practically no traces left except their bases. The tomb was 
usually a corridor, with a covered chamber and a false dome, as in some 
examples found in Ur. There were also palaces walled with a terrace in the 
form of a ziggurat, giving great importance to gardens (the Hanging Gardens 
of Babylon is one of the Seven Wonders of the Ancient World).

Sculpture was developed through wood carving and relief and was used in 
religious, military and hunting scenes, depicting both human and animal 
figures, whether they were real or mythological. In the Sumerian period there 
were small statues of angular form, with colored stone, bald head and with 
hands on the chest. In the Akkadian period there were figures with long hair 
and beard, noting the stele of Naram  Sin. In the Amorite period (or 
Neosumerian) notable is the representation of king Gudea of Lagash, with 
his mantle and a turban on his head and his hands on the chest. During 
Babylonian rule famous is the stele of Hammurabi. Assyrian sculpture is 
notable for its anthropomorphism of cattle and the winged genie, which is 
seen flying in many reliefs depicting war and hunting scenes, as in the Black 
Obelisk of Shalmaneser III.[13]

With the advent of writing, arose literature as a means of expressing human 
creativity. The Sumerian literature is represented by the Epic of Gilgamesh, 
written in the 17th century BCE. In it were written thirty myths about the 
most important Sumerian and Akkadian deities, which are: Innanas descent 
to hell and the cycle of gods Enki and Tammuz. Another example of 
relevance is the poem Lugal ud melambi Nirpal (The hardship of Ninurta), 
whose content type is moral and didactic. During Akkadian period notable is 
Atrahasis, which includes the flood myth. In Babylonian literature notable is 
the poem En ma Eli , which describes the creation of the world.[14]

The music was developed in this region between 4th and 3rd millennium 
BCE, used in Sumerian temples, where priests sang hymns and psalms 
(ersemma) to the gods. The liturgic chant was composed of responsories 
song alternated between the priests and choir and antiphons song 
alternated between two choirs. They had several instruments like tigi (flute), 
balag (drum), lilis (predecessor of timpani), algar (lyre), zagsal (harp) and 
adapa (pandeiro).[15]

Egypt[edit]
Main article: Ancient Egyptian art

The pyramids of Giza
In Egypt arose one of the first great civilizations, with elaborate and complex 
works of art, which assume the professional specialization of the 
artist/craftsman. Its art was intensely religious and symbolic, with a highly 
centralized power structure and hierarchy, giving great importance to the 
religious concept of immortality, especially of the pharaoh, for whom were 
built great monuments. The Egyptian art spans from 3,000 BCE until the 
conquest of Egypt by Alexander the Great. However its influence persisted in 
the Coptic art and Byzantine art.

The architecture is characterized by its monumentality, achieved by the use 
of stones in large blocks, lintel and solid columns. Notable are the funerary 
monuments, with three main types: mastaba, tomb of rectangular form; 
pyramid, which can be a step pyramid (Saqqarah) or smooth sided (Giza); 
and the hypogeum, underground tomb (Valley of the Kings). The other great 
building is the temple, a monumental complex preceded by an avenue of 
sphinxes and obelisks, which give way to two pylons and trapezoid walls, a 
hypaethros, a hypostyle hall and a shrine. Notable are the temples of 
Karnak, Luxor, Philae and Edfu. Another type of temple is the rock temple, 
which has the form of a hypogeum, like in Abu Simbel and Deir el  Bahari.

Painting was characterized by the juxtaposition of overlapping planes. The 
images were represented hierarchically, i.e., the Pharaoh is larger than the 
subjects or enemies at his side. Egyptians painted the head and limbs in 
profile, while the shoulders and eyes in front. Applied arts were developed 
significantly in Egypt, in particular woodwork and metalwork, with superb 
examples like cedar furniture inlaid with ebony and ivory of the tombs at the 
Egyptian Museum, or the pieces found in Tutankhamun's tomb, which are of 
great artistic quality.[16]


Aurochs on a cave painting in Lascaux, France
Greece and Etruria[edit]
Greek and Etruscan artists built on the artistic foundations of Egypt, further 
developing the arts of sculpture, painting, architecture, and ceramics. The 
body became represented in a more representational manner, and 
patronage of art thrived, at this time.

Rome[edit]
Roman art is sometimes viewed as derived from Greek precedents, but also 
has its own distinguishing features. Roman sculpture is often less idealized 
than the Greek precedents. Roman architecture often used concrete, and 
the round arch and dome was invented at this time.

The encyclopedic view of the history of art[edit]
Although some of the books listed above attempt a global approach, they 
are universally strong in western art history. The books use representative 
examples from each era in order to create a story that blends changing 
styles with social history. The Western narrative begins with prehistoric art 
such as Stonehenge, before discussing the ancient world. The latter begins 
with Mesopotamia, then progresses to the art of Ancient Egypt, which then 
transitions to Classical antiquity. Classical art includes both Greek and 
Roman work.

Europe[edit]
This encyclopedia view of the history of art begins with a section on the 
European context in chronological sequence.

Medieval[edit]

The interior of the Hagia Sophia in Istanbul, Turkey
With the decline of the Roman Empire, the narrative shifts to Medieval art, 
which lasted for a millennium. Early Christian art begins the period, followed 
by Byzantine art, Anglo  Saxon art, Viking art, Ottonian art, Romanesque art 
and Gothic art, with Islamic art dominating the eastern Mediterranean and 
beyond. The Medieval era ended with the Renaissance, followed by 
Mannerism, the Baroque and Rococo. In Byzantine and Gothic art of the 
Middle Ages, the dominance of the church insisted on the expression of 
biblical truths. There was no need to depict the reality of the material world, 
in which man was born in a "state of sin", especially through the extensive 
use of gold in paintings, which also presented figures in idealised, patterned 
(i.e."flat") forms.

Renaissance and Baroque[edit]
The Renaissance is the return yet again to valuation of the material world, 
and this paradigm shift is reflected in art forms, which show the corporeality 
of the human body, and the three  dimensional reality of landscape. 
Although textbooks periodize Western art by movements, as described 
above, they also do so by century, especially in Italian art. Many art 
historians give a nod to the historical importance of Italian Renaissance and 
Baroque art by referring to centuries in which it was prominent with the 
Italian terms: trecento for the fourteenth century, quattrocento for the 
fifteenth, cinquecento for the sixteenth, seicento for the seventeenth, and 
settecento for the eighteenth.

Neoclassicalism to Realism[edit]
The 18th and 19th centuries included Neoclassicism, Romantic art, 
Academic art, and Realism in art. Art historians disagree when Modern art 
began, some tracing it as far back as Francisco Goya in the Napoleonic 
period, the mid  19th century with the industrial revolution or the late 19th 
century with the advent of Impressionism. The art movements of the late 
19th through the early 21st centuries are too numerous to detail here, but 
can be broadly divided into two categories: Modernism and Contemporary 
art. The latter is sometimes referred to with another term, which has a subtly 
different connotation, Postmodern art.

Modern and Contemporary[edit]
Main articles: Modern art and Contemporary art

Henri Matisse, 1905  06, Le bonheur de vivre, oil on canvas, 175 x 241 cm, 
Barnes Foundation
The physical and rational certainties of the clockwork universe depicted by 
the 18th  century Enlightenment were shattered not only by new discoveries 
of relativity by Einstein[17] and of unseen psychology by Sigmund Freud,
[18] but also by unprecedented technological development accelerated by 
the implosion of civilization in two world wars. The history of 20th  century art 
is a narrative of endless possibilities and the search for new standards, each 
being torn down in succession by the next. Thus the parameters of 
Impressionism, Expressionism, Fauvism, Cubism, Dadaism, Surrealism, and 
other art movements cannot be maintained as significant and culturally 
germane very much beyond the time of their invention. Increasing global 
interaction during this time saw an equivalent influence of other cultures into 
Western art, such as Pablo Picasso being influenced by Iberian sculpture, 
African sculpture and Primitivism. Japonism, and Japanese woodcuts (which 
had themselves been influenced by Western Renaissance draftsmanship) 
had an immense influence on Impressionism and subsequent artistic 
developments. The influential example set by Paul Gauguin's interest in 
Oceanic art and the sudden popularity among the cognoscenti in early 20th 
century Paris of newly discovered African fetish sculptures and other works 
from non  European cultures were taken up by Picasso, Henri Matisse, and 
by many of their colleagues.

Modernism, in its response to the idealistic 19th century search for truth, and 
the century's progress in general, gave way in the latter decades of the 20th 
century to a realization of that idealism's unattainability. Rapid advances in 
science and technology were accepted as an unavoidable truth, which led to 
the late Modern and Postmodern period. In these periods, cultures of the 
world and of history are seen as changing forms, which can be appreciated 
and drawn from with occasional irony. Furthermore, the separation of 
cultures had become increasingly blurred and it has become more 
appropriate to think in terms of a global culture, rather than regional 
cultures.

The Americas[edit]
Main articles: Native American art, Painting in the Americas before 
Colonization and Pre  Columbian art
The history of art in the Americas begins in pre  Columbian times with 
Indigenous cultures. Art historians have focused particularly closely on 
Mesoamerica during this early era, because a series of stratified cultures 
arose there that erected grand architecture and produced objects of fine 
workmanship that are comparable to the arts of western Europe. Among the 
widely read textbooks is one by Mary Ellen Miller titled The Art of 
Mesoamerica.

Preclassic[edit]
The art  making tradition of Mesoamerican people begins with the Olmec 
around 1400 BCE, during the Preclassic era. These people are best known 
for making colossal heads but also carved jade, erected monumental 
architecture, made small  scale sculpture, and designed mosaic floors. Two 
of the most well  studied sites artistically are San Lorenzo Tenochtitl n and 
La Venta. After the Olmec culture declined, the Maya civilization became 
prominent in the region. Sometimes a transitional Epi  Olmec period is 
described, which is a hybrid of Olmec and Maya. A particularly well  studied 
Epi  Olmec site is La Mojarra, which includes hieroglyphic carvings that have 
been partially deciphered.

Classic[edit]
By the Late pre  Classic era, beginning around 400 BCE, the Olmec culture 
had declined but both Central Mexican and Maya peoples were thriving. 
Throughout much of the Classic period in Central Mexico the city of 
Teotihuacan was thriving, as were Xochicalco and El Tajin. These sites 
boasted both grand sculpture and architecture. Other Central Mexican 
peoples included the Mixtecs, the Zapotecs, and people in the Valley of 
Oaxaca. Maya art was at its height during the  Classic  period a name that 
mirrors that of Classical European antiquity and which began around 200 
CE. Major Maya sites from this era include Copan where numerous stelae 
were carved in the round, and Quirigua where the largest stelae of 
Mesoamerica are located along with zoomorphic altars. A complex writing 
system was developed, and Maya illuminated manuscripts were produced in 
large numbers on paper made from tree bark. Although Maya cities have 
existed to the present day, several sites  collapsed  around 1000.

Postclassic[edit]
At the time of the Spanish conquest of Yucatn during the 16th and 17th 
centuries, the Maya were still powerful, but many communities were paying 
tribute to Aztec society. The latter culture was thriving, and it included arts 
such as sculpture, painting, and feather mosaic. Perhaps the most well  
known work of Aztec art is the calendar stone, which has become a national 
symbol of the state of Mexico. During the Spanish conquest of the Aztec 
Empire many of these artistic objects were sent to Europe, where they were 
placed in cabinets of curiosities, and later redistributed to art museums. The 
Aztec empire was based in the city of Tenochtitlan which was largely 
destroyed during the colonial era. What remains of it was buried beneath 
Mexico City. A few buildings, such as the foundation of the Templo Mayor 
have since been unearthed by archaeologists, but they are in poor condition.

Colonial[edit]
Art in the Americas since the conquest has been a mixture of indigenous and 
foreign traditions, including European, African, and Asian settlers. Thus, 
books about the visual arts of the United States, such as Francis Pohl  s 
Framing America, start with the conquest and reconstruct manifold 
traditions. Numerous indigenous traditions thrived after the conquest. For 
example, the Plains Indians created quillwork, beadwork, winter counts, 
ledger art, and tipis in the pre  reservation era, and afterwards became 
assimilated into the world of Modern and Contemporary art through 
institutions such as the Santa Fe Indian School which encouraged students 
to develop a unique Native American style. Many paintings from that school, 
now called the Studio Style, were exhibited at the Philbrook Museum of Art 
during its Indian annual held from 1946 to 1979.

Modern[edit]
Intertwined with this story of indigenous art, are movements of painting, 
sculpture, and architecture such as the Hudson River School and the 
Ashcan School of the 19th century, and Pop Art and Abstract Expressionism 
of the 20th. Some of the most celebrated images were produced by artists of 
the American West, featuring  Cowboys and Indians,  and some of the most 
visually complex objects were created by African Americans.

Western Asia[edit]
Main articles: Ancient art, Art of Ancient Egypt, Art and architecture of 
Assyria, Persian art, Scythian art, Islamic art and Byzantine Art
Religious Islamic art often forbids depictions of people, as they may be 
misused as idols. Religious ideas are thus often represented through 
geometric designs instead. However, there are many Islamic paintings which 
display religious themes and scenes of stories common among the three 
main monotheistic faiths of Islam, Christianity, and Judaism.

Central/Southern/Eastern Asian[edit]

The Great Wave off Kanagawa by Hokusai
Main article: Eastern art history
Eastern civilization broadly includes Asia, and it also includes a complex 
tradition of art making. One Eastern art history survey textbook is John 
Laplante  s Asian Art. It divides the field by nation, with units on India, China, 
and Japan.


Fresco from Ajanta caves, c. 450  500
Eastern art has generally worked in a style akin to Western medieval art, 
namely a concentration on surface patterning and local colour (meaning the 
plain colour of an object, such as basic red for a red robe, rather than the 
modulations of that colour brought about by light, shade and reflection). A 
characteristic of this style is that the local colour is often defined by an 
outline (a contemporary equivalent is the cartoon). This is evident in, for 
example, the art of India, Tibet and Japan.

Africa[edit]

One of many ancient Yoruba sculptures discovered at Ife
See also: Egyptian art, Art of ancient Egypt, African folk art and African tribal 
masks
The long story of African Art includes both high sculpture, perhaps typified 
by the brass castings of the Benin people, as well as folk art. In the ancient 
world, Egypt is often thought of as the greatest artistic culture of Africa, but it 
is also rivaled by Nubia, which was located in present  day Sudan. 
Concurrent with the European Middle Ages, in the eleventh century CE a 
nation that made grand architecture, gold sculpture, and intricate jewelry 
was founded in Great Zimbabwe. Impressive sculpture was concurrently 
being cast from brass by the Yoruba people of what is now Nigeria. Such a 
culture grew and was ultimately transformed to become the Benin Kingdom, 
where elegant altar tusks, brass heads, plaques of brass, and palatial 
architecture was created. The Benin Kingdom was ended by the British in 
1897, and little of the historical art now remains in Nigeria. Today, the most 
significant arts venue in Africa is the Johannesburg Biennale.

Oceania[edit]
Main article: Art of Oceania
The Art of Oceania includes the geographic areas of Micronesia, Polynesia, 
Australia, New Zealand, and Melanesia. Nicholas Thomas  s textbook 
Oceanic Art treats the area thematically, with essays on ancestry, warfare, 
the body, gender, trade, religion, and tourism. Unfortunately, little ancient art 
survives from Oceania. Scholars believe that this is likely because artists 
used perishable materials, such as wood and feathers, which did not survive 
in the tropical climate, and there are no historical records to refer to this most 
material. The understanding of Oceania's artistic cultures thus begins with 
the documentation of it by Westerners, such as Captain James Cook in the 
eighteenth century. At the turn of the twentieth century the French artist Paul 
Gauguin spent significant amounts of time in Tahiti, living with local people 
and making modern art a fact that has become intertwined with Tahitian 
visual culture to the present day. The indigenous art of Australia often looks 
like abstract modern art, but it has deep roots in local culture.

Art museums[edit]

The Guggenheim Museum in Bilbao, Spain
The experience of art history, as conveyed by art museums, tends to be 
organized differently from that of textbooks due to the nature of collections 
and the institutions themselves. Rather than a full march through time, 
museums employ curators who assemble objects into exhibitions, often with 
unique commentary that is later reinterpreted by docents. Because they 
have the responsibility to store objects, museums develop taxonomies for 
their collections, using conventions of classification authority for the sake of 
consistency. This may be undertaken with the museum  s archivist. The 
result is to occasionally find a strong emphasis on the history of media in 
conjunction with the history of culture.

Such an emphasis on media is a natural outgrowth of the internal 
classification systems used in art museums, which usually include 
departments of painting, sculpture, decorative arts, and works on paper. 
Painting itself includes several media, such as oil painting, Tempera 
painting, watercolor. Sculpture can be divided into carving and casting. The 
decorative arts are perhaps the most diverse, as they include: textiles and 
needlework, which includes weaving, lace, shibori, and other work with 
fabric; Murals, of which frescoes are one form; and objects of adornment 
such as silver, ceramics, lacquerware, stained glass, and furniture. 
Museums generally cannot collect full buildings, but they may acquire 
pieces of architectural ornamentation, which also fall under the decorative 
arts department. Works on paper includes printmaking, photography, and 
the book arts such as illuminated manuscripts. Museums may also include a 
department of applied arts, which includes objects of good design along 
with the graphic art, illustration, and other forms of commercial art.

Art market[edit]
The art market can also be used to understand what  counts  as part of art 
history. Art dealers and auctioneers organize material for distribution to 
collectors. Two of the largest, and oldest, art auction houses are Sotheby's 
and Christie's, and each hold frequent sales of great antiquities and art 
objects.

In addition to upstanding practices, a black market exists for great art, which 
is closely tied to art theft and art forgery. No auction houses or dealers admit 
openly to participating in the black market because of its illegality, but expos 
s suggest widespread problems in the field. Because demand for art objects 
is high, and security in many parts of the world is low, a thriving trade in illicit 
antiquities acquired through looting also exists. Although the art community 
nearly universally condemns looting because it results in destruction of 
archeological sites, looted art paradoxically remains omnipresent. Warfare is 
correlated with such looting, as is demonstrated by the recent archaeological 
looting in Iraq.

Nationalist art history[edit]
Both the making of art, the academic history of art, and the history of art 
museums are closely intertwined with the rise of nationalism. Art created in 
the modern era, in fact, has often been an attempt to generate feelings of 
national superiority or love of one  s country. Russian art is an especially 
good example of this, as the Russian avant  garde and later Soviet art were 
attempts to define that country  s identity.

Most art historians working today identify their specialty as the art of a 
particular culture and time period, and often such cultures are also nations. 
For example, someone might specialize in the 19th  century German or 
contemporary Chinese art history. A focus on nationhood has deep roots in 
the discipline. Indeed, Vasari's Lives of the Artists is an attempt to show the 
superiority of Florentine artistic culture, and Heinrich W lfflin's writings 
(especially his monograph on Albrecht D rer) attempt to distinguish Italian 
from German styles of art.

Many of the largest and most well  funded art museums of the world, such 
as the Louvre, the Victoria and Albert Museum, and the National Gallery of 
Art in Washington are state  owned. Most countries, indeed have a national 
gallery, with an explicit mission of preserving the cultural patrimony owned 
by the government regardless of what cultures created the art and an often 
implicit mission to bolster that country  s own cultural heritage. The National 
Gallery of Art thus showcases art made in the United States, but also owns 
objects from across the world.

Academic art history[edit]

Laoco n and his Sons, Greek, (Late Hellenistic), c. 160 BCE and 20 BCE, 
White marble, Vatican Museum
The study of the history of art is a relatively recent phenomenon; prior to the 
Renaissance, the modern concept of "art" did not exist. Over time, art 
historians have changed their views about what art is worthy of scrutiny. For 
example, during the early Victorian era, the 15th  century Italian artists were 
considered inferior to those of 16th  century High Renaissance. Such a 
notion was challenged by the Pre  Raphaelite movement. There has since 
been a trend, dominant in art history of the 21st century, to treat all cultures 
and periods neutrally. Thus, Australian Aboriginal art would not be deemed 
better or worse than Renaissance art it is just different. Art historical analysis 
has also evolved into studying the social and political use of art, rather than 
focusing solely on the aesthetic appreciation of its craftsmanship (beauty). 
What may once have been viewed simply as a masterpiece is now 
understood as an economic, social, philosophical, and cultural manifestation 
of the artist's world  view, philosophy, intentions and background.

Building
From Wikipedia, the free encyclopedia
This article is about a man-made structure intended for human use or 
occupation. For the act of making buildings, see Construction. For structures 
not intended for human use, see Nonbuilding structure. For other uses, see 
Building (disambiguation).

The H tel de Ville, building in Paris, France

A Shaolin Monastery building in China
A building or edifice is a structure with a roof and walls standing more or less 
permanently in one place, such as a house or factory.[1] Buildings come in a 
variety of sizes, shapes and functions, and have been adapted throughout 
history for a wide number of factors, from building materials available, to 
weather conditions, to land prices, ground conditions, specific uses and 
aesthetic reasons. To better understand the term building compare the list of 
nonbuilding structures.

Buildings serve several needs of society   primarily as shelter from weather, 
security, living space, privacy, to store belongings, and to comfortably live 
and work. A building as a shelter represents a physical division of the human 
habitat (a place of comfort and safety) and the outside (a place that at times 
may be harsh and harmful).

Ever since the first cave paintings, buildings have also become objects or 
canvasess of artistic expression. In recent years, interest in sustainable 
planning and building practices has also become an intentional part of the 
design process of many new buildings.

Contents  [hide] 
1  Definitions
2 History
3 Types
3.1 Residential
3.2 Multi-storey
4 Creation
4.1 Ownership and funding
5 Building services
5.1 Physical plant
5.2 Conveying systems
6 Building damage
7 See also
8 References
9 External links
Definitions[edit]

A building and skybridge in Munich, Germany

The Rotunda in Hellerup, Denmark, a cylindric building made in steel frame 
and aluminum

Example of a religious building: the Great Mosque of Kairouan (also called 
the Mosque of Uqba), founded in 670, dates in its present state principally 
from the 9th century. The Great Mosque of Kairouan is located in the city of 
Kairouan, Tunisia.

Da Vinci building (at the left), in Mendoza, Argentina. Considered one of the 
1000 architectures of the Americas.
The word building is both a noun and a verb: the structure itself and the act 
of making it. As a noun, a building is 'a structure that has a roof and walls 
and stands more or less permanently in one place';[1] "there was a three-
storey building on the corner"; "it was an imposing edifice". In the broadest 
interpretation a fence or wall is a building[2] However, the word structure is 
used more broadly than building including natural and man-made 
formations[3] and does not necessarily have walls. Structure is more likely to 
be used for a fence. Sturgis' Dictionary included that "[building] differs from 
Architecture [sic] in excluding all idea of artistic treatment; and it differs from 
Construction [sic] in the idea of excluding scientific or highly skilful 
treatment."[4] As a verb, building is the act of construction.

Structural height in technical usage is the height to the highest architectural 
detail on building from street-level. Depending on how they are classified, 
spires and masts may or may not be included in this height. Spires and 
masts used as antennas are not generally included. The definition of a low-
rise vs. a high-rise building is a matter of debate, but generally three storeys 
or less is considered low-rise.[5]

History[edit]
See also: History of architecture
A report by Shinichi Fujimura of a shelter built 500 000 years ago[6] is 
doubtful since Fujimura was later found to have faked many of his findings.
[7] Supposed remains of huts found at the Terra Amata site in Nice 
purportedly dating from 200 000 to 400 000 years ago[8] have also been 
called into question. (See Terra Amata.) There is clear evidence of home-
building from around 18 000 BC.[9] Buildings became common during the 
Neolithic (see Neolithic architecture).

Types[edit]
Main article: List of building types

A timber-framed house in Marburg, Germany

A block of tenements (apartments) in Bruntsfield, Edinburgh, Scotland
Residential[edit]
Main article: List of human habitation forms
Single-family residential buildings are most often called houses or homes. 
Residential buildings containing more than one dwelling unit are called a 
duplex, apartment building to differentiate them from 'individual' houses. A 
condominium is an apartment that the occupant owns rather than rents. 
Houses may also be built in pairs (semi-detached), in terraces where all but 
two of the houses have others either side; apartments may be built round 
courtyards or as rectangular blocks surrounded by a piece of ground of 
varying sizes. Houses which were built as a single dwelling may later be 
divided into apartments or bedsitters; they may also be converted to another 
use e.g. an office or a shop.

Building types may range from huts to multi-million dollar high-rise 
apartment blocks able to house thousands of people. Increasing settlement 
density in buildings (and smaller distances between buildings) is usually a 
response to high ground prices resulting from many people wanting to live 
close to work or similar attractors. Other common building materials are 
brick, concrete or combinations of either of these with stone.

Residential buildings have different names for their use depending if they 
are seasonal include holiday cottage (vacation home) or timeshare; size 
such as a cottage or great house; value such as a shack or mansion; 
manner of construction such as a log home or mobile home; proximity to the 
ground such as earth sheltered house, stilt house, or tree house. Also if the 
residents are in need of special care such as a nursing home, orphanage or 
prison; or in group housing like barracks or dormitorys.

Historically many people lived in communal buildings called longhouses, 
smaller dwellings called pit-houses and houses combined with barns 
sometimes called housebarns.

Buildings are defined to be substantial, permanent structures so other 
dwelling forms such as houseboats, yurts, and motorhomes are dwellings 
but not buildings.

Multi-storey[edit]
A Multi-storey is a building that has multiple floors above ground in the 
building.

Multi-storey buildings aim to increase the floor area of the building without 
increasing the area of the land the building is built on, hence saving land 
and, in most cases, money (depending on material used and land prices in 
the area). The building with the most stories is the Burj Khalifa, with 162.

Creation[edit]
The practice of designing, constructing, and operating buildings is most 
usually a collective effort of different groups of professionals and trades. 
Depending on the size, complexity, and purpose of a particular building 
project, the project team may include:

A real estate developer who secures funding for the project;
One or more financial institutions or other investors that provide the funding
Local planning and code authorities
A Surveyor who performs an ALTA/ACSM and construction surveys 
throughout the project;
Construction managers who coordinate the effort of different groups of 
project participants;
Licensed architects and engineers who provide building design and prepare 
construction documents;
Landscape architects;
Interior designers;
Other consultants;
Contractors who provide construction services and install building systems 
such as climate control, electrical, plumbing, Decoration, fire protection, 
security and telecommunications;
Marketing or leasing agents;
Facility managers who are responsible for operating the building.
Regardless of their size or intended use, all buildings in the US must comply 
with zoning ordinances, building codes and other regulations such as fire 
codes, life safety codes and related standards.

Vehicles such as trailers, caravans, ships and passenger aircraft are treated 
as "buildings" for life safety purposes.

Ownership and funding[edit]
Mortgage loan
Real estate developer
Building services[edit]
Physical plant[edit]
Main article: Physical plant

The BB&T Building in Macon, Georgia is constructed of aluminum.
Any building requires a certain amount of internal infrastructure to function, 
which includes such elements like heating / cooling, power and 
telecommunications, water and wastewater etc. Especially in commercial 
buildings (such as offices or factories), these can be extremely intricate 
systems taking up large amounts of space (sometimes located in separate 
areas or double floors / false ceilings) and constitute a big part of the regular 
maintenance required.

Conveying systems[edit]
Systems for transport of people within buildings:

Elevator
Escalator
Moving sidewalk (horizontal and inclined)
Systems for transport of people between interconnected buildings:

Skyway
Underground city
Building damage[edit]

A building in Massueville, Quebec, Canada engulfed by fire
Buildings may be damaged during the construction of the building or during 
maintenance. There are several other reasons behind building damage like 
accidents[10] such as storms, explosions and subsidence caused by mining 
or poor foundations. Buildings also may suffer from fire damage and 
flooding in special circumstances. They may also become dilapidated 
through lack of proper maintenance or alteration work improperly carried out.

See also[edit]
An autonomous building is a building designed to be operated 
independently from infrastructural support services such as the electric 
power grid, gas grid, municipal water systems, sewage treatment systems, 
storm drains, communication services, and in some cases, public roads.

Advocates of autonomous building describe advantages that include 
reduced environmental impacts, increased security, and lower costs of 
ownership. Some cited advantages satisfy tenets of green building, not 
independence per se (see below). Off-grid buildings often rely very little on 
civil services and are therefore safer and more comfortable during civil 
disaster or military attacks. (Off-grid buildings would not lose power or water 
if public supplies were compromised for some reason.)

Most of the research and published articles concerning autonomous building 
focus on residential homes.

British architects Brenda and Robert Vale have said that, as of 2002,

"It is quite possible in all parts of Australia to construct a 'house with no 
bills', which would be comfortable without heating and cooling, which would 
make its own electricity, collect its own water and deal with its own 
waste...These houses can be built now, using off-the-shelf techniques. It is 
possible to build a "house with no bills" for the same price as a conventional 
house, but it would be (25%) smaller."[1] 

Creativity is a phenomenon whereby something new and somehow valuable 
is formed. The created item may be intangible (such as an idea, a scientific 
theory, a musical composition or a joke) or a physical object (such as an 
invention, a literary work or a painting).

Scholarly interest in creativity involves many definitions and concepts 
pertaining to a number of disciplines: psychology, cognitive science, 
education, philosophy (particularly philosophy of science), technology, 
theology, sociology, linguistics, business studies, songwriting, and 
economics, covering the relations between creativity and general 
intelligence, mental and neurological processes, personality type and 
creative ability, creativity and mental health; the potential for fostering 
creativity through education and training, especially as augmented by 
technology; and the application of creative resources to improve the 
effectiveness of teaching and learning.
In a summary of scientific research into creativity, Michael Mumford 
suggested: "Over the course of the last decade, however, we seem to have 
reached a general agreement that creativity involves the production of novel, 
useful products" (Mumford, 2003, p. 110),[1] or, in Robert Sternberg's words, 
the production of "something original and worthwhile".[2] Authors have 
diverged dramatically in their precise definitions beyond these general 
commonalities: Peter Meusburger reckons that over a hundred different 
analyses can be found in the literature.[3] As an illustration, one definition 
given by Dr. E. Paul Torrance described it as "a process of becoming 
sensitive to problems, deficiencies, gaps in knowledge, missing elements, 
disharmonies, and so on; identifying the difficulty; searching for solutions, 
making guesses, or formulating hypotheses about the deficiencies:testing 
and retesting these hypotheses and possibly modifying and retesting them; 
and finally communicating the results."[4]

Aspects[edit]
Theories of creativity (particularly investigation of why some people are more 
creative than others) have focused on a variety of aspects. The dominant 
factors are usually identified as "the four Ps"   process, product, person and 
place (according to Mel Rhodes).[5] A focus on process is shown in cognitive 
approaches that try to describe thought mechanisms and techniques for 
creative thinking. Theories invoking divergent rather than convergent 
thinking (such as Guilford), or those describing the staging of the creative 
process (such as Wallas) are primarily theories of creative process. A focus 
on creative product usually appears in attempts to measure creativity 
(psychometrics, see below) and in creative ideas framed as successful 
memes.[6] The psychometric approach to creativity reveals that it also 
involves the ability to produce more.[7] A focus on the nature of the creative 
person considers more general intellectual habits, such as openness, levels 
of ideation, autonomy, expertise, exploratory behavior and so on. A focus on 
place considers the circumstances in which creativity flourishes, such as 
degrees of autonomy, access to resources and the nature of gatekeepers. 
Creative lifestyles are characterized by nonconforming attitudes and 
behaviors as well as flexibility.[7]

Etymology[edit]
The lexeme in the English word creativity comes from the Latin term cre  "to 
create, make": its derivational suffixes also come from Latin. The word 
"create" appeared in English as early as the 14th century, notably in 
Chaucer, to indicate divine creation[8] (in The Parson's Tale[9]). However, its 
modern meaning as an act of human creation did not emerge until after the 
Enlightenment.[8]

History of the concept[edit]
Main article: History of the concept of creativity

Greek philosophers like Plato rejected the concept of creativity, preferring to 
see art as a form of discovery. Asked in The Republic, "Will we say, of a 
painter, that he makes something ", Plato answers, "Certainly not, he merely 
imitates."[10]
Ancient views[edit]
Most ancient cultures, including thinkers of Ancient Greece,[10] Ancient 
China, and Ancient India,[11] lacked the concept of creativity, seeing art as a 
form of discovery and not creation. The ancient Greeks had no terms 
corresponding to "to create" or "creator" except for the expression "poiein" 
("to make"), which only applied to poiesis (poetry) and to the poietes (poet, 
or "maker") who made it. Plato did not believe in art as a form of creation. 
Asked in The Republic,[12] "Will we say, of a painter, that he makes 
something ", he answers, "Certainly not, he merely imitates."[10]

It is commonly argued that the notion of "creativity" originated in Western 
culture through Christianity, as a matter of divine inspiration.[8] According to 
the historian Daniel J. Boorstin, "the early Western conception of creativity 
was the Biblical story of creation given in the Genesis."[13] However, this is 
not creativity in the modern sense, which did not arise until the Renaissance. 
In the Judaeo-Christian tradition, creativity was the sole province of God; 
humans were not considered to have the ability to create something new 
except as an expression of God's work.[14] A concept similar to that of 
Christianity existed in Greek culture, for instance, Muses were seen as 
mediating inspiration from the Gods.[15] Romans and Greeks invoked the 
concept of an external creative "daemon" (Greek) or "genius" (Latin), linked 
to the sacred or the divine. However, none of these views are similar to the 
modern concept of creativity, and the individual was not seen as the cause of 
creation until the Renaissance.[16] It was during the Renaissance that 
creativity was first seen, not as a conduit for the divine, but from the abilities 
of "great men".[16]

The Enlightenment and after[edit]
The rejection of creativity in favor of discovery and the belief that individual 
creation was a conduit of the divine would dominate the West probably until 
the Renaissance and even later.[14] The development of the modern 
concept of creativity begins in the Renaissance, when creation began to be 
perceived as having originated from the abilities of the individual, and not 
God. This could be attributed to the leading intellectual movement of the 
time, aptly named humanism, which developed an intensely human-centric 
outlook on the world, valuing the intellect and achievement of the individual.
[17] From this philosophy arose the Renaissance man (or polymath), an 
individual who embodies the principals of humanism in their ceaseless 
courtship with knowledge and creation.[18] One of the most well-known and 
immensely accomplished examples is Leonardo da Vinci.

However, this shift was gradual and would not become immediately apparent 
until the Enlightenment.[16] By the 18th century and the Age of 
Enlightenment, mention of creativity (notably in aesthetics), linked with the 
concept of imagination, became more frequent.[19] In the writing of Thomas 
Hobbes, imagination became a key element of human cognition;[8] William 
Duff was one of the first to identify imagination as a quality of genius, 
typifying the separation being made between talent (productive, but 
breaking no new ground) and genius.[15]

As a direct and independent topic of study, creativity effectively received no 
attention until the 19th century.[15] Runco and Albert argue that creativity as 
the subject of proper study began seriously to emerge in the late 19th 
century with the increased interest in individual differences inspired by the 
arrival of Darwinism. In particular they refer to the work of Francis Galton, 
who through his eugenicist outlook took a keen interest in the heritability of 
intelligence, with creativity taken as an aspect of genius.[8]

In the late 19th and early 20th centuries, leading mathematicians and 
scientists such as Hermann von Helmholtz (1896) and Henri Poincar  (1908) 
began to reflect on and publicly discuss their creative processes.

Twentieth century to the present day[edit]
The insights of Poincar  and von Helmholtz were built on in early accounts of 
the creative process by pioneering theorists such as Graham Wallas[20] and 
Max Wertheimer. In his work Art of Thought, published in 1926, Wallas 
presented one of the first models of the creative process. In the Wallas stage 
model, creative insights and illuminations may be explained by a process 
consisting of 5 stages:

(i) preparation (preparatory work on a problem that focuses the individual's 
mind on the problem and explores the problem's dimensions),
(ii) incubation (where the problem is internalized into the unconscious mind 
and nothing appears externally to be happening),
(iii) intimation (the creative person gets a "feeling" that a solution is on its 
way),
(iv) illumination or insight (where the creative idea bursts forth from its 
preconscious processing into conscious awareness);
(v) verification (where the idea is consciously verified, elaborated, and then 
applied).
Wallas' model is often treated as four stages, with "intimation" seen as a 
sub-stage.

Wallas considered creativity to be a legacy of the evolutionary process, 
which allowed humans to quickly adapt to rapidly changing environments. 
Simonton[21] provides an updated perspective on this view in his book, 
Origins of genius: Darwinian perspectives on creativity.

In 1927, Alfred North Whitehead gave the Gifford Lectures at the University 
of Edinburgh, later published as Process and Reality.[22] He is credited with 
having coined the term "creativity" to serve as the ultimate category of his 
metaphysical scheme: "Whitehead actually coined the term   our term, still 
the preferred currency of exchange among literature, science, and the arts. . 
. a term that quickly became so popular, so omnipresent, that its invention 
within living memory, and by Alfred North Whitehead of all people, quickly 
became occluded".[23]

The formal psychometric measurement of creativity, from the standpoint of 
orthodox psychological literature, is usually considered to have begun with 
J. P. Guilford's 1950 address to the American Psychological Association, 
which helped popularize the topic[24] and focus attention on a scientific 
approach to conceptualizing creativity. (It should be noted that the London 
School of Psychology had instigated psychometric studies of creativity as 
early as 1927 with the work of H. L. Hargreaves into the Faculty of 
Imagination,[25] but it did not have the same impact.) Statistical analysis led 
to the recognition of creativity (as measured) as a separate aspect of human 
cognition to IQ-type intelligence, into which it had previously been 
subsumed. Guilford's work suggested that above a threshold level of IQ, the 
relationship between creativity and classically measured intelligence broke 
down.[26]

"Four C" model[edit]
James C. Kaufman and Beghetto introduced a "four C" model of creativity; 
mini-c ("transformative learning" involving "personally meaningful 
interpretations of experiences, actions and insights"), little-c (everyday 
problem solving and creative expression), Pro-C (exhibited by people who 
are professionally or vocationally creative though not necessarily eminent) 
and Big-C (creativity considered great in the given field). This model was 
intended to help accommodate models and theories of creativity that 
stressed competence as an essential component and the historical 
transformation of a creative domain as the highest mark of creativity. It also, 
the authors argued, made a useful framework for analyzing creative 
processes in individuals.[27]

The contrast of terms "Big C" and "Little c" has been widely used. Kozbelt, 
Beghetto and Runco use a little-c/Big-C model to review major theories of 
creativity [26] Margaret Boden distinguishes between h-creativity (historical) 
and p-creativity (personal).[28]

Robinson[29] and Anna Craft[30] have focused on creativity in a general 
population, particularly with respect to education. Craft makes a similar 
distinction between "high" and "little c" creativity.[30] and cites Ken Robinson 
as referring to "high" and "democratic" creativity. Mih ly Cs kszentmih lyi[31] 
has defined creativity in terms of those individuals judged to have made 
significant creative, perhaps domain-changing contributions. Simonton has 
analysed the career trajectories of eminent creative people in order to map 
patterns and predictors of creative productivity.[32]

Theories of creative processes[edit]
There has been much empirical study in psychology and cognitive science 
of the processes through which creativity occurs. Interpretation of the results 
of these studies has led to several possible explanations of the sources and 
methods of creativity.

Incubation[edit]
Incubation is a temporary break from creative problem solving that can result 
in insight.[33] There has been some empirical research looking at whether, 
as the concept of "incubation" in Wallas' model implies, a period of 
interruption or rest from a problem may aid creative problem-solving. Ward
[34] lists various hypotheses that have been advanced to explain why 
incubation may aid creative problem-solving, and notes how some empirical 
evidence is consistent with the hypothesis that incubation aids creative 
problem-solving in that it enables "forgetting" of misleading clues. Absence 
of incubation may lead the problem solver to become fixated on 
inappropriate strategies of solving the problem.[35] This work disputes the 
earlier hypothesis that creative solutions to problems arise mysteriously from 
the unconscious mind while the conscious mind is occupied on other tasks.
[36] This earlier hypothesis is discussed in Csikszentmihalyi's five phase 
model of the creative process which describes incubation as a time that your 
unconscious takes over. This allows for unique connections to be made 
without your consciousness trying to make logical order out of the problem.
[37]

Convergent and divergent thinking[edit]
J. P. Guilford[38] drew a distinction between convergent and divergent 
production (commonly renamed convergent and divergent thinking). 
Convergent thinking involves aiming for a single, correct solution to a 
problem, whereas divergent thinking involves creative generation of multiple 
answers to a set problem. Divergent thinking is sometimes used as a 
synonym for creativity in psychology literature. Other researchers have 
occasionally used the terms flexible thinking or fluid intelligence, which are 
roughly similar to (but not synonymous with) creativity.[citation needed]

Creative cognition approach[edit]
In 1992, Finke et al. proposed the "Geneplore" model, in which creativity 
takes place in two phases: a generative phase, where an individual 
constructs mental representations called preinventive structures, and an 
exploratory phase where those structures are used to come up with creative 
ideas. Some evidence shows that when people use their imagination to 
develop new ideas, those ideas are heavily structured in predictable ways by 
the properties of existing categories and concepts.[39] Weisberg[40] argued, 
by contrast, that creativity only involves ordinary cognitive processes yielding 
extraordinary results.

The Explicit Implicit Interaction (EII) theory[edit]
Helie and Sun[41] recently proposed a unified framework for understanding 
creativity in problem solving, namely the Explicit Implicit Interaction (EII) 
theory of creativity. This new theory constitutes an attempt at providing a 
more unified explanation of relevant phenomena (in part by 
reinterpreting/integrating various fragmentary existing theories of incubation 
and insight). The EII theory relies mainly on five basic principles, namely 1) 
The co-existence of and the difference between explicit and implicit 
knowledge; 2) The simultaneous involvement of implicit and explicit 
processes in most tasks; 3) The redundant representation of explicit and 
implicit knowledge; 4) The integration of the results of explicit and implicit 
processing; and 5) The iterative (and possibly bidirectional) processing. A 
computational implementation of the theory was developed based on the 
CLARION cognitive architecture and used to simulate relevant human data. 
This work represents an initial step in the development of process-based 
theories of creativity encompassing incubation, insight, and various other 
related phenomena.

Conceptual blending[edit]
Main article: Conceptual blending
In The Act of Creation, Arthur Koestler introduced the concept of bisociation 
that creativity arises as a result of the intersection of two quite different 
frames of reference.[42] This idea was later developed into conceptual 
blending. In the '90s, various approaches in cognitive science that dealt with 
metaphor, analogy and structure mapping have been converging, and a new 
integrative approach to the study of creativity in science, art and humor has 
emerged under the label conceptual blending.

Honing theory[edit]
Honing theory posits that creativity arises due to the self-organizing, self-
mending nature of a worldview, and that it is by way of the creative process 
the individual hones (and re-hones) an integrated worldview. Honing theory 
places equal emphasis on the externally visible creative outcome and the 
internal cognitive restructuring brought about by the creative process. 
Indeed, one factor that distinguishes it from other theories of creativity is that 
it focuses on not just restructuring as it pertains to the conception of the 
task, but as it pertains to the worldview as a whole. When faced with a 
creatively demanding task, there is an interaction between the conception of 
the task and the worldview. The conception of the task changes through 
interaction with the worldview, and the worldview changes through 
interaction with the task. This interaction is reiterated until the task is 
complete, at which point not only is the task conceived of differently, but the 
worldview is subtly or drastically transformed. Thus another distinguishing 
feature of honing theory is that the creative process reflects the natural 
tendency of a worldview to attempt to resolve dissonance and seek internal 
consistency amongst its components, whether they be ideas, attitudes, or 
bits of knowledge; it mends itself as does a body when it has been injured.

Yet another central, distinguishing feature of honing theory is the notion of a 
potentiality state.[43] Honing theory posits that creative thought proceeds 
not by searching through and randomly mutating  predefined possibilities, 
but by drawing upon associations that exist due to overlap in the distributed 
neural cell assemblies that participate in the encoding of experiences in 
memory. Midway through the creative process one may have made 
associations between the current task and previous experiences, but not yet 
disambiguated which aspects of those previous experiences are relevant to 
the current task. Thus the creative idea may feel half-baked . It is at that 
point that it can be said to be in a potentiality state, because how it will 
actualize depends on the different internally or externally generated contexts 
it interacts with.

Honing theory can account for many phenomena that are not readily 
explained by other theories of creativity. For example, creativity was 
commonly thought to be fostered by a supportive, nurturing, trustworthy 
environment conducive to self-actualization. However, research shows that 
creativity is actually associated with childhood adversity, which would 
stimulate honing. Honing theory also makes several predictions that differ 
from what would be predicted by other theories. For example, empirical 
support has been obtained using analogy problem solving experiments for 
the proposal that midway through the creative process one's mind is in a 
potentiality state. Other experiments show that different works by the same 
creator exhibit a recognizable style or 'voice', and that this same 
recognizable quality even comes through in different creative outlets. This is 
not predicted by theories of creativity that emphasize chance processes or 
the accumulation of expertise, but it is predicted by honing theory, according 
to which personal style reflects the creator's uniquely structured worldview. 
This theory has been developed by Liane Gabora.

Everyday imaginative thought[edit]
In everyday thought, people often spontaneously imagine alternatives to 
reality when they think "if only...".[44] Their counterfactual thinking is viewed 
as an example of everyday creative processes.[45] It has been proposed that 
the creation of counterfactual alternatives to reality depends on similar 
cognitive processes to rational thought.[46]

Assessing individual creative ability[edit]
Creativity quotient[edit]
Several attempts have been made to develop a creativity quotient of an 
individual similar to the intelligence quotient (IQ), however these have been 
unsuccessful.[47]

Psychometric approach[edit]
J. P. Guilford's group,[38] which pioneered the modern psychometric study 
of creativity, constructed several tests to measure creativity in 1967:

Plot Titles, where participants are given the plot of a story and asked to write 
original titles.
Quick Responses is a word-association test scored for uncommonness.
Figure Concepts, where participants were given simple drawings of objects 
and individuals and asked to find qualities or features that are common by 
two or more drawings; these were scored for uncommonness.
Unusual Uses is finding unusual uses for common everyday objects such as 
bricks.
Remote Associations, where participants are asked to find a word between 
two given words (e.g. Hand _____ Call)
Remote Consequences, where participants are asked to generate a list of 
consequences of unexpected events (e.g. loss of gravity)
Building on Guilford's work, Torrance[48] developed the Torrance Tests of 
Creative Thinking in 1966.[49] They involved simple tests of divergent 
thinking and other problem-solving skills, which were scored on:

Fluency   The total number of interpretable, meaningful and relevant ideas 
generated in response to the stimulus.
Originality   The statistical rarity of the responses among the test subjects.
Elaboration   The amount of detail in the responses.
The Creativity Achievement Questionnaire, a self-report test that measures 
creative achievement across 10 domains, was described in 2005 and shown 
to be reliable and valid when compared to other measures of creativity and 
to independent evaluation of creative output.[50]

Such tests, sometimes called Divergent Thinking (DT) tests have been both 
supported[51] and criticized.[52]

Considerable progress has been made in automated scoring of Divergent 
Thinking tests using semantic approach. When compared to human raters, 
NLP techniques were shown to be reliable and valid in scoring the originality 
(when compared to human raters).[53][54] The reported computer programs 
were able to achieve a correlation of 0.60 and 0.72 respectively to human 
graders.

Semantic networks were also used to devise originality scores that yielded 
significant correlations with socio-personal measures.[55] Most recently, An 
NSF-funded[56] team of researchers led by James C. Kaufman and Mark A. 
Runco[57] combined expertise in creativity research, natural language 
processing, computational linguistics, and statistical data analysis to devise 
a scalable system for computerized automated testing (SparcIt Creativity 
Index Testing system). This system enabled automated scoring of DT tests 
that is reliable, objective, and scalable, thus addressing most of the issues 
of DT tests that had been found and reported.[52] The resultant computer 
system was able to achieve a correlation of 0.73 to human graders.[58]

Social-personality approach[edit]
Some researchers have taken a social-personality approach to the 
measurement of creativity. In these studies, personality traits such as 
independence of judgement, self-confidence, attraction to complexity, 
aesthetic orientation and risk-taking are used as measures of the creativity of 
individuals.[24] A meta-analysis by Gregory Feist showed that creative 
people tend to be "more open to new experiences, less conventional and 
less conscientious, more self-confident, self-accepting, driven, ambitious, 
dominant, hostile,and impulsive." Openness, conscientiousness, self-
acceptance, hostility and impulsivity had the strongest effects of the traits 
listed.[59] Within the framework of the Big Five model of personality some 
consistent traits have emerged.[60] Openness to experience has been 
shown to be consistently related to a whole host of different assessments of 
creativity.[61] Among the other Big Five traits, research has demonstrated 
subtle differences between different domains of creativity. Compared to 
non-artists, artists tend to have higher levels of openness to experience and 
lower levels of conscientiousness, while scientists are more open to 
experience, conscientious, and higher in the confidence-dominance facets of 
extraversion compared to non-scientists.[59]

Creativity and intelligence[edit]
The potential relationship between creativity and Intelligence has been of 
interest since the late 1900s, when a multitude of influential studies   from 
Getzels & Jackson,[62] Barron,[63] Wallach & Kogan,[64] and Guilford[65]   
focused not only on creativity, but also on intelligence. This joint focus 
highlights both the theoretical and practical importance of the relationship: 
researchers are interested not only if the constructs are related, but also 
how and why.[66]

There are multiple theories accounting for their relationship, with the 3 main 
theories as follows:

Threshold Theory   Intelligence is a necessary, but not sufficient condition for 
creativity. There is a moderate positive relationship between creativity and 
intelligence until IQ ~120 [63][65]
Certification Theory   Creativity is not intrinsically related to intelligence. 
Instead individuals are required to meet the requisite level intelligence in 
order to gain a certain level of education/work, which then in turn offers the 
opportunity to be creative. Displays of creativity are moderated by 
intelligence[67]
Interference Theory   Extremely high intelligence might interfere with creative 
ability [68]
Sternberg and O Hara[69] proposed a framework of 5 possible relationships 
between creativity and intelligence:

Creativity is a subset of intelligence
Intelligence is a subset of creativity
Creativity and intelligence are overlapping constructs
Creativity and intelligence are part of the same construct (coincident sets)
Creativity and intelligence are distinct constructs (disjoint sets)
Creativity as a subset of intelligence[edit]
A number of researchers include creativity, either explicitly or implicitly, as a 
key component of intelligence.

Examples of theories that include creativity as a subset of intelligence

Gardner s Theory of multiple intelligences (MIT)[70]   implicitly includes 
creativity as a subset of MIT. To demonstrate this, Gardner cited examples of 
different famous creators, each of whom differed in their types of 
intelligences e.g. Picasso (spatial intelligence); Freud (intrapersonal); 
Einstein (logical-mathematical); and Gandhi (interpersonal).
Sternberg s Theory of Successful intelligence[68][69][71] (see Triarchic 
theory of intelligence) includes creativity as a main component, and 
comprises 3 sub-theories: Componential (Analytic), Contextual (Practical) 
and Experiential (Creative). Experiential sub-theory   the ability to use pre-
existing knowledge and skills to solve new and novel problems   is directly 
related to creativity.
The Cattell Horn Carroll theory includes creativity as a subset of intelligence. 
Specifically, it is associated with the broad group factor of long-term storage 
and retrieval (Glr). Glr narrow abilities relating to creativity include:[72] 
ideational fluency, associational fluency and originality/creativity. Silvia et al.
[73] conducted a study to look at the relationship between divergent thinking 
and verbal fluency tests, and reported that both fluency and originality in 
divergent thinking were significantly affected by the broad level Glr factor. 
Martindale [74] extended the CHC-theory in the sense that it was proposed 
that those individuals who are creative are also selective in their processing 
speed Martindale argues that in the creative process, larger amounts of 
information are processed more slowly in the early stages, and as the 
individual begins to understand the problem, the processing speed is 
increased.
The Dual Process Theory of Intelligence[75] posits a two-factor/type model 
of intelligence. Type 1 is a conscious process, and concerns goal directed 
thoughts, which are explained by g. Type 2 is an unconscious process, and 
concerns spontaneous cognition, which encompasses daydreaming and 
implicit learning ability. Kaufman argues that creativity occurs as a result of 
Type 1 and Type 2 processes working together in combination. The use of 
each Type in the creative process can be used to varying degrees.
Intelligence as a subset of creativity[edit]
In this relationship model, intelligence is a key component in the 
development of creativity.

Theories of creativity that include intelligence as a subset of creativity

Sternberg & Lubart s Investment Theory.[76][77] Using the metaphor of a 
stock market, they demonstrate that creative thinkers are like good investors  
 they buy low and sell high (in their ideas). Like under/low-valued stock, 
creative individuals generate unique ideas that are initially rejected by other 
people. The creative individual has to persevere, and convince the others of 
the ideas value. After convincing the others, and thus increasing the ideas 
value, the creative individual sells high  by leaving the idea with the other 
people, and moves onto generating another idea. According to this theory, 
six distinct, but related elements contribute to successful creativity: 
intelligence, knowledge, thinking styles, personality, motivation, and 
environment. Intelligence is just one of the six factors that can either solely, 
or in conjunction with the other five factors, generate creative thoughts.
Amabile s Componential Model of Creativity.[78][79] In this model there are 3 
within-individual components needed for creativity   domain-relevant skills, 
creativity-relevant processes, and task motivation   and 1 component 
external to the individual: their surrounding social environment. Creativity 
requires a confluence of all components. High creativity will result when an 
individual is: intrinsically motivated, possesses both a high level of domain-
relevant skills and has high skills in creative thinking, and is working in a 
highly creative environment.
Amusement Park Theoretical Model.[80] In this 4-step theory, both domain-
specific and generalist views are integrated into a model of creativity. The 
researchers make use of the metaphor of the amusement park to 
demonstrate that within each of these creative levels, intelligence plays a 
key role:
To get into the amusement park, there are initial requirements (e.g., 
time/transport to go to the park). Initial requirements (like intelligence) are 
necessary, but not sufficient for creativity. They are more like prerequisites 
for creativity, and if an individual does not possess the basic level of the 
initial requirement (intelligence), then they will not be able to generate 
creative thoughts/behaviour.
Secondly are the subcomponents   general thematic areas   that increase in 
specificity. Like choosing which type of amusement park to visit (e.g. a zoo or 
a water park), these areas relate to the areas in which someone could be 
creative (e.g. poetry).
Thirdly there are specific domains. After choosing the type of park to visit 
e.g. waterpark, you then have to choose which specific park to go to. Within 
the poetry domain, there are many different types (e.g. free verse, riddles, 
sonnet, etc.) that have to be selected from.
Lastly, there are micro-domains. These are the specific tasks that reside 
within each domain e.g. individual lines in a free verse poem / individual 
rides at the waterpark.
Creativity and intelligence as overlapping yet distinct constructs[edit]
This possible relationship concerns creativity and intelligence as distinct, but 
intersecting constructs.

Theories that include Creativity and Intelligence as Overlapping Yet Distinct 
Constructs

Renzulli s Three-Ring Conception of Giftedness.[81] In this 
conceptualisation, giftedness occurs as a result from the overlap of above 
average intellectual ability, creativity, and task commitment. Under this view, 
creativity and intelligence are distinct constructs, but they do overlap under 
the correct conditions.
PASS theory of intelligence. In this theory, the planning component   relating 
to the ability to solve problems, make decisions and take action   strongly 
overlaps with the concept of creativity.[82]
Threshold Theory (TT). A number of previous research findings have 
suggested that a threshold exists in the relationship between creativity and 
intelligence   both constructs are moderately positively correlated up to an IQ 
of ~120. Above this threshold of an IQ of 120, if there is a relationship at all, 
it is small and weak.[62][63][83] TT posits that a moderate level of 
intelligence is necessary for creativity.
In support of the TT, Barron [63][84] reported finding a non-significant 
correlation between creativity and intelligence in a gifted sample; and a 
significant correlation in a non-gifted sample. Yamamoto[85] in a sample of 
secondary school children, reported a significant correlation between 
creativity and intelligence of r = .3, and reported no significant correlation 
when the sample consisted of gifted children. Fuchs-Beauchamp et al.[86] 
in a sample of preschoolers found that creativity and intelligence correlated 
from r = .19 to r = .49 in the group of children who had an IQ below the 
threshold; and in the group above the threshold, the correlations were r = 
<.12. Cho et al.[87] reported a correlation of .40 between creativity and 
intelligence in the average IQ group of a sample of adolescents and adults; 
and a correlation of close to r = .0 for the high IQ group. Jauk et al.[88] 
found support for the TT, but only for measures of creative potential; not 
creative performance.

Much modern day research reports findings against TT. Wai et al.[89] in a 
study using data from the longitudinal Study of Mathematically Precocious 
Youth   a cohort of elite students from early adolescence into adulthood   
found that differences in SAT scores at age 13 were predictive of creative 
real-life outcomes 20 years later. Kim s[90] meta-analysis of 21 studies did 
not find any supporting evidence for TT, and instead negligible correlations 
were reported between intelligence, creativity, and divergent thinking both 
below and above IQ's of 120. Preckel et al.,[91] investigating fluid 
intelligence and creativity, reported small correlations of r = .3 to r = .4 
across all levels of cognitive ability.

Creativity and intelligence as coincident sets[edit]
Under this view, researchers posit that there are no differences in the 
mechanisms underlying creativity in those used in normal problem solving; 
and in normal problem solving, there is no need for creativity. Thus, creativity 
and Intelligence (problem solving) are the same thing. Perkins[92] referred 
to this as the nothing-special  view.

Weisberg & Alba[93] examined problem solving by having participants 
complete the 9-dot problem (see Thinking outside the box#Nine dots puzzle) 
  where the participants are asked to connect all 9 dots in the 3 rows of 3 
dots using 4 straight lines or less, without lifting their pen or tracing the 
same line twice. The problem can only be solved if the lines go outside the 
boundaries of the square of dots. Results demonstrated that even when 
participants were given this insight, they still found it difficult to solve the 
problem, thus showing that to successfully complete the task it is not just 
insight (or creativity) that is required.

Creativity and intelligence as disjoint sets[edit]
In this view, creativity and intelligence are completely different, unrelated 
constructs.

Getzels and Jackson[62] administered 5 creativity measures to a group of 
449 children from grades 6-12, and compared these test findings to results 
from previously administered (by the school) IQ tests. They found that the 
correlation between the creativity measures and IQ was r = .26. The high 
creativity group scored in the top 20% of the overall creativity measures, but 
were not included in the top 20% of IQ scorers. The high intelligence group 
scored the opposite: they scored in the top 20% for IQ, but were outside the 
top 20% scorers for creativity, thus showing that creativity and intelligence 
are distinct and unrelated.

However, this work has been heavily criticised. Wallach and Kogan[64] 
highlighted that the creativity measures were not only weakly related to one 
another (to the extent that they were no more related to one another than 
they were with IQ), but they seemed to also draw upon non-creative skills. 
McNemar[94] noted that there were major measurement issues, in that the 
IQ scores were a mixture from 3 different IQ tests.

Wallach and Kogan[64] administered 5 measures of creativity, each of which 
resulted in a score for originality and fluency; and 10 measures of general 
intelligence to 151 5th grade children. These tests were untimed, and given 
in a game-like manner (aiming to facilitate creativity). Inter-correlations 
between creativity tests were on average r = .41. Inter-correlations between 
intelligence measures were on average r = .51 with each other. Creativity 
tests and intelligence measures correlated r = .09.

Neuroscience[edit]
The neuroscience of creativity looks at the operation of the brain during 
creative behaviour. It has been addressed[95] in the article "Creative 
Innovation: Possible Brain Mechanisms." The authors write that "creative 
innovation might require coactivation and communication between regions of 
the brain that ordinarily are not strongly connected." Highly creative people 
who excel at creative innovation tend to differ from others in three ways:

they have a high level of specialized knowledge,
they are capable of divergent thinking mediated by the frontal lobe.
and they are able to modulate neurotransmitters such as norepinephrine in 
their frontal lobe.
Thus, the frontal lobe appears to be the part of the cortex that is most 
important for creativity.

This article also explored the links between creativity and sleep, mood and 
addiction disorders, and depression.

In 2005, Alice Flaherty presented a three-factor model of the creative drive. 
Drawing from evidence in brain imaging, drug studies and lesion analysis, 
she described the creative drive as resulting from an interaction of the frontal 
lobes, the temporal lobes, and dopamine from the limbic system. The frontal 
lobes can be seen as responsible for idea generation, and the temporal 
lobes for idea editing and evaluation. Abnormalities in the frontal lobe (such 
as depression or anxiety) generally decrease creativity, while abnormalities in 
the temporal lobe often increase creativity. High activity in the temporal lobe 
typically inhibits activity in the frontal lobe, and vice versa. High dopamine 
levels increase general arousal and goal directed behaviors and reduce 
latent inhibition, and all three effects increase the drive to generate ideas.
[96] A 2015 study on creativity found that it involves the interaction of 
multiple neural networks, including the those that support associative 
thinking, along with other default mode network functions.[97]

Working memory and the cerebellum[edit]
Vandervert[98] described how the brain's frontal lobes and the cognitive 
functions of the cerebellum collaborate to produce creativity and innovation. 
Vandervert's explanation rests on considerable evidence that all processes of 
working memory (responsible for processing all thought[99]) are adaptively 
modeled for increased efficiency by the cerebellum.[100] The cerebellum 
(consisting of 100 billion neurons, which is more than the entirety of the rest 
of the brain[101]) is also widely known to adaptively model all bodily 
movement for efficiency. The cerebellum's adaptive models of working 
memory processing are then fed back to especially frontal lobe working 
memory control processes[102] where creative and innovative thoughts 
arise.[103] (Apparently, creative insight or the "aha" experience is then 
triggered in the temporal lobe.[104])

According to Vandervert, the details of creative adaptation begin in "forward" 
cerebellar models which are anticipatory/exploratory controls for movement 
and thought. These cerebellar processing and control architectures have 
been termed Hierarchical Modular Selection and Identification for Control 
(HMOSAIC).[105] New, hierarchically arranged levels of the cerebellar 
control architecture (HMOSAIC) develop as mental mulling in working 
memory is extended over time. These new levels of the control architecture 
are fed forward to the frontal lobes. Since the cerebellum adaptively models 
all movement and all levels of thought and emotion,[106] Vandervert's 
approach helps explain creativity and innovation in sports, art, music, the 
design of video games, technology, mathematics, the child prodigy, and 
thought in general.

Essentially, Vandervert has argued that when a person is confronted with a 
challenging new situation, visual-spatial working memory and speech-
related working memory are decomposed and re-composed (fractionated) by 
the cerebellum and then blended in the cerebral cortex in an attempt to deal 
with the new situation. With repeated attempts to deal with challenging 
situations, the cerebro-cerebellar blending process continues to optimize the 
efficiency of how working memory deals with the situation or problem.[107] 
Most recently, he has argued that this is the same process (only involving 
visual-spatial working memory and pre-language vocalization) that led to the 
evolution of language in humans.[108] Vandervert and Vandervert-Weathers 
have pointed out that this blending process, because it continuously 
optimizes efficiencies, constantly improves prototyping attempts toward the 
invention or innovation of new ideas, music, art, or technology.[109] 
Prototyping, they argue, not only produces new products, it trains the 
cerebro-cerebellar pathways involved to become more efficient at prototyping 
itself. Further, Vandervert and Vandervert-Weathers believe that this 
repetitive "mental prototyping" or mental rehearsal involving the cerebellum 
and the cerebral cortex explains the success of the self-driven, individualized 
patterning of repetitions initiated by the teaching methods of the Khan 
Academy. The model proposed by Vandervert has however received incisive 
critique from several authors.[110][111]

REM sleep[edit]
Creativity involves the forming of associative elements into new combinations 
that are useful or meet some requirement. Sleep aids this process.[112] 
REM rather than NREM sleep appears to be responsible.[113][114] This has 
been suggested to be due to changes in cholinergic and noradrenergic 
neuromodulation that occurs during REM sleep.[113] During this period of 
sleep, high levels of acetylcholine in the hippocampus suppress feedback 
from the hippocampus to the neocortex, and lower levels of acetylcholine 
and norepinephrine in the neocortex encourage the spread of associational 
activity within neocortical areas without control from the hippocampus.[115] 
This is in contrast to waking consciousness, where higher levels of 
norepinephrine and acetylcholine inhibit recurrent connections in the 
neocortex. It is proposed that REM sleep adds creativity by allowing 
"neocortical structures to reorganize associative hierarchies, in which 
information from the hippocampus would be reinterpreted in relation to 
previous semantic representations or nodes."[113]

Affect[edit]
Some theories suggest that creativity may be particularly susceptible to 
affective influence. As noted in voting behavior the term "affect" in this 
context can refer to liking or disliking key aspects of the subject in question. 
This work largely follows from findings in psychology regarding the ways in 
which affective states are involved in human judgment and decision-making.
[116]

Positive affect relations[edit]
According to Alice Isen, positive affect has three primary effects on cognitive 
activity:

Positive affect makes additional cognitive material available for processing, 
increasing the number of cognitive elements available for association;
Positive affect leads to defocused attention and a more complex cognitive 
context, increasing the breadth of those elements that are treated as 
relevant to the problem;
Positive affect increases cognitive flexibility, increasing the probability that 
diverse cognitive elements will in fact become associated. Together, these 
processes lead positive affect to have a positive influence on creativity.
Barbara Fredrickson in her broaden-and-build model suggests that positive 
emotions such as joy and love broaden a person's available repertoire of 
cognitions and actions, thus enhancing creativity.

According to these researchers, positive emotions increase the number of 
cognitive elements available for association (attention scope) and the 
number of elements that are relevant to the problem (cognitive scope).

Various meta-analyses, such as Baas et al. (2008) of 66 studies about 
creativity and affect support the link between creativity and positive affect
[117][118]

Creativity and artificial intelligence[edit]
J rgen Schmidhuber's formal theory of creativity[119][120] postulates that 
creativity, curiosity and interestingness are by-products of a simple 
computational principle for measuring and optimizing learning progress. 
Consider an agent able to manipulate its environment and thus its own 
sensory inputs. The agent can use a black box optimization method such as 
reinforcement learning to learn (through informed trial and error) sequences 
of actions that maximize the expected sum of its future reward signals. There 
are extrinsic reward signals for achieving externally given goals, such as 
finding food when hungry. But Schmidhuber's objective function to be 
maximized also includes an additional, intrinsic term to model "wow-effects." 
This non-standard term motivates purely creative behavior of the agent even 
when there are no external goals. A wow-effect is formally defined as follows. 
As the agent is creating and predicting and encoding the continually 
growing history of actions and sensory inputs, it keeps improving the 
predictor or encoder, which can be implemented as an artificial neural 
network or some other machine learning device that can exploit regularities 
in the data to improve its performance over time. The improvements can be 
measured precisely, by computing the difference in computational costs 
(storage size, number of required synapses, errors, time) needed to encode 
new observations before and after learning. This difference depends on the 
encoder's present subjective knowledge, which changes over time, but the 
theory formally takes this into account. The cost difference measures the 
strength of the present "wow-effect" due to sudden improvements in data 
compression or computational speed. It becomes an intrinsic reward signal 
for the action selector. The objective function thus motivates the action 
optimizer to create action sequences causing more wow-effects. Irregular, 
random data (or noise) do not permit any wow-effects or learning progress, 
and thus are "boring" by nature (providing no reward). Already known and 
predictable regularities also are boring. Temporarily interesting are only the 
initially unknown, novel, regular patterns in both actions and observations. 
This motivates the agent to perform continual, open-ended, active, creative 
exploration.

According to Schmidhuber, his objective function explains the activities of 
scientists, artists and comedians.[121][122] For example, physicists are 
motivated to create experiments leading to observations obeying previously 
unpublished physical laws permitting better data compression. Likewise, 
composers receive intrinsic reward for creating non-arbitrary melodies with 
unexpected but regular harmonies that permit wow-effects through data 
compression improvements. Similarly, a comedian gets intrinsic reward for 
"inventing a novel joke with an unexpected punch line, related to the 
beginning of the story in an initially unexpected but quickly learnable way 
that also allows for better compression of the perceived data."[123] 
Schmidhuber argues that that ongoing computer hardware advances will 
greatly scale up rudimentary artificial scientists and artists[clarification 
needed] based on simple implementations of the basic principle since 1990.
[124] He used the theory to create low-complexity art[125] and an attractive 
human face.[126]

Mental health[edit]
Main article: Creativity and mental illness
A study by psychologist J. Philippe Rushton found creativity to correlate with 
intelligence and psychoticism.[127] Another study found creativity to be 
greater in schizotypal than in either normal or schizophrenic individuals. 
While divergent thinking was associated with bilateral activation of the 
prefrontal cortex, schizotypal individuals were found to have much greater 
activation of their right prefrontal cortex.[128] This study hypothesizes that 
such individuals are better at accessing both hemispheres, allowing them to 
make novel associations at a faster rate. In agreement with this hypothesis, 
ambidexterity is also associated with schizotypal and schizophrenic 
individuals. Three recent studies by Mark Batey and Adrian Furnham have 
demonstrated the relationships between schizotypal[129][130] and 
hypomanic personality [131] and several different measures of creativity.

Particularly strong links have been identified between creativity and mood 
disorders, particularly manic-depressive disorder (a.k.a. bipolar disorder) and 
depressive disorder (a.k.a. unipolar disorder). In Touched with Fire: Manic-
Depressive Illness and the Artistic Temperament, Kay Redfield Jamison 
summarizes studies of mood-disorder rates in writers, poets and artists. She 
also explores research that identifies mood disorders in such famous writers 
and artists as Ernest Hemingway (who shot himself after electroconvulsive 
treatment), Virginia Woolf (who drowned herself when she felt a depressive 
episode coming on), composer Robert Schumann (who died in a mental 
institution), and even the famed visual artist Michelangelo.

A study looking at 300,000 persons with schizophrenia, bipolar disorder or 
unipolar depression, and their relatives, found overrepresentation in creative 
professions for those with bipolar disorder as well as for undiagnosed 
siblings of those with schizophrenia or bipolar disorder. There was no overall 
overrepresentation, but overrepresentation for artistic occupations, among 
those diagnosed with schizophrenia. There was no association for those with 
unipolar depression or their relatives. [132]

Another study involving more than one million people, conducted by 
Swedish researchers at the Karolinska Institute, reported a number of 
correlations between creative occupations and mental illnesses. Writers had 
a higher risk of anxiety and bipolar disorders, schizophrenia, unipolar 
depression, and substance abuse, and were almost twice as likely as the 
general population to kill themselves. Dancers and photographers were also 
more likely to have bipolar disorder.[133]

However, as a group, those in the creative professions were no more likely to 
suffer from psychiatric disorders than other people, although they were more 
likely to have a close relative with a disorder, including anorexia and, to 
some extent, autism, the Journal of Psychiatric Research reports.[133]

According to psychologist Robert Epstein, PhD, creativity can be obstructed 
through stress.[134]

Creativity and personality[edit]
Creativity can be expressed in a number of different forms, depending on 
unique people and environments. A number of different theorists have 
suggested models of the creative person. One model suggests that there 
are kinds to produce growth, innovation, speed, etc. These are referred to as 
the four "Creativity Profiles" that can help achieve such goals.[135]

(i) Incubate (Long-term Development)
(ii) Imagine (Breakthrough Ideas)
(iii) Improve (Incremental Adjustments)
(iv) Invest (Short-term Goals)
Research by Dr Mark Batey of the Psychometrics at Work Research Group 
at Manchester Business School has suggested that the creative profile can 
be explained by four primary creativity traits with narrow facets within each

(i) "Idea Generation" (Fluency, Originality, Incubation and Illumination)
(ii) "Personality" (Curiosity and Tolerance for Ambiguity)
(iii) "Motivation" (Intrinsic, Extrinsic and Achievement)
(iv) "Confidence" (Producing, Sharing and Implementing)
This model was developed in a sample of 1000 working adults using the 
statistical techniques of Exploratory Factor Analysis followed by Confirmatory 
Factor Analysis by Structural Equation Modelling.[136]

An important aspect of the creativity profiling approach is to account for the 
tension between predicting the creative profile of an individual, as 
characterised by the psychometric approach, and the evidence that team 
creativity is founded on diversity and difference.[137]

One characteristic of creative people, as measured by some psychologists, 
is what is called divergent production. divergent production is the ability of a 
person to generate a diverse assortment, yet an appropriate amount of 
responses to a given situation.[138] One way of measuring divergent 
production is by administering the Torrance Tests of Creative Thinking.[139] 
The Torrance Tests of Creative Thinking assesses the diversity, quantity, and 
appropriateness of participants responses to a variety of open-ended 
questions.

Other researchers of creativity see the difference in creative people as a 
cognitive process of dedication to problem solving and developing expertise 
in the field of their creative expression. Hard working people study the work 
of people before them and within their current area, become experts in their 
fields, and then have the ability to add to and build upon previous 
information in innovative and creative ways. In a study of projects by design 
students, students who had more knowledge on their subject on average 
had greater creativity within their projects.[140]

The aspect of motivation within a person's personality may predict creativity 
levels in the person. Motivation stems from two different sources, intrinsic 
and extrinsic motivation. Intrinsic motivation is an internal drive within a 
person to participate or invest as a result of personal interest, desires, 
hopes, goals, etc. Extrinsic motivation is a drive from outside of a person and 
might take the form of payment, rewards, fame, approval from others, etc. 
Although extrinsic motivation and intrinsic motivation can both increase 
creativity in certain cases, strictly extrinsic motivation often impedes creativity 
in people.[141]

From a personality-traits perspective, there are a number of traits that are 
associated with creativity in people.[142] Creative people tend to be more 
open to new experiences, are more self-confident, are more ambitious, self-
accepting, impulsive, driven, dominant, and hostile, compared to people with 
less creativity.

From an evolutionary perspective, creativity may be a result of the outcome 
of years of generating ideas. As ideas are continuously generated, the need 
to evolve produces a need for new ideas and developments. As a result, 
people have been creating and developing new, innovative, and creative 
ideas to build our progress as a society.[143]

In studying exceptionally creative people in history, some common traits in 
lifestyle and environment are often found. Creative people in history usually 
had supportive parents, but rigid and non-nurturing. Most had an interest in 
their field at an early age, and most had a highly supportive and skilled 
mentor in their field of interest. Often the field they chose was relatively 
uncharted, allowing for their creativity to be expressed more in a field with 
less previous information. Most exceptionally creative people devoted almost 
all of their time and energy into their craft, and after about a decade had a 
creative breakthrough of fame. Their lives were marked with extreme 
dedication and a cycle of hard-work and breakthroughs as a result of their 
determination [144]

Another theory of creative people is the investment theory of creativity. This 
approach suggest that there are many individual and environmental factors 
that must exist in precise ways for extremely high levels of creativity opposed 
to average levels of creativity. In the investment sense, a person with their 
particular characteristics in their particular environment may see an 
opportunity to devote their time and energy into something that has been 
overlooked by others. The creative person develops an undervalued or 
under-recognised idea to the point that it is established as a new and 
creative idea. Just like in the financial world, some investments are worth the 
buy in, while others are less productive and do not build to the extent that 
the investor expected. This investment theory of creativity views creativity in a 
unique perspective compared to others, by asserting that creativity might 
rely to some extent on the right investment of effort being added to a field at 
the right time in the right way.[145]

Creativity across cultures[edit]
Creativity is viewed differently in different countries.[146] For example, 
cross-cultural research centred on Hong Kong found that Westerners view 
creativity more in terms of the individual attributes of a creative person, such 
as their aesthetic taste, while Chinese people view creativity more in terms of 
the social influence of creative people e.g. what they can contribute to 
society.[147] Mpofu et al. surveyed 28 African languages and found that 27 
had no word which directly translated to 'creativity' (the exception being 
Arabic).[148] The principle of linguistic relativity, i.e. that language can affect 
thought, suggests that the lack of an equivalent word for 'creativity' may 
affect the views of creativity among speakers of such languages. However, 
more research would be needed to establish this, and there is certainly no 
suggestion that this linguistic difference makes people any less (or more) 
creative; Africa has a rich heritage of creative pursuits such as music, art, 
and storytelling. Nevertheless, it is true that there has been very little 
research on creativity in Africa,[149] and there has also been very little 
research on creativity in Latin America.[150] Creativity has been more 
thoroughly researched in the northern hemisphere, but here again there are 
cultural differences, even between countries or groups of countries in close 
proximity. For example, in Scandinavian countries, creativity is seen as an 
individual attitude which helps in coping with life's challenges,[151] while in 
Germany, creativity is seen more as a process that can be applied to help 
solve problems.[152]

In organizations[edit]

Training meeting in an eco-design stainless steel company in Brazil. The 
leaders among other things wish to cheer and encourage the workers in 
order to achieve a higher level of creativity.
It has been the topic of various research studies to establish that 
organizational effectiveness depends on the creativity of the workforce to a 
large extent. For any given organization, measures of effectiveness vary, 
depending upon its mission, environmental context, nature of work, the 
product or service it produces, and customer demands. Thus, the first step 
in evaluating organizational effectiveness is to understand the organization 
itself   how it functions, how it is structured, and what it emphasizes.

Amabile[153] argued that to enhance creativity in business, three 
components were needed:

Expertise (technical, procedural and intellectual knowledge),
Creative thinking skills (how flexibly and imaginatively people approach 
problems),
and Motivation (especially intrinsic motivation).
There are two types of motivation:

extrinsic motivation   external factors, for example threats of being fired or 
money as a reward,
intrinsic motivation   comes from inside an individual, satisfaction, enjoyment 
of work etc.
Six managerial practices to encourage motivation are:

Challenge   matching people with the right assignments;
Freedom   giving people autonomy choosing means to achieve goals;
Resources   such as time, money, space etc. There must be balance fit 
among resources and people;
Work group features   diverse, supportive teams, where members share the 
excitement, willingness to help and recognize each other's talents;
Supervisory encouragement   recognitions, cheering, praising;
Organizational support   value emphasis, information sharing, collaboration.
Nonaka, who examined several successful Japanese companies, similarly 
saw creativity and knowledge creation as being important t
o the success of organizations.[154] In particular, he emphasized the role 
that tacit knowledge has to play in the creative process.

In business, originality is not enough. The idea must also be appropriate 
useful and actionable.[155][156] Creative competitive intelligence is a new 
solution to solve this problem. According to Reijo Siltala it links creativity to 
innovation process and competitive intelligence to creative workers.

Creativity can be encouraged in people and professionals and in the 
workplace. It is essential for innovation, and is a factor affecting economic 
growth and businesses. In 2013 the sociologist Silvia Leal Mart n, using the 
Innova 3DX method, suggested measuring the various parameters that 
encourage creativity and innovation: corporate culture, work environment, 
leadership and management, creativity, self-esteem and optimism, locus of 
control and learning orientation, motivation and fear.[157]

Economic views of creativity[edit]
Economic approaches to creativity have focussed on three aspects   the 
impact of creativity on economic growth, methods of modelling markets for 
creativity, and the maximisation of economic creativity (innovation).

In the early 20th century, Joseph Schumpeter introduced the economic 
theory of creative destruction, to describe the way in which old ways of doing 
things are endogenously destroyed and replaced by the new. Some 
economists (such as Paul Romer) view creativity as an important element in 
the recombination of elements to produce new technologies and products 
and, consequently, economic growth. Creativity leads to capital, and creative 
products are protected by intellectual property laws.

Mark A. Runco and Daniel Rubenson have tried to describe a 
"psychoeconomic" model of creativity.[158] In such a model, creativity is the 
product of endowments and active investments in creativity; the costs and 
benefits of bringing creative activity to market determine the supply of 
creativity. Such an approach has been criticised for its view of creativity 
consumption as always having positive utility, and for the way it analyses the 
value of future innovations.[159]

The creative class is seen by some to be an important driver of modern 
economies. In his 2002 book, The Rise of the Creative Class, economist 
Richard Florida popularized the notion that regions with "3 T's of economic 
development: Technology, Talent and Tolerance" also have high 
concentrations of creative professionals and tend to have a higher level of 
economic development.

Fostering creativity[edit]
Main article: Creativity techniques
Daniel Pink, in his 2005 book A Whole New Mind, repeating arguments 
posed throughout the 20th century, argues that we are entering a new age 
where creativity is becoming increasingly important. In this conceptual age, 
we will need to foster and encourage right-directed thinking (representing 
creativity and emotion) over left-directed thinking (representing logical, 
analytical thought). However, this simplification of 'right' versus 'left' brain 
thinking is not supported by the research data.[160]

Nickerson[161] provides a summary of the various creativity techniques that 
have been proposed. These include approaches that have been developed 
by both academia and industry:

Establishing purpose and intention
Building basic skills
Encouraging acquisitions of domain-specific knowledge
Stimulating and rewarding curiosity and exploration
Building motivation, especially internal motivation
Encouraging confidence and a willingness to take risks
Focusing on mastery and self-competition
Promoting supportable beliefs about creativity
Providing opportunities for choice and discovery
Developing self-management (metacognitive skills)
Teaching techniques and strategies for facilitating creative performance
Providing balance
Some see the conventional system of schooling as "stifling" of creativity and 
attempt (particularly in the pre-school/kindergarten and early school years) 
to provide a creativity-friendly, rich, imagination-fostering environment for 
young children.[161][162][163] Researchers have seen this as important 
because technology is advancing our society at an unprecedented rate and 
creative problem solving will be needed to cope with these challenges as 
they arise.[163] In addition to helping with problem solving, creativity also 
helps students identify problems where others have failed to do so.[161]
[162][164] See the Waldorf School as an example of an education program 
that promotes creative thought.

Promoting intrinsic motivation and problem solving are two areas where 
educators can foster creativity in students. Students are more creative when 
they see a task as intrinsically motivating, valued for its own sake.[162][163]
[165][166] To promote creative thinking educators need to identify what 
motivates their students and structure teaching around it. Providing students 
with a choice of activities to complete allows them to become more 
intrinsically motivated and therefore creative in completing the tasks.[161]
[167]

Teaching students to solve problems that do not have well defined answers 
is another way to foster their creativity. This is accomplished by allowing 
students to explore problems and redefine them, possibly drawing on 
knowledge that at first may seem unrelated to the problem in order to solve 
it.[161][162][163][165]

Several different researchers have proposed methods of increasing the 
creativity of an individual. Such ideas range from the psychological-cognitive, 
such as Osborn-Parnes Creative Problem Solving Process, Synectics, 
Science-based creative thinking, Purdue Creative Thinking Program, and 
Edward de Bono's lateral thinking; to the highly structured, such as TRIZ 
(the Theory of Inventive Problem-Solving) and its variant Algorithm of 
Inventive Problem Solving (developed by the Russian scientist Genrich 
Altshuller), and Computer-Aided Morphological analysis.

Creativity has also been identified as one of the key 21st century skills and 
as one of the Four Cs of 21st century learning by educational leaders and 
theorists in the United States.

See also[edit]

Music therapy is the use of interventions to accomplish individual goals 
within a therapeutic relationship by a professional who has completed an 
approved music therapy program.[1] Music therapy is an allied health 
profession and one of the expressive therapies, consisting of a process in 
which a music therapist uses music and all of its facets physical, emotional, 
mental, social, aesthetic, and spiritual to help clients improve their physical 
and mental health. Music therapists primarily help clients improve their 
health in several domains, such as cognitive functioning, motor skills, 
emotional development, social skills, and quality of life, by using music 
experiences such as free improvisation, singing, and listening to, discussing, 
and moving to music to achieve treatment goals. It has a wide qualitative and 
quantitative research literature base and incorporates clinical therapy, 
psychotherapy, biomusicology, musical acoustics, music theory, 
psychoacoustics, embodied music cognition, aesthetics of music, sensory 
integration, and comparative musicology. Referrals to music therapy services 
may be made by other health care professionals such as physicians, 
psychologists, physical therapists, and occupational therapists. Clients can 
also choose to pursue music therapy services without a referral (i.e., self-
referral).

Music therapists are found in nearly every area of the helping professions. 
Some commonly found practices include developmental work 
(communication, motor skills, etc.) with individuals with special needs, 
songwriting and listening in reminiscence/orientation work with the elderly, 
processing and relaxation work, and rhythmic entrainment for physical 
rehabilitation in stroke victims. Music therapy is also used in some medical 
hospitals, cancer centers, schools, alcohol and drug recovery programs, 
psychiatric hospitals, and correctional facilities.[2]

Music therapy comes in two different forms: active and receptive. In active 
therapy, the therapist and patient actively participate in creating music with 
instruments, their voice, or other objects. This allows for the patient to be 
creative and expressive through the art of music. Receptive therapy takes 
place in a more relaxed setting where the therapist plays or makes music to 
the patient who is free to draw, listen or meditate. Usually the therapist 
determines the method unless specifically requested by the patient.[3]
Approaches[edit]

A music therapist from a "Blues in the Schools" program plays harmonica 
with a US Navy sailor at a Naval Therapy Center.
Approaches used in music therapy that have emerged from the field of 
education include Orff-Schulwerk (Orff), Dalcroze Eurhythmics, and Kodaly. 
Models that developed directly out of music therapy are Neurologic Music 
Therapy (NMT), Nordoff-Robbins and the Bonny Method of Guided Imagery 
and Music.[4]

Music therapists may work with individuals who have behavioral-emotional 
disorders.[5] To meet the needs of this population, music therapists have 
taken current psychological theories and used them as a basis for different 
types of music therapy. Different models include behavioral therapy, 
cognitive behavioral therapy, and psychodynamic therapy.[6]

One therapy model based on neuroscience, called "neurological music 
therapy" (NMT), is "based on a neuroscience model of music perception and 
production, and the influence of music on functional changes in non-musical 
brain and behavior functions."[7] In other words, NMT studies how the brain 
is without music, how the brain is with music, measures the differences, and 
uses these differences to cause changes in the brain through music that will 
eventually affect the client non-musically. As one researcher, Dr. Thaut, said: 
"The brain that engages in music is changed by engaging in music."[8] NMT 
trains motor responses (i.e. tapping foot or fingers, head movement, etc.) to 
better help clients develop motor skills that help "entrain the timing of 
muscle activation patterns".[9]

Children[edit]
Music therapy approaches used with children[edit]
Nordoff-Robbins[edit]
Further information: Nordoff-Robbins music therapy
Paul Nordoff, a Juilliard School graduate and Professor of Music, was a 
gifted pianist and composer who, upon seeing disabled children respond so 
positively to music, gave up his academic career to further investigate the 
possibility of music as a means for therapy. Dr. Clive Robbins, a special 
educator, partnered with Nordoff for over 17 years in the exploration and 
research of music s effects on disabled children first in the United Kingdom, 
and then in the USA in the 1950s and 60s. Their pilot projects included 
placements at care units for autistic children and child psychiatry 
departments, where they put programs in place for children with mental 
disorders, emotional disturbances, developmental delays, and other 
handicaps. Their success at establishing a means of communication and 
relationship with autistic children at the University of Pennsylvania gave rise 
to the National Institutes of Health s first grant given of this nature, and the 
5-year study  Music Therapy Project for Psychotic Children Under Seven at 
the Day Care Unit  involved research, publication, training and treatment.[10] 
Several publications, including Therapy in Music for Handicapped Children, 
Creative Music Therapy, Music Therapy in Special Education, as well as 
instrumental and song books for children, were released during this time. 
Nordoff and Robbins s success became known globally in the mental health 
community, and they were invited to share their findings and offer training on 
an international tour that lasted several years. Funds were granted to 
support the founding of the Nordoff Robbins Music Therapy Centre in Great 
Britain in 1974, where a one-year Graduate program for students was 
implemented. In the early eighties, a center was opened in Australia, and 
various programs and institutes for Music Therapy were founded in Germany 
and other countries. In the United States, the Nordoff-Robbins Center for 
Music Therapy was established at New York University in 1989.

The Nordoff-Robbins approach, based on the belief that everyone is capable 
of finding meaning in and benefitting from musical experience, is now 
practiced by hundreds of therapists internationally. It focuses on treatment 
through the creation of music by both therapist and client together. Various 
techniques are used to accommodate all capabilities so that even the most 
low functioning individuals are able to participate actively.[11]

Orff Music Therapy[edit]
Further information: Orff Schulwerk
Developed by Gertrude Orff at the Kindezentrum M nchen, is another 
approach known as Orff Music Therapy. Both the clinical setting of social 
pediatrics as well as the Orff Schulwerk (Schoolwork) approach in music 
education (developed by German composer Carl Orff) influence this method, 
which is used with children with developmental problems, delays and 
disabilities.[12] The area of social pediatrics was developed after the Second 
World War in Germany by Theodor Hellbr gge, who understood that 
medicine alone could not meet the complex needs of developmentally 
disabled children. He consulted psychologists, occupational therapists and 
other mental healthcare professionals whose knowledge and skills could aid 
in the diagnostics and treatment of children. Gertrude Orff was asked to 
develop a form of therapy based on the Orff Schulwerk approach to support 
the emotional development of patients. Elements found in both the music 
therapy and education approaches include the understanding of holistic 
music presentation as involving word, sound and movement; the use of both 
music and play improvisation as providing a creative stimulus for the child to 
investigate and explore; Orff instrumentation, including keyboard 
instruments and percussion instruments as a means of participation and 
interaction in a therapeutic setting; and lastly, the multisensory aspects of 
music used by the therapist to meet the particular needs of the child, such 
as both feeling and hearing sound.[12]

Corresponding with the attitudes of Humanistic psychology, the 
developmental potential of the child- as in the acknowledgement of their 
strengths as well as their handicaps, and the importance of the therapist- 
child relationship are central factors in Orff Music Therapy. Theoretical 
foundations are also influenced by the strong emphasis on social integration 
and the involvement of parents in the therapeutic process found in social 
paediatrics. Knowledge of developmental psychology puts into perspective 
how developmental disabilities influence the child, as do their social and 
familial environments. The basis for interaction in this method is known as 
responsive interaction, in which the therapist meets the child at their level 
and responds according to their initiatives, combining both humanistic and 
developmental psychology philosophies. Involving the parents in this type of 
interaction, by having them participate directly or observe the therapist's 
techniques, equips the parents with ideas of how to interact appropriately 
with their child, thus fostering a positive parent-child relationship.[12]

Bonny Method of Guided Imagery in Music (GIM)[edit]
Further information: Guided imagery
Music educator and therapist Helen Lindquist Bonny (1921 - May 25, 2010) 
developed an approach influenced by humanistic and transpersonal 
psychological views, known as the Bonny Method of Guided Imagery in 
Music, or GIM. Guided imagery refers to a technique used in natural and 
alternative medicine that involves using mental imagery to help with the 
physiological and psychological ailments of patients.[13] The practitioner 
often suggests a relaxing and focusing image and through the use of 
imagination and discussion, aims to find constructive solutions to manage 
their problems. Bonny applied this psychotherapeutic method to the field of 
music therapy by using music as the means of guiding the patient to a 
higher state of consciousness where healing and constructive self- 
awareness can take place. Music is considered a "co-therapist" because of 
its importance. GIM with children can be used in one-on-one or group 
settings, and involves relaxation techniques, identification and sharing of 
personal feeling states, and improvisation to discover the self, and foster 
growth. The choice of music is carefully selected for the client based on their 
musical preferences and the goals of the session. Usually a classical piece, 
it must reflect the age and attentional abilities of the child in length and 
genre, and a full explanation of the exercises must be offered at their level of 
understanding.[13]

The use of guided imagery with autistic children has been found to decrease 
stereotypical behaviours and hyperactivity, increase attention and the ability 
to follow instructions, as well as increase self-initiated communication, both 
verbal and non-verbal.[14]

Assessment and interventions[edit]
As with any type of therapy, the practice of Music Therapy with children must 
uphold standards of conduct and ethics, agreed upon by national and 
provincial associations such as the Canadian Association for Music Therapy. 
In part with this, formal assessment is crucial for understanding the child   
their background, limitations and needs, as well as to create appropriate 
goals for the process and select the means of achieving them. This serves 
as the starting point from which to measure the client s progression 
throughout the therapeutic process and to make adjustments later, if 
necessary. Similarly to how assessments are conducted with adults, the 
music therapist obtains extensive data on the client including their full 
medical history, musical (ability to duplicate a melody or identify changes in 
rhythm, etc.) and nonmusical functioning (social, physical/motor, emotional, 
etc.).[15] The assessment process is then carried out in formal, informal, and 
standardized ways.

The following are the most common methods of assessment:[16]

Interviews with Clients and/or Family Members
Structured or Unstructured Observation
Reviewing of Client Records
Standardized Assessment Tests
Information gathered at the music therapy assessment is then used to 
determine if music therapy is indicated for the child. The therapist then 
formulates a music therapy treatment plan, which includes specific short-
term objectives, long-term goals, and an expected timeline for therapy.[17]

Music therapy interventions used with children can fall into two categories. 
The first, Supportive active therapy, is product- oriented and can included 
rhythm activities such as body percussion (stomping feet, clapping hands, 
etc.), singing songs which re-inforce nonmusical skills, awareness and 
expression, or movement to music (as simple as marching to the beat, as 
complex as structured dances). The second area is called Insight music 
therapy which is process-oriented. Activities could include song-writing, 
active listening and reacting, or auditory discrimination activities for sensory 
skill development.[18] Music therapy for children is conducted either in a 
one-on-one session or in a group session.[19] The therapist typically plays 
either a piano or a guitar, which allows for a wide variety of musical styles to 
suit the client's preferences. The child is usually encouraged to play an 
instrument adapted to his or her unique abilities and needs.[20] These 
elements are designed to improve the experience and outcome of the 
therapy.

Prenatal music therapy[edit]
Music Therapy can play an important role during pregnancy. At just 16 
weeks, a fetus is able to hear their mother's speech as well as singing. 
Through technologies, such as ultrasound, health care professionals are 
able to observe the movements of the unborn child responding to musical 
stimuli. Through these fetal observations, we see that the baby is capable of 
expressing its needs, preferences, and interests through movements in the 
womb. At the beginning of the second trimester, the ear structure is fully 
matured. By this time, the fetus will begin to hear not only maternal sounds, 
but also vibrations of instruments.[21]

Prenatal music therapy has three main benefits.[22]

Prenatal Stress Relief: Pregnant women may experience high levels of 
stress which can negatively affect the baby. This will cause the body will 
release Norepinephrine and Cortisol hormones which will increase blood 
pressure and weaken the immune system of both mother and child.[23] High 
levels of cortisol exposure in early development can increase the likelihood 
of the child later having anxiety, mental retardation, autism, and depression.
[24] Music therapists use music to elevate the stress threshold of an 
expectant mother which helps her to maintain a relaxed state during labour 
and birthing process.[25] During a music therapy session, the mother is 
guided to listen to her internal rhythms, as well as listing to the movements 
and reactions of the fetus in response to her voice and music. This 
technique is useful in helping reduce the mother's level of stress, and 
prepare her for the birth of her child.[26]
Maternal-Fetal Bonding: Communication between the mother and fetus is 
essential during pregnancy. One way of strengthening the bond between 
the two is through music therapy. Music stimulation helps to develop the 
fetus's nervous system, structurally and functionally. The unborn child 
especially prefers the voice of their mother. The most effective way to 
enhance communication is through singing. Lullabies are the most popular 
songs sung by mothers. Singing lullabies is a wonderful way for mothers to 
express their love and have the baby become familiarized with their mother's 
melodies and intonations which will provide them a sense of security when 
they are born, because it will feel just like how they were in the womb.[27] 
Electronic voice phenomena studies have shown that the father's voice 
engages the fetus from feet to the abdomen - which will lead the baby to 
start walking at a younger age. The mother's voice engages the fetus from 
waist to head which will strengthen the baby's neck and upper limbs. Not 
only does prenatal singing benefit the fetus, it also help produce endorphins 
that automatically reduce the perception of pain and help relax breathing.
[28] A fetus can show preference for music; observations have shown the 
fetus's movements are gentle when listening to soothing music, and 
comparatively, where there are dissonances included in the music, their 
movements are bigger and much more rhythmic, such as rolling. The fetus 
would be comforted by hearing slow-pace passages of Baroque music 
(Vivaldi and Handel) and lullabies sung by their mother.[29]
Prenatal Language Development: Music is said to be the unborn child's 
beginning of language learning. It can be consider as a pre-linguistic 
language that prepares the Auditory Sensory System to listen, combine, and 
produce language sounds. The fetus learns through the voice of their 
mother, not only from speech but songs. The sound is received by the baby 
through bone conduction when the mother speaks. The singing voice is said 
to have a wider range of frequencies than speech. Prenatal sounds are 
important during the prenatal period because it forms the basis of future 
learning and behaviour.[29]
Music therapy for premature infants[edit]
Music therapy has been shown to be very beneficial in stimulating growth 
and development in premature infants.[30] Premature infants are those born 
at 37 weeks or less gestational stage. They are subject to numerous 
struggles, such as abnormal breathing patterns, decreased body fat and 
muscle tissue, as well as feeding issues. The coordination for sucking and 
breathing is often not fully developed, making feeding a challenge. The 
improved developmental activity and behavioural status of premature infants 
when they are discharged from the NICU, is directly related to the 
stimulation programs and interventions they benefited from during 
hospitalization, such as music therapy.

Music is typically conducted by a musical therapist in Neonatal Intensive 
Care (NICU), with five main techniques designed to benefit premature 
infants;[31]

Live or Recorded Music: Live or recorded music has been effective in 
promoting respiratory regularity and oxygen saturation levels, as well as 
decreasing signs of neonatal distress. Since premature infants have 
sensitive and immature sensory modalities, music is often performed in a 
gentle and control environment, either in the form of audio recordings or live 
vocalization, although live singing has been shown to have a greater affect. 
Live music also reduces the physiological responses in parents. Studies 
have shown that by combining live music, such as harp music, with the 
Kangaroo Care, maternal anxiety is reduced. This allows for parents, 
especially mothers to spend important time bonding with their premature 
infants. Female singing voices are also more affective at soothing premature 
infants. Despite being born premature, infants show a preference for the 
sound of a female singing voice, making it more beneficial than instrumental 
music.[32]
Promote Healthy Sucking Reflex: By using a Pacifier-Actived Lullaby Device, 
music therapists can help promote stronger sucking reflexes, while also 
reducing pain perception for the infant. The Gato Box is a small rectangular 
instrument that stimulates a prenatal heartbeat sound in a soft and rhythmic 
manner that has also been effective in aiding sucking behaviours.[33] The 
music therapist uses their fingers to tap on the drum, rather than using a 
mallet. The rhythm supports movement when feeding and promotes healthy 
sucking patterns. By increasing sucking patterns, babies are able to 
coordinate the important dual mechanisms of breathing, sucking and 
swallowing needed to feed, thus promoting growth and weight gain. When 
this treatment proves effective, infants are able to leave the hospital earlier.
Multimodal Stimulation and Music: By combining music, such as lullabies, 
and multimodal stimulation, premature infants were discharged from the 
NICU sooner, than those infants who did not receive therapy. Multimodal 
stimulation includes the applications of auditory, tactile, vestibular, and visual 
stimulation that helps aid in premature infant development. The combination 
of music and MMS helps premature infants sleep and conserve vital energy 
required to gain weight more rapidly. Studies have shown that girls respond 
more positively than boys during multimodal stimulation.[34] While the voice 
is a popular choice for parents looking to bond with their premature infants, 
other effective instruments include the Remo Ocean Disk and the Gato Box. 
Both are used to stimulate the sounds of the womb. The Remo Ocean Disk, 
a round musical instrument that mimics the fluid sounds of the womb, has 
been shown to benefit decreased heart rate after therapeutic uses, as well 
as promoting healthy sleep patterns, lower respiratory rates and improve 
sucking behavior.[35]
Infant Stimulation: This type of intervention uses musical stimulation to 
compensate for the lack of normal environmental sensory stimulation found 
in the NICU. The sound environment the NICU provides can be disruptive; 
however, music therapy can mask unwanted auditory stimuli and promote a 
calm environment that reduces the complications for high-risk or failure-to-
thrive infants. Parent-infant bonding can also be affected by the noise of the 
NICU, which in turn can delay the interactions between parents and their 
premature infants. But music therapy creates a relaxed and peaceful 
environment for parents to speak and spend time with their babies while 
incubated.[36]
Parent-Infant Bonding: Therapists work with parents so they may perform 
infant-directed singing techniques, as well as home care. Singing lullabies 
therapeutically can promote relaxation and decrease heart rate in premature 
infants. By calming premature babies, it allows for them to preserve their 
energy, which creates a stable environment for growth. Lullabies, such as 
"Twinkle Twinkle Little Star", or other culturally relevant lullabies, have been 
shown to greatly soothe babies. These techniques can also improve overall 
sleep quality, caloric intake and feeding behaviours, which aids in 
development of the baby while they are still in the NICU. Singing has also 
shown greater results on oxygen saturation levels for infants while 
incubated, more than mothers speech alone. This technique promoted high 
levels of oxygen for longer periods of time.[37]
Music therapy in child rehabilitation[edit]
Music therapy has multiple benefits which contribute to the maintenance of 
health and the drive toward rehabilitation for children. Advanced technology 
that can monitor cortical activity offers a look at how music engages and 
produces changes in the brain during the perception and production of 
musical stimuli. Music therapy, when used with other rehabilitation methods, 
has increased the success rate of sensorimotor, cognitive, and 
communication rehabilitation.[38] Music therapy intervention programs can 
include an average of 18 sessions of treatment. The achievement of a 
physical rehabilitation goal relies on the child's existing motivation and 
feelings towards music and their commitment to engage in meaningful, 
rewarding efforts. Regaining full functioning also confides in the prognosis of 
recovery, the condition of the client, and the environmental resources 
available. Sessions may consist of either active techniques, where the client 
creates music, or receptive techniques, where the client listens to, analyze, 
move and respond to music.[39] Both techniques use systematic processes 
where the therapists assist the client by using musical experiences and 
connections that collaborate as a dynamic force of change toward 
rehabilitation.[40] The music is at times chosen by the client, or by the music 
therapist based on the clients reciprocation to the music.[41]

Music has many calming and soothing properties that can be used as a 
sedative in rehabilitation. For example, a patient with chronic pain may 
decrease the physiological result of stress, and draw attention away from the 
pain by focusing on music.[42] Research has indicated that children 
undergoing chemotherapy reported lower scores in pain, heart rate, 
respiratory rate, and anxiety after simply listening to music during music 
therapy sessions.[43] Music has the ability to associate physiological 
changes in the body and elicit physiological responses such as pulse rate, 
respiration rate, blood pressure, and muscle tension. Music may also 
stimulate a calming effect of the cardiovascular system.[40]

Music therapy used in child rehabilitation has had a substantial emphasis on 
sensorimotor development including; balance and position, locomotion, 
agility, mobility, range of motion, strength, laterality and directionality.[42] By 
using music during senorimotor rehabilitation, it allows clients to express 
themselves and motivates them to learn the active joint range of motion and 
motor coordination in which they are aiming to acquire. For example, clients 
with a brain injury may lack the ability to initiate movement. The intensely 
captivating and attention enhancing quality of music motivates clients to 
participate in physical activity or exercise by easing the discomfort and 
strenuousness of the physical rehabilitation and helps the client persevere 
without being conscious of the difficulty. Music can be an element of 
distraction, allowing the client to transcend into a positive, aesthetically-
pleasing state that is beneficial to achieving their goals.[40] Research 
suggests a strong connection between motor activation and the cueing of 
musical rhythm. Rhythmic stimuli has been found to help balance training 
for those with a brain injury. Repetition of proficient rhythmic qualities will 
stimulate participants so that the abrasive beats will synchronize with neural 
activity during a rhythmic motor task. For example, clients with hemiplegia 
gain improvement of posture stability, and consistency of symmetrical strides 
and regularity in step lengths when listening to music with strong rhythmic 
beats.[40]

Music therapy rehabilitation sessions that incorporate active techniques 
involve the client producing the music themselves. This may include the 
client making a musical composition, or performing by singing or chanting, 
playing instruments, or musically improvising.[39] Singing is a form of 
rehabilitation for neurological impairments. Neurological impairments 
following a brain injury can be in the form of apraxia   loss to perform 
purposeful movements, dysarthria   muscle control disturbances (due to 
damage of the central nervous system), aphasia (defect in expression 
causing distorted speech), or language comprehension. Singing training has 
been found to improve lung, speech clarity, and coordination of speech 
muscles, thus, accelerating rehabilitation of such neurological impairments. 
For example, melodic intonation therapy is the practice of communicating 
with others by singing to enhance speech or increase speech production by 
promoting socialization, and emotional expression.[40]

When having the child actively participate with an instrument, it is especially 
important for the therapist to provide them with an instrument that they can 
readily and easily use. Clients with limited physical abilities may express 
frustration when they are not able to control their environment. The ability to 
employ and operate a musical instrument provides them a sense of 
relaxation and accomplishment. Instruments must be selected to provide 
immediately successful experiences. Certain adaptions of the instruments 
may be required in order for the people to manipulate them. For example, a 
drumstick's handle should be manipulated to be more prominent for those 
clients that may have a weak grip.[40] Electric music-making devices have 
been adapted to fit the clients limited but existing movements, strength, and 
abilities. Electronic devices, such as the Sound Beam and the Wave Rider- 
read a variety of small movements made by the clients and converts the 
movements into electronic musical information. The devices are programmed 
to create easy, yet pleasing notes and sounds in coordination to the 
participants  movements. It is also crucial for the client to be aware that 
music making is simply a modality for rehabilitation and that their wellness is 
not dependent on their existing musical skills. It provides children with an 
outlet of expression that they may have lacked in the past or due to present 
circumstances. By accomplishing the production of musical sounds despite 
their weaknesses and disabilities, it encourages the client and relieves their 
anxiety that they may acquire at the thought of playing musical instrument 
without experience. By using such adaptive music devices, it grants client's 
the ability to create sounds that are originally expressive and allows them to 
experience affirmation  a feeling of capability to control ones own 
environment- an ability they may not be familiar with.[40]

Music therapy and children with autism[edit]
Music therapy can be a particularly useful when working with children with 
autism due to the nonverbal, non-threatening nature of the medium.[44] 
Studies have shown that children with autism have difficulty with joint 
attention, symbolic communication and sharing of positive affect. Use of 
music therapy has demonstrated improvements of socially acceptable 
behaviors. Wan, Demaine, Zipse, Norton, & Schlaug (2010) found singing 
and music making may engage areas of the brain related to language 
abilities, and that music facilitated the language, social, and motor skills.[45] 
Successful therapy involves long-term individual intervention tailored to each 
child s needs. Passing and sharing instruments, music and movement 
games, learning to listen and singing greetings and improvised stories are 
just a few ways music therapy can improve a child s social interaction. For 
example, passing a ball back and forth to percussive music or playing sticks 
and cymbals with another person might help foster the child s ability to 
follow directions when passing the ball and learn to share the cymbals and 
sticks. In addition to improved social behaviors music therapy has been 
shown to also increase communication attempts, increase focus and 
attention, reduce anxiety, and improve body awareness and coordination.[46]

Since up to 30 per cent of children with autism are nonverbal and many 
have difficulty understanding verbal commands music therapy becomes very 
useful as it has been found that music can improve the mapping of sounds 
to actions. So by pairing music with actions, and with many hours of training 
the neural pathways for speech can be improved.[47] Child-appropriate 
action songs would be like playing the game  peek-ka-boo  or  eeny meeny 
miney mo  with a musical accompaniment, usually a piano or guitar.

Children with autism are also prone to more bouts of anxiety than the 
average child. Short sessions (15   20 mins) of listening to percussive music 
or classical music with a steady rhythm have been shown to alleviate 
symptoms of anxiety and temporarily decrease anxiety-related behaviour. 
Music with a steady 4/4 beat is thought to work best due to the predictability 
of the beat.

Target behaviours such as restlessness, aggression and noisiness can also 
be affected by the use of music therapy. Weekly sessions ranging for   hour 
to 1 hour during which a therapist plays child-preferred melodies such as 
Twinkle Twinkle Little Star and engages the child in quiet singing increases 
socially acceptable behaviour such as using an appropriate volume when 
speaking. Studies also suggest that playing one of the child s favorite songs 
while the child and therapist both play the piano or strum chords on a guitar 
can increase a child s ability to hold eye contact and share in an experience 
due to their enjoyment of the therapy.[48]

Musical improvisation during a one on one session has also been shown to 
be highly effective with increasing joint attention. Some noted improvisation 
techniques are using a welcome song that includes the child s name, which 
allows the child to get used to their surroundings; an adult-led song followed 
by a child led song and then conclude with a goodbye song.[49] During 
such sessions the child would most likely sit across from the therapist on the 
floor or beside the therapist on the piano bench. Composing original music 
that incorporates the child s day-to-day life with actions and words is also a 
part of improvisation. The shared music making experience allows for 
spontaneous interpersonal responses from the child and may motivate the 
child to increase positive social behaviour and initiate further interaction with 
the therapist.[50]

Some common instruments in music therapy for children are:

Upright piano, Guitar, Xylophone, Small guiro, Paddle drums, Egg shakers, 
Finger cymbals, Birdcalls, Whistles, & Toy hand bells.
Music therapy has also been recognized as a method for children with 
autism. Music therapy helps stabilize moods, increase frustration tolerance, 
identify a range of emotions, and improve self-expression along with much 
more.[51] The visual and auditory sensory system is responsible for 
interpreting sounds and images. With autistic children, if a sound or image is 
unpleasant the child may not have the ability to express itself, which makes 
it difficult for a therapist, parent, etc. to interpret.[52] Music engages the 
brain in both sub-coritcal and neo-cortical levels, which means it is not 
critical to think  while listening to music when hearing the notes and sounds. 
Music therapy, in the topic of austism s sensory interpretation, provides 
repetitive stimuli which aim to  teach  the brain other possible ways to 
respond that might be more useful as they grow older.[53]

Adolescents[edit]
Mood disorders[edit]
According to the Mayo Health Clinic, two to three thousand out of every 
100,000 adolescents will have mood disorders, and out of those two to three 
thousand, eight to ten will commit suicide.[citation needed] Two prevalent 
mood disorders in the adolescent population are clinical depression and 
bipolar disorder.

On average, American adolescents listen to approximately 4.5 hours of 
music per day and are responsible for 70% of pop music sales. Now, with 
the invention of new technologies such as the iPod and digital downloads, 
access to music has become easier than ever. As children make the 
transition into adolescence they become less likely to sit and watch TV, an 
activity associated with family, and spend more of their leisure time listening 
to music, an activity associated with friends.[54]

Adolescents obtain many benefits from listening to music, including 
emotional, social, and daily life benefits, along with help in forming their 
identity. Music can provide a sense of independence and individuality, which 
in turn contributes to an adolescent's self-discovery and sense of identity. 
Music also offers adolescents relatable messages that allow them to take 
comfort in knowing that others feel the same way they do. It can also serve 
as a creative outlet to release or control emotions and find ways of coping 
with difficult situations. Music can improve an adolescent's mood by 
reducing stress and lowering anxiety levels, which can help counteract or 
prevent depression.[55] Music education programs provide adolescents with 
a safe place to express themselves and learn life skills such as self-
discipline, diligence, and patience. These programs also promote confidence 
and self-esteem. Ethnomusicologist Alan Merriam (1964) once stated that 
music is a universal behavior   it is something with which everyone can 
identify. Among adolescents, music is a unifying force, bringing people of 
different backgrounds, age groups, and social groups together.

Referrals and assessments[edit]
While many adolescents may listen to music for its therapeutic qualities, it 
does not mean every adolescent needs music therapy. Many adolescents go 
through a period of teenage angst characterized by intense feelings of strife 
that are caused by the development of their brains and bodies. Some 
adolescents develop more serious mood disorders such as major clinical 
depression and bipolar disorder. Adolescents diagnosed with a mood 
disorder may be referred to a music therapist by a physician, therapist, or 
school counselor/teacher. When a music therapist gets a referral, he or she 
must first assess the patient and then create goals and objectives before 
beginning the actual therapy. According to the American Music Therapy 
Association Standards of Clinical Practice[56] assessments should include 
the  general categories of psychological, cognitive, communicative, social, 
and physiological functioning focusing on the client s needs and 
strengthsand will also determine the client s response to music, music 
skills, and musical preferences [57] The result of the assessment is used to 
create an individualized music therapy intervention plan.

Treatment techniques[edit]
There are many different music therapy techniques used with adolescents. 
The music therapy model is based on various theoretical backgrounds such 
as psychodynamic, behavioral, and humanistic approaches. Techniques can 
be classified as active vs. receptive and improvisational vs. structured.[58] 
The most common techniques in use with adolescents are musical 
improvisation, the use of precomposed songs or music, receptive listening to 
music, verbal discussion about the music, and incorporating creative media 
outlets into the therapy. Research also showed that improvisation and the 
use of other media were the two techniques most often used by the music 
therapists. The overall research showed that adolescents in music therapy  
change more when discipline-specific music therapy techniques, such as 
improvisation and verbal reflection of the music, are used.  The results of 
this study showed that music therapists should put careful thought into their 
choice of technique with each individual client. In the end, those choices can 
affect the outcome of the treatment.

To those unfamiliar with music therapy the idea may seem a little strange, 
but music therapy has been found to be as effective as traditional forms of 
therapy. In a meta-analysis of the effects of music therapy for children and 
adolescents with psychopathology, Gold, Voracek, and Wigram (2004) 
looked at ten studies conducted between 1970 and 1998 to examine the 
overall efficacy of music therapy on children and adolescents with 
behavioral, emotional, and developmental disorders. The results of the 
meta-analysis found that  music therapy with these clients has a highly 
significant, medium to large effect on clinically relevant outcomes.  More 
specifically, music therapy was most effective on subjects with mixed 
diagnoses. Another important result was that  the effects of music therapy 
are more enduring when more sessions are provided. [58]

One example of clinical work is that done by music therapists who work with 
adolescents to increase their emotional and cognitive stability, identify factors 
contributing to distress and initiate changes to alleviate that distress. Music 
therapy may also focus on improving quality of life and building self-esteem, 
a sense self-worth, and confidence. Improvements in these areas can be 
measured by a number of tests, including qualitative questionnaires like 
Beck s Depression Inventory, State and Trait Anxiety Inventory, and 
Relationship Change Scale.[59] Effects of music therapy can also be 
observed in the patient s demeanor, body language, and changes in 
awareness of mood.

Two main methods for music therapy are group meetings and one-one 
sessions. Group music therapy can include group discussions concerning 
moods and emotions in or toward music, songwriting, and musical 
improvisation. Groups emphasizing mood recognition and awareness, group 
cohesion, and improvement in self-esteem can be effective in working with 
adolescents.[60][61] Group therapy, however, is not always the best choice 
for the client. Ongoing one-on-one music therapy has also been shown to 
be effective. One-on-one music therapy provides a non-invasive, non-
judgmental environment, encouraging clients to show capacities that may be 
hidden in group situations.

Music Therapy in which clients play musical instruments directly, show very 
promising results. Specifically, playing wind instruments strengthens oral 
and respiratory muscles, sound vocalization, articulation, and improves 
breath support.[62] Symbolic Communication Training Through Music is also 
an important technique in playing instruments in music therapy, because 
this makes communication (verbally and non verbally) improved in social 
situations. Most importantly, is that music provides a time cue for the body to 
remain regulated.[63] Making music is also important for people of all ages 
because it causes motivation, increases "psychomotor" activity, causes an 
individual to identify with a group (in group music), regulates breathing, 
improves organizational skills, and increases coordination.[64]

Though more research needs to be done to ascertain the effect of music 
therapy on adolescents with mood disorders, most research has shown 
positive effects.

Medical disorders[edit]
Heart Disease[edit]
According to a 2009 Cochrane review some music may reduce heart rate, 
respiratory rate, and blood pressure in those with coronary heart disease.
[65] Music does not appear to have much effect on psychological distress. 
"The quality of the evidence is not strong and the clinical significance 
unclear". Research indicates that listening to music, whether a Mozart 
concerto or a song from the popular music charts, has been found to lower 
blood pressure, improve heart rate variability and can help to de-stress.[66]

Neurological disorders[edit]
The use of music therapy in treating mental and neurological disorders is on 
the rise. Music therapy has shown effectiveness in treating symptoms of 
many disorders, including schizophrenia, amnesia, dementia and 
Alzheimer's, Parkinson's disease, mood disorders such as depression, 
aphasia and similar speech disorders, and Tourette s syndrome, among 
others.[67]

While music therapy has been used for many years, up until the mid-1980s 
little empirical research had been done to support the efficacy of the 
treatment. Since then, more research has focused on determining both the 
effectiveness and the underlying physiological mechanisms leading to 
symptom improvement. For example, one meta-study covering 177 patients 
(over 9 studies) showed a significant effect on many negative symptoms of 
psychopathologies, particularly in developmental and behavioral disorders. 
Music therapy was especially effective in improving focus and attention, and 
in decreasing negative symptoms like anxiety and isolation.[68]

The following sections will discuss the uses and effectiveness of music 
therapy in the treatment of specific pathologies.

Stroke[edit]
Music has been shown to affect portions of the brain. One reason for the 
effectiveness of music therapy for stroke victims is the capacity of music to 
affect emotions and social interactions. Research by Nayak et al. showed 
that music therapy is associated with a decrease in depression, improved 
mood, and a reduction in state anxiety.[69] Both descriptive and 
experimental studies have documented effects of music on quality of life, 
involvement with the environment, expression of feelings, awareness and 
responsiveness, positive associations, and socialization.[70] Additionally, 
Nayak et al. found that music therapy had a positive effect on social and 
behavioral outcomes and showed some encouraging trends with respect to 
mood.[69]

More recent research suggests that music can increase a patient's 
motivation and positive emotions.[69][71][72] Current research also suggests 
that when music therapy is used in conjunction with traditional therapy it 
improves success rates significantly.[73][74][75] Therefore, it is hypothesized 
that music therapy helps a victim of stroke recover faster and with more 
success by increasing the patient's positive emotions and motivation, 
allowing him or her to be more successful and feel more driven to participate 
in traditional therapies.

Recent studies have examined the effect of music therapy on stroke patients 
when combined with traditional therapy. One study found the incorporation 
of music with therapeutic upper extremity exercises gave patients more 
positive emotional effects than exercise alone.[73] In another study, Nayak et 
al. found that rehabilitation staff rated participants in the music therapy 
group more actively involved and cooperative in therapy than those in the 
control group.[69] Their findings gave preliminary support to the efficacy of 
music therapy as a complementary therapy for social functioning and 
participation in rehabilitation with a trend toward improvement in mood 
during acute rehabilitation.

Current research shows that when music therapy is used in conjunction with 
traditional therapy, it improves rates of recovery and emotional and social 
deficits resulting from stroke.[69][73][74][75][76][77] A study by Jeong & Kim 
examined the impact of music therapy when combined with traditional stroke 
therapy in a community-based rehabilitation program.[76] Thirty-three stroke 
survivors were randomized into one of two groups: the experimental group, 
which combined rhythmic music and specialized rehabilitation movement for 
eight weeks; and a control group that sought and received traditional 
therapy. The results of this study showed that participants in the 
experimental group gained not only more flexibility and wider range of 
motion, but an increased frequency and quality of social interactions and 
positive mood.[76]

Music has proven useful in the recovery of motor skills. Rhythmical auditory 
stimulation in a musical context in combination with traditional gait therapy 
improved the ability of stroke patients to walk.[74] The study consisted of two 
treatment conditions, one which received traditional gait therapy and another 
which received the gait therapy in combination with the rhythmical auditory 
stimulation. During the rhythmical auditory stimulation, stimulation was 
played back measure by measure, and was initiated by the patient's heel-
strikes. Each condition received fifteen sessions of therapy. The results 
revealed that the rhythmical auditory stimulation group showed more 
improvement in stride length, symmetry deviation, walking speed and 
rollover path length (all indicators for improved walking gait) than the group 
that received traditional therapy alone.[74]

Schneider et al. also studied the effects of combining music therapy with 
standard motor rehabilitation methods.[75] In this experiment, researchers 
recruited stroke patients without prior musical experience and trained half of 
them in an intensive step by step training program that occurred fifteen 
times over three weeks, in addition to traditional treatment. These 
participants were trained to use both fine and gross motor movements by 
learning how to use the piano and drums. The other half of the patients 
received only traditional treatment over the course of the three weeks. 
Three-dimensional movement analysis and clinical motor tests showed 
participants who received the additional music therapy had significantly 
better speed, precision, and smoothness of movement as compared to the 
control subjects. Participants who received music therapy also showed a 
significant improvement in every-day motor activities as compared to the 
control group.[75] Wilson, Parsons, & Reutens looked at the effect of 
melodic intonation therapy (MIT) on speech production in a male singer with 
severe Broca's aphasia.[77] In this study, thirty novel phrases were taught in 
three conditions: unrehearsed, rehearsed verbal production (repetition), or 
rehearsed verbal production with melody (MIT). Results showed that 
phrases taught in the MIT condition had superior production, and that 
compared to rehearsal, effects of MIT lasted longer.

Another study examined the incorporation of music with therapeutic upper 
extremity exercises on pain perception in stroke victims.[73] Over the course 
of eight weeks, stroke victims participated in upper extremity exercises (of 
the hand, wrist, and shoulder joints) in conjunction with one of the three 
conditions: song, karaoke accompaniment, and no music. Patients 
participated in each condition once, according to a randomized order, and 
rated their perceived pain immediately after the session. Results showed 
that although there was no significant difference in pain rating across the 
conditions, video observations revealed more positive affect and verbal 
responses while performing upper extremity exercises with both music and 
karaoke accompaniment.[73] Nayak et al.[69] examined the combination of 
music therapy with traditional stroke rehabilitation and also found that the 
addition of music therapy improved mood and social interaction. Participants 
who had suffered traumatic brain injury or stroke were placed in one of two 
conditions: standard rehabilitation or standard rehabilitation along with music 
therapy. Participants received three treatments per week for up to ten 
treatments. Therapists found that participants who received music therapy in 
conjunction with traditional methods had improved social interaction and 
mood.

Dementia[edit]
Alzheimer's disease and other types of dementia are among the disorders 
most commonly treated with music therapy. Like many of the other disorders 
mentioned, some of the most common significant effects are seen in social 
behaviors, leading to improvements in interaction, conversation, and other 
such skills. A meta-study of over 330 subjects showed music therapy 
produces highly significant improvements to social behaviors, overt 
behaviors like wandering and restlessness, reductions in agitated behaviors, 
and improvements to cognitive defects, measured with reality orientation and 
face recognition tests.[78] As with many studies of MT s effectiveness, these 
positive effects on Alzheimer's and other dementias are not homogeneous 
among all studies. The effectiveness of the treatment seems to be strongly 
dependent on the patient, the quality and length of treatment, and other 
similar factors.[79]

Another meta-study examined the proposed neurological mechanisms 
behind music therapy s effects on these patients. Many authors suspect that 
music has a soothing effect on the patient by affecting how noise is 
perceived: music renders noise familiar, or buffers the patient from 
overwhelming or extraneous noise in their environment. Others suggest that 
music serves as a sort of mediator for social interactions, providing a vessel 
through which to interact with others without requiring much cognitive load.
[79] Because Music has the ability to access multiple parts of the brain, 
music therapy is highly effective in providing therapeutic support for 
individuals with all types of dementia. Research indicates that the sections of 
the brain weakened by dementia can be supported and in some cases 
strengthened by other areas of the brain through musical activities. Musical 
ability and awareness is also one of the last functions to be compromised in 
an individual with dementia, which makes it an especially effective 
intervention, even in people with very late stage forms of the disease.[80] 
Music therapy is more than simply listening to or playing music. Through the 
use of evidence based interventions and clinical assessments, a music 
therapist works to improve the lives and abilities of individuals. These 
interventions can decrease anxiety, improve speech and self- expression, 
and a decrease in negative behaviors and isolation which are commonly 
found in individuals with dementia.[81] Common negative behaviors that 
correspond with dementia are depression and agitation. According to Dr. 
Mary S. Mittelman, the director of psychosocial research at Langone Medical 
Center, music therapy helped to decrease both of these negative 
substantially. The reason for this is because in the brain, the parts 
corresponding to music are preserved even through the effects of dementia. 
Due to these being preserved, residents who live their lives in a blur, find 
some clarity and familiarity through music. Thus creating lower levels of 
stress and agitation.[82]

Amnesia[edit]
Some symptoms of amnesia have been shown to be alleviated through 
various interactions with music, including playing and listening. One such 
case is that of Clive Wearing, whose severe retrograde and anterograde 
amnesia have been detailed in the documentaries Prisoner of 
Consciousness and The Man with the 7 Second Memory. Though unable to 
recall past memories or form new ones, Wearing is still able to play, conduct, 
and sing along with music learned prior to the onset of his amnesia, and 
even add improvisations and flourishes.[83]

Wearing s case reinforces the theory that episodic memory fundamentally 
differs from procedural or semantic memory. Sacks suggests that while 
Wearing is completely unable to recall events or episodes, musical 
performance (and the muscle memory involved) are a form of procedural 
memory that is not typically hindered in amnesia cases [Sacks]. Indeed, 
there is evidence that while episodic memory is reliant on the hippocampal 
formation, amnesiacs with damage to this area can show a loss of episodic 
memory accompanied by (partially) intact semantic memory.[84]

Aphasia[edit]
Melodic intonation therapy (MIT) is a commonly used method of treating 
aphasias, particularly those involving speech deficits (as opposed to reading 
or writing). MIT is a multi-stage treatment that involves committing words and 
speech rhythm to memory by incorporating them into song. The musical and 
rhythmic aspects are then separated from the speech and phased out, until 
the patient can speak normally. This method has slight variations between 
adult patients and child patients, but both follow the same basic structure.

While MIT is a commonly used therapy, research supporting its effectiveness 
is lacking. Some recent research suggests that the therapy s efficacy may 
stem more from the rhythmic components of the treatment rather than the 
melodic aspects.[85]

Psychiatric disorders[edit]
Schizophrenia[edit]
Music therapy is used with schizophrenic patients to ameliorate many of the 
symptoms of the disorder. Individual studies of patients undergoing music 
therapy showed diminished negative symptoms such as flattened affect, 
speech issues, and anhedonia and improved social symptoms such as 
increased conversation ability, reduced social isolation, and increased 
interest in external events.[86]

Meta-studies have confirmed many of these results, showing that music 
therapy in conjunction with standard care to be superior to standard care 
alone. Improvements were seen in negative symptoms, general mental state, 
depression, anxiety, and even cognitive functioning. These meta-studies 
have also shown, however, that these results can be inconsistent and that 
they depend heavily on both the quality and number of therapy sessions.
[87]

Depression[edit]
Music therapy has been found to have numerous significant outcomes for 
patients with major depressive disorder. A systematic review of five 
randomized trials found that people with depression generally accepted 
music therapy and was found to produce improvements in mood when 
compared to standard therapy.[88] Another study showed that MDD patients 
were better able to express their emotional states while listening to sad 
music than while listening to no music or to happy, angry, or scary music. 
The authors found that this therapy helped patients overcome verbal barriers 
to expressing emotion, which can assist therapists in successfully guiding 
treatment.[89]

Other studies have provided insight into the physiological interactions 
between music therapy and depression. Music has been shown to decrease 
significantly the levels of the stress hormone cortisol, leading to improved 
affect, mood and cognitive functioning. A study also found that music led to 
a shift in frontal lobe activity (as measured by EEG) in depressed 
adolescents. Music was shown to shift activity from the right frontal lobe to 
the left, a phenomenon associated with positive affect and mood.[90]

Usage by region[edit]
Africa[edit]
In 1999, the first program for music therapy in Africa opened in Pretoria, 
South Africa. Research has shown that in Tanzania patients can receive 
palliative care for life-threatening illnesses directly after the diagnosis of 
these illnesses. This is different from many Western countries, because they 
reserve palliative care for patients who have an incurable illness. Music is 
also viewed differently between Africa and Western countries. In Western 
countries and a majority of other countries throughout the world, music is 
traditionally seen as entertainment whereas in many African cultures, music 
is used in recounting stories, celebrating life events, or sending messages.
[91]

Australia[edit]
[icon]  This section requires expansion. (June 2011)
In Australia in 1949, music therapy (not clinical music therapy as understood 
today) was started through concerts organized by the Australian Red Cross 
along with a Red Cross Music Therapy Committee. The key Australian body, 
the Australian Music Therapy Association (AMTA), was founded in 1975.

Norway[edit]
Norway is widely recognised as an important country for music therapy 
research. Its two major research centres are the Center for Music and 
Health[92] with the Norwegian Academy of Music in Oslo, and the Grieg 
Academy Centre for Music Therapy (GAMUT),[93] at University of Bergen. 
The former was mostly developed by professor Even Ruud, while professor 
Brynjulf Stige is largely responsible for cultivating the latter. The centre in 
Bergen has 18 staff, including 2 professors and 4 associate professors, as 
well as lecturers and PhD students. Two of the field s major international 
research journals are based in Bergen: Nordic Journal for Music Therapy[94] 
and Voices: A World Forum for Music Therapy.[95] Norway s main 
contribution to the field is mostly in the area of "community music therapy", 
which tends to be as much oriented toward social work as individual 
psychotherapy, and music therapy research from this country uses a wide 
variety of methods to examine diverse methods across an array of social 
contexts, including community centres, medical clinics, retirement homes, 
and prisons.

United States[edit]
Music therapy has existed in its current form in the United States since 1944 
when the first undergraduate degree program in the world was begun at 
Michigan State University and the first graduate degree program was 
established at the University of Kansas. The American Music Therapy 
Association (AMTA) was founded in 1998 as a merger between the National 
Association for Music Therapy (NAMT, founded in 1950) and the American 
Association for Music Therapy (AAMT, founded in 1971). Numerous other 
national organizations exist, such as the Institute for Music and Neurologic 
Function, Nordoff-Robbins Center For Music Therapy, and the Association 
for Music and Imagery. Music therapists use ideas from different disciplines 
such as speech and language, physical therapy, medicine, nursing, and 
education.

A music therapy degree candidate can earn an undergraduate, master's or 
doctoral degree in music therapy. Many AMTA approved programs offer 
equivalency and certificate degrees in music therapy for students that have 
completed a degree in a related field. Some practicing music therapists have 
held PhDs in fields other than, but usually related to, music therapy. 
Recently, Temple University established a PhD program in music therapy. A 
music therapist typically incorporates music therapy techniques with broader 
clinical practices such as psychotherapy, rehabilitation, and other practices 
depending on client needs. Music therapy services rendered within the 
context of a social service, educational, or health care agency are often 
reimbursable by insurance and sources of funding for individuals with 
certain needs. Music therapy services have been identified as reimbursable 
under Medicaid, Medicare, private insurance plans and federal and state 
government programs.

A degree in music therapy requires proficiency in guitar, piano, voice, music 
theory, music history, reading music, improvisation, as well as varying levels 
of skill in assessment, documentation, and other counseling and health care 
skills depending on the focus of the particular university's program. A music 
therapist may hold the designations CMT (Certified Music Therapist), ACMT 
(Advanced Certified Music Therapist), or RMT (Registered Music Therapist)   
credentials previously conferred by the former national organizations AAMT 
and NAMT ; these credentials remain in force through 2020 and have not 
been available since 1998. The current credential available is MT-BC. To 
become board certified, a music therapist must complete a music therapy 
degree from an accredited AMTA program at a college or university, 
successfully complete a music therapy internship, and pass the Board 
Certification Examination in Music Therapy, administered through The 
Certification Board for Music Therapists. To maintain the credential, either 
100 units of continuing education must be completed every five years, or the 
board exam must be retaken near the end of the five-year cycle. The units 
claimed for credit fall under the purview of the Certification Board for Music 
Therapists. North Dakota, Nevada and Georgia have established licenses for 
music therapists. In the State of New York, the License for Creative Arts 
Therapies (LCAT) incorporates the music therapy credentials within their 
licensure.

United Kingdom[edit]
Live music was used in hospitals after both World Wars as part of the 
treatment program for recovering soldiers. Clinical music therapy in Britain 
as it is understood today was pioneered in the 1960s and 1970s by French 
cellist Juliette Alvin whose influence on the current generation of British 
music therapy lecturers remains strong. Mary Priestley, one of Juliette Alvin's 
students, created "analytical music therapy". The Nordoff-Robbins approach 
to music therapy developed from the work of Paul Nordoff and Clive Robbins 
in the 1950/60s.

Practitioners are registered with the Health Professions Council and, starting 
from 2007, new registrants must normally hold a master's degree in music 
therapy. There are master's level programs in music therapy in Manchester, 
Bristol, Cambridge, South Wales, Edinburgh and London, and there are 
therapists throughout the UK. The professional body in the UK is the British 
Association for Music Therapy[96] In 2002, the World Congress of Music 
Therapy, coordinated and promoted by the World Federation of Music 
Therapy, was held in Oxford on the theme of Dialogue and Debate.[97] In 
November 2006, Dr. Michael J. Crawford and his colleagues again found 
that music therapy helped the outcomes of schizophrenic patients.[98][99]

India[edit]
The roots of musical therapy in India, can be traced back to ancient Hindu 
mythology, Vedic texts, and local folk traditions.[100] It is very possible that 
music therapy has been used for hundreds of years in the Indian culture.

Suvarna Nalapat has studied music therapy in the Indian context. Her books 
Nadalayasindhu-Ragachikilsamrutam (2008), Music Therapy in Management 
Education and Administration (2008) and Ragachikitsa (2008) are accepted 
textbooks on music therapy and Indian arts.[101][102][103][104][105][106]

The "Music Therapy Trust of India" is yet another venture in the country. It 
was started by Margaret Lobo[107]

History[edit]
Music has been used as a healing implement for centuries.[55] Apollo is the 
ancient Greek god of music and of medicine. Aesculapius was said to cure 
diseases of the mind by using song and music, and music therapy was used 
in Egyptian temples. Plato said that music affected the emotions and could 
influence the character of an individual. Aristotle taught that music affects 
the soul and described music as a force that purified the emotions. Aulus 
Cornelius Celsus advocated the sound of cymbals and running water for the 
treatment of mental disorders. Music therapy was practiced in biblical times, 
when David played the harp to rid King Saul of a bad spirit.[108] As early as 
400 B.C., Hippocrates played music for mental patients. In the thirteenth 
century, Arab hospitals contained music-rooms for the benefit of the 
patients.[109] In the United States, Native American medicine men often 
employed chants and dances as a method of healing patients.[110] The 
Turco-Persian psychologist and music theorist al-Farabi (872 950), known as 
Alpharabius in Europe, dealt with music therapy in his treatise Meanings of 
the Intellect, in which he discussed the therapeutic effects of music on the 
soul.[111] Robert Burton wrote in the 17th century in his classic work, The 
Anatomy of Melancholy, that music and dance were critical in treating mental 
illness, especially melancholia.[112][113][114]ne record mentioning it has 
been found. A later reservoir pen was developed in 1636. In his Deliciae 
Physico-Mathematicae (1636), German inventor Daniel Schwenter described 
a pen made from two quills. One quill served as a reservoir for ink inside the 
other quill. The ink was sealed inside the quill with cork. Ink was squeezed 
through a small hole to the writing point. In 1809, Bartholomew Folsch 
received a patent in England for a pen with an ink reservoir.[12]

While a student in Paris, Romanian Petrache Poenaru invented the fountain 
pen, which the French Government patented in May 1827. Fountain pen 
patents and production then increased in the 1850s, especially steel pens 
produced by John Mitchell.

The first patent on a ballpoint pen was issued on October 30, 1888, to John 
J Loud.[13] In 1938, L szl  B r , a Hungarian newspaper editor, with the help 
of his brother George, a chemist, began to work on designing new types of 
pens including one with a tiny ball in its tip that was free to turn in a socket. 
As the pen moved along the paper, the ball rotated, picking up ink from the 
ink cartridge and leaving it on the paper. B r  filed a British patent on June 
15, 1938. In 1940 the B r  brothers and a friend, Juan Jorge Meyne, moved 
to Argentina fleeing Nazi Germany and on June 10, filed another patent, and 
formed B r  Pens of Argentina. By the summer of 1943 the first commercial 
models were available.[14] Erasable ballpoint pens were 
Stylus
From Wikipedia, the free encyclopedia
This article is about a writing utensil. For the pointing device, see Stylus 
(computing). For other uses, see Stylus (disambiguation).
"Stylus pen" redirects here. It is not to be confused with Digital pen.

Wax tablet and a Roman stylus
A stylus, plural styli or styluses,[1][2] is a writing utensil, or a small tool for 
some other form of marking or shaping, for example in pottery. It can also be 
a computer accessory that is used to assist in navigating or providing more 
precision when using touchscreens. It usually refers to a narrow elongated 
staff, similar to a modern ballpoint pen. Many styluses are heavily curved to 
be held more easily. Another widely used writing tool is the stylus used by 
blind users in conjunction with the slate for punching out the dots in Braille.
[3]

Styluses were first used by the ancient Mesopotamians in order to write in 
cuneiform. Egyptians (Middle Kingdom) and the Minoans of Crete (Linear A 
and Cretan Hieroglyphic) made styluses in various materials: reeds that 
grew on the sides of the Tigris and Euphrates rivers and in marshes and 
down to Egypt where the Egyptians used styluses from sliced reeds with 
sharp points; bone and metal styluses were also used. Cuneiform was 
entirely based on the "wedge-shaped" mark that the end of a cut reed made 
when pushed into a clay tablet; from Latin cuneus = wedge. The linear 
writings of Crete in the first half of the second millennium BC which were 
made on clay tablets that were left to dry in the sun until they became 
"leather" hard before being incised by the stylus. The linear nature of the 
writing was also dictated by the use of the stylus.

In Western Europe styluses were widely used until the late Middle Ages. For 
learning purposes the stylus was gradually replaced by a writing slate. From 
the mid-14th century improved water-powered paper mills produced large 
and cheap quantities of paper and the wax tablet and stylus disappeared 
completely from daily life.

Contents  [hide] 
1 Etymology
2 Use in arts
3 Use in music recording and reproduction
4 Smartphones and computing
5 Scientific instruments
6 See also
7 References
Etymology[edit]

Examples of 4 Medieval styluses for writing on wax tablets. Two are made of 
iron, one brass and one bone stylus.
The word "stylus" (along with the word "style") comes from the Latin word 
stilus meaning: "a stake; a pointed instrument, used by the Romans, for 
writing upon wax tablets,"[4] which derives from the Greek word        
meaning "pillar" and "stile for writing on waxed tablets."[5] A different 
suggestion is that the word does not derive from the Greek word "      ", but 
that it has a common root with the Greek verb "     " (meaning "mark"). 
According to the 1875 London Dictionary of Greek & Roman Antiquities a 
Stylus is "an object tapering like an architectural column; a metal instrument 
resembling a pencil in size and shape, used for writing or recording 
impressions upon waxed tablets. It signifies:

"An iron instrument (Ov. Met. IX.521; Martial, XIV.21), resembling a pencil in 
size and shape, used for writing upon waxed tablets (Plaut. Bacch. IV.4.63; 
Plin. H.N. XXXIV.14). At one end it was sharpened to a point for scratching 
the characters upon the wax (Quintil. i.1  27), while the other end being flat 
and circular served to render the surface of the tablets smooth again, and so 
to obliterate what had been written. Thus, vertere stilum means to erase, 
and hence to correct, as in the well-known precept saepe stilum vertas (Hor. 
Sat. 1.10.72; Cic. Verr. II.41)."

There exists minor controversy about the correct pluralization of "stylus". 
Some assert that "stylus" is a direct loanword from Latin and should be 
pluralised as "styli". However, "stylus" is an English word based on the Latin 
word "stilus", and is more appropriately pluralised in English as "styluses". 
Occasionally the pluralisation "stylii" is seen.

Use in arts[edit]
Styluses are still used in various arts and crafts. Example situations: rubbing 
off dry transfer letters, tracing designs onto a new surface with carbon 
paper, and hand embossing. Styluses are also used to engrave into 
materials like metal or clay.

Styluses are used to make dots as found in folk art and Mexican pottery 
artifacts. Oaxaca dot art is created using styluses.

Use in music recording and reproduction[edit]

A gramophone cartridge with stylus for use on vinyl records, a late use of the 
stylus in audio
In the sound recording industry, a stylus is a phonograph or gramophone 
needle used to play back sound on gramophone records, as well as to 
record the sound indentations on the master record.

Several technologies were used to record the sounds, beginning with wax 
cylinders, almost half a century before the invention of the magnetic 
cartridge. Nowadays mostly vinyl records are used. When playing the 
record, the stylus is placed in the grooves of the record. By then spinning 
the record, the stylus start to vibrate caused by the shape of the grooves. 
These vibrations are then converted by the cartridge. The harder the material 
used for the record, the harder the stylus has to be in order to increase the 
quality of the sound and to decrease the wear of the needle.[6] For shellac 
records, a disposable stylus softer than the record was generally preferred 
for preservation of the recording. The styluses for playing vinyl records are 
made out of Sapphire or diamond. There are two common types of stylus: 
elliptical and spherical. Each contacts the groove differently than the other; 
the elliptical stylus allows for more groove contact, which increases fidelity, 
while the spherical stylus makes less contact with the groove, which yields a 
more sensitive stylus.

Smartphones and computing[edit]

Styluses for different PDAs
Main article: Stylus (computing)
Modern day devices, such as phones, can often be used with a stylus to 
accurately navigate through menus, send messages etc. Today, the term 
stylus often refers to an input tool usually used with touchscreen-enabled 
devices, such as Tablet PCs, to accurately navigate interface elements, send 
messages, etc. This also prevents smearing the screen with oils from one's 
fingers. Styluses may also be used for handwriting; or for drawing using 
graphics tablets.

Many new phones have a built-in stylus which tucks in behind the back 
cover. Some styluses may extend and contract into small, pen-like cylinders, 
which are easy to put away.

Styluses come in both passive and active versions. A passive or capacitive 
stylus is a stylus that acts just like a finger when touching a device screen. 
There is no electronic communication between a passive stylus and a 
device. The device cannot tell the difference between a finger and a passive 
stylus.

An active stylus includes electronic components that communicate with the 
touchscreen controller on a device. Active pens are typically used for note 
taking, on-screen drawing/painting, and electronic document annotation. As 
before, the stylus is pointed or rounded at one end and is made to fit in the 
grip of a hand comfortably. These styluses can be found in many different 
styles.

Palm Rejection: Since many modern tablets make use of multi-touch 
recognition, some stylus and app manufactures have created palm rejection 
technologies into their products. This works to turn off the multi-touch 
feature allowing the palm to rest on the tablet while still recognizing the 
stylus.

Scientific instruments[edit]
A stylus is also an instrument used to scribe a recording into smoked foil or 
glass. In various scientific instruments this method may be employed instead 
of a pen for recording as it has the advantage of being able to operate over a 
wide temperature range, does not clog or dry prematurely, and has very 
small friction in comparison to other methods. These characteristics were 
useful in certain types of early seismographs and in recording barographs 
that were once used to verify sailplane records. The styluses used in 
scanning tunneling microscopes have only a single atom at the tip; these are 
effectively the sharpest styluses possible.
Paper is a thin material produced by pressing together moist fibres of 
cellulose pulp derived from wood, rags or grasses, and drying them into 
flexible sheets. It is a versatile material with many uses, including writing, 
printing, packaging, cleaning, and a number of industrial and construction 
processes.

The pulp papermaking process is said to have been developed in China 
during the early 2nd century AD, possibly as early as the year 105 A.D.,[1] 
by the Han court eunuch Cai Lun, although the earliest archaeological 
fragments of paper derive from the 2nd century BC in China.[2] The modern 
pulp and paper industry is global, with China leading its production and the 
United States right behind it.

Contents  [hide] 
1 History
2 Etymology
3 Papermaking
3.1 Chemical pulping
3.2 Mechanical pulping
3.3 De-inked pulp
3.4 Additives
3.5 Producing paper
3.6 Finishing
4 Applications
5 Types, thickness and weight
6 Paper stability
7 Environmental impact of paper
8 Future of paper
9 See also
10  References and notes
11  Further reading
12  External links
History
Main article: History of paper

Hemp wrapping paper, China, circa 100 BC.
The oldest known archaeological fragments of the immediate precursor to 
modern paper, date to the 2nd century BC in China. The pulp papermaking 
process is ascribed to Cai Lun, a 2nd-century AD Han court eunuch.[2] With 
paper as an effective substitute for silk in many applications, China could 
export silk in greater quantity, contributing to a Golden Age.

Its knowledge and uses spread from China through the Middle East to 
medieval Europe in the 13th century, where the first water powered paper 
mills were built.[3] Because of paper's introduction to the West through the 
city of Baghdad, it was first called bagdatikos.[4] In the 19th century, 
industrial manufacture greatly lowered its cost, enabling mass exchange of 
information and contributing to significant cultural shifts. In 1844, the 
Canadian inventor Charles Fenerty and the German F. G. Keller 
independently developed processes for pulping wood fibres.[5]

Etymology
Further information: Papyrus
The word "paper" is etymologically derived from Latin papyrus, which comes 
from the Greek         (papuros), the word for the Cyperus papyrus plant.[6]
[7] Papyrus is a thick, paper-like material produced from the pith of the 
Cyperus papyrus plant, which was used in ancient Egypt and other 
Mediterranean cultures for writing before the introduction of paper into the 
Middle East and Europe.[8] Although the word paper is etymologically 
derived from papyrus, the two are produced very differently and the 
development of the first is distinct from the development of the second. 
Papyrus is a lamination of natural plant fibres, while paper is manufactured 
from fibres whose properties have been changed by maceration.[2]

Papermaking
Main article: Papermaking
Chemical pulping
Main articles: kraft process, sulfite process and soda pulping
To make pulp from wood, a chemical pulping process separates lignin from 
cellulose fibres. This is accomplished by dissolving lignin in a cooking liquor, 
so that it may be washed from the cellulose; this preserves the length of the 
cellulose fibres. Paper made from chemical pulps are also known as wood-
free papers not to be confused with tree-free paper; this is because they do 
not contain lignin, which deteriorates over time. The pulp can also be 
bleached to produce white paper, but this consumes 5% of the fibres; 
chemical pulping processes are not used to make paper made from cotton, 
which is already 90% cellulose.


The microscopic structure of paper: Micrograph of paper autofluorescing 
under ultraviolet illumination. The individual fibres in this sample are around 
10  m in diameter.
There are three main chemical pulping processes: the sulfite process dates 
back to the 1840s and it was the dominant method extent before the second 
world war. The kraft process, invented in the 1870s and first used in the 
1890s, is now the most commonly practiced strategy, one of its advantages 
is the chemical reaction with lignin, that produces heat, which can be used 
to run a generator. Most pulping operations using the kraft process are net 
contributors to the electricity grid or use the electricity to run an adjacent 
paper mill. Another advantage is that this process recovers and reuses all 
inorganic chemical reagents. Soda pulping is another specialty process 
used to pulp straws, bagasse and hardwoods with high silicate content.

Mechanical pulping
There are two major mechanical pulps, the thermomechanical one (TMP) 
and groundwood pulp (GW). In the TMP process, wood is chipped and then 
fed into large steam heated refiners, where the chips are squeezed and 
converted to fibres between two steel discs. In the groundwood process, 
debarked logs are fed into grinders where they are pressed against rotating 
stones to be made into fibres. Mechanical pulping does not remove the 
lignin, so the yield is very high, >95%, however it causes the paper thus 
produced to turn yellow and become brittle over time. Mechanical pulps 
have rather short fibres, thus producing weak paper. Although large 
amounts of electrical energy are required to produce mechanical pulp, it 
costs less than the chemical kind.

De-inked pulp
Main article: de-inking
Paper recycling processes can use either chemically or mechanically 
produced pulp; by mixing it with water and applying mechanical action the 
hydrogen bonds in the paper can be broken and fibres separated again. 
Most recycled paper contains a proportion of virgin fibre for the sake of 
quality; generally speaking, de-inked pulp is of the same quality or lower 
than the collected paper it was made from.

There are three main classifications of recycled fibre:.

Mill broke or internal mill waste   This incorporates any substandard or 
grade-change paper made within the paper mill itself, which then goes back 
into the manufacturing system to be re-pulped back into paper. Such out-
of-specification paper is not sold and is therefore often not classified as 
genuine reclaimed recycled fibre, however most paper mills have been 
reusing their own waste fibre for many years, long before recycling become 
popular.
Preconsumer waste   This is offcut and processing waste, such as guillotine 
trims and envelope blank waste; it is generated outside the paper mill and 
could potentially go to landfill, and is a genuine recycled fibre source; it 
includes de-inked preconsumer (recycled material that has been printed but 
did not reach its intended end use, such as waste from printers and unsold 
publications).[9]
Postconsumer waste   This is fibre from paper that has been used for its 
intended end use and includes office waste, magazine papers and 
newsprint. As the vast majority of this material has been printed   either 
digitally or by more conventional means such as lithography or rotogravure   
it will either be recycled as printed paper or go through a de-inking process 
first.
Recycled papers can be made from 100% recycled materials or blended with 
virgin pulp, although they are (generally) not as strong nor as bright as 
papers made from the latter.

Additives
Besides the fibres, pulps may contain fillers such as chalk or china clay, 
which improve its characteristics for printing or writing. Additives for sizing 
purposes may be mixed with it and/or applied to the paper web later in the 
manufacturing process; the purpose of such sizing is to establish the correct 
level of surface absorbency to suit ink or paint.

Producing paper
Main articles: Paper machine and papermaking
The pulp is fed to a paper machine where it is formed as a paper web and 
the water is removed from it by pressing and drying.

Pressing the sheet removes the water by force; once the water is forced from 
the sheet, a special kind of felt, which is not to be confused with the 
traditional one, is used to collect the water; whereas when making paper by 
hand, a blotter sheet is used instead.

Drying involves using air and/or heat to remove water from the paper sheets; 
in the earliest days of paper making this was done by hanging the sheets 
like laundry; in more modern times various forms of heated drying 
mechanisms are used. On the paper machine the most common is the 
steam heated can dryer. These can reach temperatures above 200  F (93  C) 
and are used in long sequences of more than 40 cans; where the heat 
produced by these can easily dry the paper to less than 6% moisture.

Finishing
The paper may then undergo sizing to alter its physical properties for use in 
various applications.

Paper at this point is uncoated. Coated paper has a thin layer of material 
such as calcium carbonate or china clay applied to one or both sides in 
order to create a surface more suitable for high-resolution halftone screens. 
(Uncoated papers are rarely suitable for screens above 150 lpi.) Coated or 
uncoated papers may have their surfaces polished by calendering. Coated 
papers are divided into matte, semi-matte or silk, and gloss. Gloss papers 
give the highest optical density in the printed image.

The paper is then fed onto reels if it is to be used on web printing presses, 
or cut into sheets for other printing processes or other purposes. The fibres 
in the paper basically run in the machine direction. Sheets are usually cut 
"long-grain", i.e. with the grain parallel to the longer dimension of the sheet.

All paper produced by paper machines as the Fourdrinier Machine are wove 
paper, i.e. the wire mesh that transports the web leaves a pattern that has 
the same density along the paper grain and across the grain. Textured 
finishes, watermarks and wire patterns imitating hand-made laid paper can 
be created by the use of appropriate rollers in the later stages of the 
machine.

Wove paper does not exhibit "laidlines", which are small regular lines left 
behind on paper when it was handmade in a mould made from rows of 
metal wires or bamboo. Laidlines are very close together. They run 
perpendicular to the "chainlines", which are further apart. Handmade paper 
similarly exhibits "deckle edges", or rough and feathery borders.[10]

Applications
Paper can be produced with a wide variety of properties, depending on its 
intended use.

For representing value: paper money, bank note, cheque, security (see 
security paper), voucher and ticket
For storing information: book, notebook, magazine, newspaper, art, zine, 
letter
For personal use: diary, note to remind oneself, etc.; for temporary personal 
use: scratch paper
For communication: between individuals and/or groups of people.
For packaging: corrugated box, paper bag, envelope, Packing & Wrapping 
Paper, Paper string, Charta emporetica and wallpaper
For cleaning: toilet paper, handkerchiefs, paper towels, facial tissue and cat 
litter
For construction: papier-m ch , origami, paper planes, quilling, paper 
honeycomb, used as a core material in composite materials, paper 
engineering, construction paper and paper clothing
For other uses: emery paper, sandpaper, blotting paper, litmus paper, 
universal indicator paper, paper chromatography, electrical insulation paper 
(see also dielectric and permittivity) and filter paper
Types, thickness and weight
Main articles: Paper size, Grammage and Paper density

Card and paper stock for crafts use comes in a wide variety of textures and 
colors.
The thickness of paper is often measured by caliper, which is typically given 
in thousandths of an inch in the United States and in thousandths of a mm 
in the rest of the world.[11] Paper may be between 0.07 and 0.18 millimetres 
(0.0028 and 0.0071 in) thick.[12]

Paper is often characterized by weight. In the United States, the weight 
assigned to a paper is the weight of a ream, 500 sheets, of varying "basic 
sizes", before the paper is cut into the size it is sold to end customers. For 
example, a ream of 20 lb, 8.5 in   11 in (216 mm   279 mm) paper weighs 5 
pounds, because it has been cut from a larger sheet into four pieces.[13] In 
the United States, printing paper is generally 20 lb, 24 lb, or 32 lb at most. 
Cover stock is generally 68 lb, and 110 lb or more is considered card stock.

In Europe, and other regions using the ISO 216 paper sizing system, the 
weight is expressed in grammes per square metre (g/m2 or usually just g) of 
the paper. Printing paper is generally between 60 g and 120 g. Anything 
heavier than 160 g is considered card. The weight of a ream therefore 
depends on the dimensions of the paper and its thickness.

Most commercial paper sold in North America is cut to standard paper sizes 
based on customary units and is defined by the length and width of a sheet 
of paper.

The ISO 216 system used in most other countries is based on the surface 
area of a sheet of paper, not on a sheet's width and length. It was first 
adopted in Germany in 1922 and generally spread as nations adopted the 
metric system. The largest standard size paper is A0 (A zero), measuring 
one square meter (approx. 1189   841 mm). Two sheets of A1, placed upright 
side by side fit exactly into one sheet of A0 laid on its side. Similarly, two 
sheets of A2 fit into one sheet of A1 and so forth. Common sizes used in the 
office and the home are A4 and A3 (A3 is the size of two A4 sheets).

The density of paper ranges from 250 kg/m3 (16 lb/cu ft) for tissue paper to 
1,500 kg/m3 (94 lb/cu ft) for some speciality paper. Printing paper is about 
800 kg/m3 (50 lb/cu ft).[14]

Paper may be classified into seven categories:[15]

Printing papers of wide variety.
Wrapping papers for the protection of goods and merchandise. This 
includes wax and kraft papers.
Writing paper suitable for stationery requirements. This includes ledger, 
bank, and bond paper.
Blotting papers containing little or no size.
Drawing papers usually with rough surfaces used by artists and designers, 
including cartridge paper.
Handmade papers including most decorative papers, Ingres papers, 
Japanese paper and tissues, all characterized by lack of grain direction.
Specialty papers including cigarette paper, toilet tissue, and other industrial 
papers.
Some paper types include:

Bank paper
Banana paper
Bond paper
Book paper
Coated paper: glossy and matte surface
Construction paper/sugar paper
Cotton paper
Fish paper (vulcanized fibres for electrical insulation)
Inkjet paper
Kraft paper
Laid paper
Leather paper
Mummy paper
Oak Tag Paper
Sandpaper
Tyvek paper
Wallpaper
Washi
Waterproof paper
Wax paper
Wove paper
Xuan paper
Paper stability
Much of the early paper made from wood pulp contained significant amounts 
of alum, a variety of aluminium sulfate salts that is significantly acidic. Alum 
was added to paper to assist in sizing,[16] making it somewhat water 
resistant so that inks did not "run" or spread uncontrollably. Early 
papermakers did not realize that the alum they added liberally to cure 
almost every problem encountered in making their product would eventually 
be detrimental.[17] The cellulose fibres that make up paper are hydrolyzed 
by acid, and the presence of alum would eventually degrade the fibres until 
the paper disintegrated in a process that has come to be known as "slow 
fire". Documents written on rag paper were significantly more stable. The 
use of non-acidic additives to make paper is becoming more prevalent, and 
the stability of these papers is less of an issue.

Paper made from mechanical pulp contains significant amounts of lignin, a 
major component in wood. In the presence of light and oxygen, lignin reacts 
to give yellow materials,[18] which is why newsprint and other mechanical 
paper yellows with age. Paper made from bleached kraft or sulfite pulps 
does not contain significant amounts of lignin and is therefore better suited 
for books, documents and other applications where whiteness of the paper 
is essential.

Paper made from wood pulp is not necessarily less durable than a rag 
paper. The ageing behavior of a paper is determined by its manufacture, not 
the original source of the fibres.[19] Furthermore, tests sponsored by the 
Library of Congress prove that all paper is at risk of acid decay, because 
cellulose itself produces formic, acetic, lactic and oxalic acids.[20]

Mechanical pulping yields almost a tonne of pulp per tonne of dry wood 
used, which is why mechanical pulps are sometimes referred to as "high 
yield" pulps. With almost twice the yield as chemical pulping, mechanical 
pulps is often cheaper. Mass-market paperback books and newspapers tend 
to use mechanical papers. Book publishers tend to use acid-free paper, 
made from fully bleached chemical pulps for hardback and trade paperback 
books.

Environmental impact of paper
Main articles: Environmental impact of paper, Paper pollution and 
Deforestation
The production and use of paper has a number of adverse effects on the 
environment.

Worldwide consumption of paper has risen by 400% in the past 40 years 
leading to increase in deforestation, with 35% of harvested trees being used 
for paper manufacture. Most paper companies also plant trees to help 
regrow forests. Logging of old growth forests accounts for less than 10% of 
wood pulp,[21] but is one of the most controversial issues.

Paper waste accounts for up to 40% of total waste produced in the United 
States each year, which adds up to 71.6 million tons of paper waste per year 
in the United States alone.[22] The average office worker in the US prints 31 
pages every day.[23] Americans also use on the order of 16 billion paper 
cups per year.

Conventional bleaching of wood pulp using elemental chlorine produces and 
releases into the environment large amounts of chlorinated organic 
compounds, including chlorinated dioxins.[24] Dioxins are recognized as a 
persistent environmental pollutant, regulated internationally by the 
Stockholm Convention on Persistent Organic Pollutants. Dioxins are highly 
toxic, and health effects on humans include reproductive, developmental, 
immune and hormonal problems. They are known to be carcinogenic. Over 
90% of human exposure is through food, primarily meat, dairy, fish and 
shellfish, as dioxins accumulate in the food chain in the fatty tissue of 
animals.[25]

Future of paper
Some manufacturers have started using a new, significantly more 
environmentally friendly alternative to expanded plastic packaging. Made out 
of paper, and known commercially as paperfoam, the new packaging has 
very similar mechanical properties to some expanded plastic packaging, but 
is biodegradable and can also be recycled with ordinary paper.[26]

With increasing environmental concerns about synthetic coatings (such as 
PFOA) and the higher prices of hydrocarbon based petrochemicals, there is 
a focus on zein (corn protein) as a coating for paper in high grease 
applications such as popcorn bags.[27]

Also, synthetics such as Tyvek and Teslin have been introduced as printing 
media as a more durable material than paper.

rtist
From Wikipedia, the free encyclopedia
For other uses, see Artist (disambiguation).

Johann Wolfgang von Goethe, German artist known for his works of poetry, 
drama, prose, philosophy, visual arts, and science.
An artist is a person engaged in one or more of any of a broad spectrum of 
activities related to creating art, practicing the arts, and/or demonstrating an 
art. The common usage in both everyday speech and academic discourse is 
a practitioner in the visual arts only. The term is often used in the 
entertainment business, especially in a business context, for musicians and 
other performers (less often for actors). "Artiste" (the French for artist) is a 
variant used in English only in this context. Use of the term to describe 
writers, for example, is valid, but less common, and mostly restricted to 
contexts like criticism.

Contents  [hide] 
1 Dictionary definitions
2 History of the term
3 The present day concept of an 'artist'
4 Examples of art and artists
5 See also
6 Notes
7 References
Dictionary definitions[edit]
Wiktionary defines the noun 'artist' (Singular: artist; Plural: artists) as follows:

A person who creates art.
A person who makes and creates art as an occupation.
A person who is skilled at some activity.
A person whose trade or profession requires a knowledge of design, 
drawing, painting, etc.
The Oxford English Dictionary defines the older broad meanings of the term 
"artist":

A learned person or Master of Arts
One who pursues a practical science, traditionally medicine, astrology, 
alchemy, chemistry
A follower of a pursuit in which skill comes by study or practice
A follower of a manual art, such as a mechanic
One who makes their craft a fine art
One who cultivates one of the fine arts   traditionally the arts presided over 
by the muses
History of the term[edit]
The Greek word "techn ", often translated as "art," implies mastery of any 
sort of craft. The adjectival Latin form of the word, "technicus",[1] became 
the source of the English words technique, technology, technical.

In Greek culture each of the nine Muses oversaw a different field of human 
creation:

Calliope (the 'beautiful of speech'): chief of the muses and muse of epic or 
heroic poetry
Clio (the 'glorious one'): muse of history
Erato (the 'amorous one'): muse of love or erotic poetry, lyrics, and marriage 
songs
Euterpe (the 'well-pleasing'): muse of music and lyric poetry
Melpomene (the 'chanting one'): muse of tragedy
Polyhymnia or Polymnia (the '[singer] of many hymns'): muse of sacred 
song, oratory, lyric, singing, and rhetoric
Terpsichore (the '[one who] delights in dance'): muse of choral song and 
dance
Thalia (the 'blossoming one'): muse of comedy and bucolic poetry
Urania (the 'celestial one'): muse of astronomy
No muse was identified with the visual arts of painting and sculpture. In 
ancient Greece sculptors and painters were held in low regard, somewhere 
between freemen and slaves, their work regarded as mere manual labour.[2]

The word art derives from the Latin "ars" (stem art-), which, although literally 
defined, means "skill method" or "technique", and conveys a connotation of 
beauty.

During the Middle Ages the word artist already existed in some countries 
such as Italy, but the meaning was something resembling craftsman, while 
the word artesan was still unknown. An artist was someone able to do a work 
better than others, so the skilled excellency was underlined, rather than the 
activity field. In this period some "artisanal" products (such as textiles) were 
much more precious and expensive than paintings or sculptures.

The first division into major and minor arts dates back at least to the works of 
Leon Battista Alberti (1404 1472): De re aedificatoria, De statua, De pictura, 
which focused on the importance of the intellectual skills of the artist rather 
than the manual skills (even if in other forms of art there was a project 
behind).[3]

With the Academies in Europe (second half of 16th century) the gap 
between fine and applied arts was definitely set.

Many contemporary definitions of "artist" and "art" are highly contingent on 
culture, resisting aesthetic prescription, in much the same way that the 
features constituting beauty and the beautiful cannot be standardized easily 
without corruption into kitsch.

The present day concept of an 'artist'[edit]
Artist is a descriptive term applied to a person who engages in an activity 
deemed to be an art. An artist also may be defined unofficially as "a person 
who expresses him- or herself through a medium". The word is also used in 
a qualitative sense of, a person creative in, innovative in, or adept at, an 
artistic practice.

Most often, the term describes those who create within a context of the fine 
arts or 'high culture', activities such as drawing, painting, sculpture, acting, 
dancing, writing, filmmaking, new media, photography, and music people 
who use imagination, talent, or skill to create works that may be judged to 
have an aesthetic value. Art historians and critics define artists as those who 
produce art within a recognized or recognizable discipline. Contrasting terms 
for highly skilled workers in media in the applied arts or decorative arts 
include artisan, craftsman, and specialized terms such as potter, goldsmith 
or glassblower. Fine arts artists such as painters succeeded in the 
Renaissance in raising their status, formerly similar to these workers, to a 
decisively higher level, but in the 20th century the distinction became rather 
less relevant[citation needed].

The term may also be used loosely or metaphorically to denote highly skilled 
people in any non-"art" activities, as well  law, medicine, mechanics, or 
mathematics, for example.

Often, discussions on the subject focus on the differences among "artist" 
and "technician", "entertainer" and "artisan", "fine art" and "applied art", or 
what constitutes art and what does not. The French word artiste (which in 
French, simply means "artist") has been imported into the English language 
where it means a performer (frequently in Music Hall or Vaudeville). Use of 
the word "artiste" can also be a pejorative term.[4]

The English word 'artiste' has thus a narrower range of meaning than the 
word 'artiste' in French.

In Living with Art,[citation needed] Mark Getlein proposes six activities, 
services or functions of contemporary artists:

Create places for some human purpose.
Create extraordinary versions of ordinary objects.
Record and commemorate.
Give tangible form to the unknown.
Give tangible form to feelings.
Refresh our vision and help see the world in new ways.
After looking at years of data on arts school graduates as well as policies & 
program outcomes regarding artists, arts, & culture, Elizabeth Lingo and 
Steven Tepper propose the divide between "arts for art's sake" artists and 
commercially successful artists is not as wide as may be perceived, and that 
"this bifurcation between the commercial and the noncommercial, the 
excellent and the base, the elite and the popular, is increasingly breaking 
down" (Eikhof & Haunschild, 2007). Lingo and Tepper point out:[5]

arts consumers don't restrict themselves to either "high" or "common" arts; 
instead, they demonstrate "omnivorous tastes, liking both reggae and 
Rachmaninoff" (Peterson & Kern, 1996; Walker & Scott-Melnyk, 2002)
data indicates "artists are willing to move across sectors and no longer see 
working outside the commercial sector as a badge of distinction or 
authenticity" (Bridgstock, 2013; Ellmeier, 2003)
academic, policy, and government leaders are adapting widening programs 
& opportunities in recognition of "the role of artists as drivers of economic 
growth and innovation" (Bohm & Land, 2009; DCMS, 2006, 2008; Florida, 
2012; Hesmondhalgh & Baker, 2010; Lloyd, 2010; Iyengar, 2013).
arts graduates name "business and management skills" as the "number one 
area [they] wish they had been more exposed to in college" (Strategic 
National Arts Alumni Project [SNAAP], 2011; Tepper & Kuh, 2010).[6]
Examples of art and artists[edit]
Abstract Art: Wassily Kandinsky
Abstract expressionism: Jackson Pollock
Action painting: Willem de Kooning
Actor: Marlon Brando
Actress: Greta Garbo
Animation: Chuck Jones
Appropriation art: Marcel Duchamp
Architect: I.M. Pei
Art Deco: Ert 
Art Nouveau: Louis Comfort Tiffany
Assemblage: Joseph Cornell
Ballet: Margot Fonteyn
Baroque Art: Caravaggio
BioArt: Hunter Cole
Book artist: Carol Barton
Calligraphy: Rudolf Koch
Cartoons: Carl Barks
Caricature: Honor  Daumier
Ceramic art: Peter Voulkos
Choreography: Martha Graham
Collage: Hannah H ch
Color Field: Mark Rothko
Colorist: Josef Albers
Comedy: Charlie Chaplin
Comics: Will Eisner
Composing: Giuseppe Verdi
Conceptual art: Sol LeWitt
Cubism: Pablo Picasso
Dada: Man Ray
Dance: Isadora Duncan
Decollage: Mimmo Rotella
Design: Arne Jacobsen
Digital art: David Em
Doll Maker: Greer Lankton
Etching: Csaba Markus
Expressionism: Edvard Munch
Fashion design: Yves Saint Laurent
Fashion illustration: Joel Resnicoff
Fauvist: Henri Matisse
Fiction writing: Virginia Woolf
Film director: Jean-Luc Godard
Fluxus: George Maciunas
Fumage: Burhan Dogancay
Video game design: Peter Molyneux
Geometric abstraction: Piet Mondrian
Genius: Leonardo da Vinci
Graphic design: Milton Glaser
Happening: Allan Kaprow
Hard-edge painting: Theo van Doesburg
Horticulture: Andr  le N tre
Illustrations: Quentin Blake
Impressionist: Claude Monet
Industrial design: Frank Lloyd Wright
Installation art: Christo and Jeanne-Claude
Instrumental performance: Andr  Rieu
Internet art: Aaron Koblin
Jewelry: Faberg 
Landscape architecture: Frederick Law Olmsted
Landscape art: John Constable
Light art: Dan Flavin
Mail art: Ray Johnson
Minimalist art: Donald Judd
Mosaics: Elaine M Goodwin
Murals: Diego Rivera
Musical Composer: Wolfgang Amadeus Mozart
Musical instrument assemblage: Stradivari
Musical Theatre: Stephen Sondheim
Musician: John Lennon
Neo-impressionism: Paul Signac
Neo-figurative: Ver nica Ruiz de Velasco
New Media art: Ken Feingold
Non Fiction writing: Germaine Greer
Op Art: Bridget Riley
Oration: Cicero
Ornithology: John James Audubon
Outsider art: Howard Finster
Painting: Rembrandt van Rijn
Performance Art: Carolee Schneemann
Performer: Al Jolson
Photography: Ansel Adams
Playwriting: Edward Albee
Poetry: Emily Dickinson
Pointillism: Georges Seurat
Pop Art: Andy Warhol
Posters: Henri de Toulouse-Lautrec
Post-Impressionism: Vincent van Gogh
Pottery: Bernard Leach
Printmaking: Albrecht D rer
Puppetry: Jim Henson
Realism: Ilya Repin
Renaissance art: Michelangelo Buonarroti
Rococo: Antoine Watteau
Sculpture: Auguste Rodin
Singing: Odetta
Songwriting: Joni Mitchell
Stand Up Comedy: Richard Pryor
Street Art: Banksy
Suprematism: Kazimir Malevich
Surrealism: Salvador Dali
Theatre: William Shakespeare
Theatre Arts: Robert Edmond Jones
Theatre Director: Peter Brook
Tragedy: Sophocles
Typography: Eric Gill
Ukiyo-e: Hokusai
Vedette: Susana Gimenez
Video Art: Bill Viola
See also[edit]
Portal icon Arts portal
Art
Art history
Arts by region
Artist in Residence
Fine art
Humanities
List of painters by name
List of painters
List of composers
List of sculptors
Mathematics and art
Social sciences

Applied arts
From Wikipedia, the free encyclopedia

The application of color to these glass cups is an act of applied art since 
they did not need any colour at all to perform their function.

This street-sweeping machine appears to have been streamlined for purely 
aesthetic purposes, since it moves only at the walking pace of the operator.

The Normandie Hotel, in San Juan, Puerto Rico, was inspired by the ocean 
liner SS Normandie. The streamlining of static objects was a common theme 
in Art Deco architecture.
The applied arts are the application of design and decoration to everyday 
objects to make them aesthetically pleasing.[1] The term is applied in 
distinction to the fine arts which aims to produce objects which are beautiful 
and/or provide intellectual stimulation. In practice, the two often overlap.

The fields of industrial design, graphic design, fashion design, interior 
design and the decorative arts are considered applied arts. In a creative 
and/or abstract context, the fields of architecture and photography are also 
considered applied arts.[citation needed]

Contents  [hide] 
1 Movements
2 Museums of Applied Arts
3 See also
4 References
5 Further reading
Movements[edit]
Art Deco
Art Nouveau
Arts and Crafts Movement
Bauhaus
Museums of Applied Arts[edit]
Bauhaus Archive
Die Neue Sammlung, Germany
Leipzig Museum of Applied Arts, Germany
Martin-Gropius-Bau- The School of the Arts at Columbia University offers 
MFA degrees in Film, Theatre Arts, Visual Arts and Writing, an MA degree in 
Film Studies, a joint JD/MFA degree in Theatre Management & Producing, 
and a PhD degree in Theatre History, Literature and Theory.[23]
Juilliard School, New York, NY - is a performing arts conservatory 
established in 1905 it educates and trains undergraduate and graduate 
students in dance, drama, and music. It is widely regarded as one of the 
world's leading music schools, with some of the most prestigious arts 
programs.[24][25][26]

Museum of Applied Arts (Belgrade), Serbia
Museum of Applied Arts (Budapest), Hungary
Museum f r angewandte Kunst Frankfurt, Germany
Museum f r Angewandte Kunst (Cologne), Germany
Museum f r angewandte Kunst Wien, Austria
Museum of Contemporary Design and Applied Arts (MUDAC), Lausanne, 
Switzerland
Powerhouse Museum, Sydney
Stieglitz Museum of Applied Arts (Saint Petersburg), Russia
Prague Museum of Decorative Arts (Prague), Czech Republic
Victoria and Albert Museum, London
See also[edit]
introduced by Papermate in 1979 when the Erasermate was put on the 
Design is the creation of a plan or convention for the construction of an 
object or a system (as in architectural blueprints, engineering drawings, 
business processes, circuit diagrams and sewing patterns).[1] Design has 
different connotations in different fields (see design disciplines below). In 
some cases the direct construction of an object (as in pottery, engineering, 
management, cowboy coding and graphic design) is also considered to be 
design.

Designing often necessitates considering the aesthetic, functional, economic 
and sociopolitical dimensions of both the design object and design process. 
It may involve considerable research, thought, modeling, interactive 
adjustment, and re-design. Meanwhile, diverse kinds of objects may be 
designed, including clothing, graphical user interfaces, skyscrapers, 
corporate identities, business processes and even methods of designing.[2]

Thus "design" may be a substantive referring to a categorical abstraction of 
a created thing or things (the design of something), or a verb for the process 
of creation, as is made clear by grammatical context.

Contents  [hide] 
1 Definitions
2 Design as a process
2.1 The Rational Model
2.1.1 Example sequence of stages
2.1.2 Criticism of the Rational Model
2.2 The Action-Centric Model
2.2.1 Descriptions of design activities
3 Design disciplines
4 Philosophies and studies of design
4.1 Philosophies for guiding design
4.2 Approaches to design
4.3 Methods of designing
5 Terminology
5.1 Design and art
5.2 Design and engineering
5.3 Design and production
5.4 Process design
6 See also
7 Footnotes
8 Bibliography
Definitions[edit]
More formally design has been defined as follows.

(noun) a specification of an object, manifested by an agent, intended to 
accomplish goals, in a particular environment, using a set of primitive 
components, satisfying a set of requirements, subject to constraints;
(verb, transitive) to create a design, in an environment (where the designer 
operates)[3]
Another definition for design is a roadmap or a strategic approach for 
someone to achieve a unique expectation. It defines the specifications, 
plans, parameters, costs, activities, processes and how and what to do 
within legal, political, social, environmental, safety and economic constraints 
in achieving that objective.[4]

Here, a "specification" can be manifested as either a plan or a finished 
product, and "primitives" are the elements from which the design object is 
composed.

With such a broad denotation, there is no universal language or unifying 
institution for designers of all disciplines. This allows for many differing 
philosophies and approaches toward the subject (see Philosophies and 
studies of design, below).

The person designing is called a designer, which is also a term used for 
people who work professionally in one of the various design areas, usually 
also specifying which area is being dealt with (such as a fashion designer, 
concept designer or web designer). A designer's sequence of activities is 
called a design process. The scientific study of design is called design 
science.[5][6][7][8]

Design as a process[edit]
Substantial disagreement exists concerning how designers in many fields, 
whether amateur or professional, alone or in teams, produce designs. Dorst 
and Dijkhuis argued that "there are many ways of describing design 
processes" and discussed "two basic and fundamentally different ways",[9] 
both of which have several names. The prevailing view has been called "The 
Rational Model",[10] "Technical Problem Solving"[11] and "The Reason-
Centric Perspective".[12] The alternative view has been called "Reflection-
in-Action",[11] "Evolutionary Design",[8] "co-evolution"[13] and "The Action-
Centric Perspective".[12]

The Rational Model[edit]
The Rational Model was independently developed by Simon[14] and Pahl 
and Beitz.[15] It posits that:

designers attempt to optimize a design candidate for known constraints and 
objectives,
the design process is plan-driven,
the design process is understood in terms of a discrete sequence of stages.
The Rational Model is based on a rationalist philosophy[10] and underlies 
the waterfall model,[16] systems development life cycle[17] and much of the 
engineering design literature.[18] According to the rationalist philosophy, 
design is informed by research and knowledge in a predictable and 
controlled manner. Technical rationality is at the center of the process.
[citation needed]

Example sequence of stages[edit]
Typical stages consistent with The Rational Model include the following.

Pre-production design
Design brief or Parti pris   an early (often the beginning) statement of design 
goals
Analysis   analysis of current design goals
Research   investigating similar design solutions in the field or related topics
Specification   specifying requirements of a design solution for a product 
(product design specification)[19] or service.
Problem solving   conceptualizing and documenting design solutions
Presentation   presenting design solutions
Design during production
Development   continuation and improvement of a designed solution
Testing   in situ testing a designed solution
Post-production design feedback for future designs
Implementation   introducing the designed solution into the environment
Evaluation and conclusion   summary of process and results, including 
constructive criticism and suggestions for future improvements
Redesign   any or all stages in the design process repeated (with corrections 
made) at any time before, during, or after production.
Each stage has many associated best practices.[20]

Criticism of the Rational Model[edit]
The Rational Model has been widely criticized on two primary grounds

Designers do not work this way   extensive empirical evidence has 
demonstrated that designers do not act as the rational model suggests.[21]
Unrealistic assumptions   goals are often unknown when a design project 
begins, and the requirements and constraints continue to change.[22]
The Action-Centric Model[edit]
The Action-Centric Perspective is a label given to a collection of interrelated 
concepts, which are antithetical to The Rational Model.[12] It posits that:

designers use creativity and emotion to generate design candidates,
the design process is improvised,
no universal sequence of stages is apparent   analysis, design and 
implementation are contemporary and inextricably linked[12]
The Action-Centric Perspective is based on an empiricist philosophy and 
broadly consistent with the Agile approach[23] and amethodical 
development.[24] Substantial empirical evidence supports the veracity of this 
perspective in describing the actions of real designers.[21] Like the Rational 
Model, the Action-Centric model sees design as informed by research and 
knowledge. However, research and knowledge are brought into the design 
process through the judgment and common sense of designers   by 
designers "thinking on their feet"   more than through the predictable and 
controlled process stipulated by the Rational Model. Designers' context-
dependent experience and professional judgment take center stage more 
than technical rationality.[citation needed]

Descriptions of design activities[edit]
At least two views of design activity are consistent with the Action-Centric 
Perspective. Both involve three basic activities.

In the Reflection-in-Action paradigm, designers alternate between "framing", 
"making moves", and "evaluate moves." "Framing" refers to conceptualizing 
the problem, i.e., defining goals and objectives. A "move" is a tentative 
design decision. The evaluation process may lead to further moves in the 
design.[11]

In the Sensemaking-Coevolution-Implementation Framework, designers 
alternate between its three titular activities. Sensemaking includes both 
framing and evaluating moves. Implementation is the process of constructing 
the design object. Coevolution is "the process where the design agent 
simultaneously refines its mental picture of the design object based on its 
mental picture of the context, and vice versa."[25]

The concept of the Design Cycle is understood as a circular time structure,
[26] which may start with the thinking of an idea, then expressing it by the 
use of visual and/or verbal means of communication (design tools), the 
sharing and perceiving of the expressed idea, and finally starting a new 
cycle with the critical rethinking of the perceived idea. Anderson points out 
that this concept emphasizes the importance of the means of expression, 
which at the same time are means of perception of any design ideas.[27]

Design disciplines[edit]
Applied arts
Architecture
Automotive design
Biological design
Communication design
Configuration design
Engineering design
Environmental graphic design
Fashion design
Game design
Graphic design
Information architecture
Industrial design
Instructional design
Interaction design
Interior design
Landscape architecture
Lighting design
Military design methodology[28]
Modular design
Motion graphic design
Product design
Process design
Service design
Software design
Sound design
Systems architecture
Systems design
Systems modeling
Transition design
Urban design
User experience design
Visual design
Web design
Philosophies and studies of design[edit]
There are countless philosophies for guiding design as the design values 
and its accompanying aspects within modern design vary, both between 
different schools of thought and among practicing designers.[29] Design 
philosophies are usually for determining design goals. A design goal may 
range from solving the least significant individual problem of the smallest 
element, to the most holistic influential utopian goals. Design goals are 
usually for guiding design. However, conflicts over immediate and minor 
goals may lead to questioning the purpose of design, perhaps to set better 
long term or ultimate goals.

Philosophies for guiding design[edit]
Design philosophies are fundamental guiding principles that dictate how a 
designer approaches his/her practice. Reflections on material culture and 
environmental concerns (sustainable design) can guide a design philosophy. 
One example is the First Things First manifesto which was launched within 
the graphic design community and states "We propose a reversal of 
priorities in favor of more useful, lasting and democratic forms of 
communication   a mindshift away from product marketing and toward the 
exploration and production of a new kind of meaning. The scope of debate is 
shrinking; it must expand. Consumerism is running uncontested; it must be 
challenged by other perspectives expressed, in part, through the visual 
languages and resources of design."[30]

In The Sciences of the Artificial by polymath Herbert A. Simon the author 
asserts design to be a meta-discipline of all professions. "Engineers are not 
the only professional designers. Everyone designs who devises courses of 
action aimed at changing existing situations into preferred ones. The 
intellectual activity that produces material artifacts is no different 
fundamentally from the one that prescribes remedies for a sick patient or the 
one that devises a new sales plan for a company or a social welfare policy 
for a state. Design, so construed, is the core of all professional training; it is 
the principal mark that distinguishes the professions from the sciences. 
Schools of engineering, as well as schools of architecture, business, 
education, law, and medicine, are all centrally concerned with the process of 
design."[31]

Approaches to design[edit]
A design approach is a general philosophy that may or may not include a 
guide for specific methods. Some are to guide the overall goal of the design. 
Other approaches are to guide the tendencies of the designer. A 
combination of approaches may be used if they don't conflict.

Some popular approaches include:

KISS principle, (Keep it Simple Stupid), which strives to eliminate 
unnecessary complications.
There is more than one way to do it (TIMTOWTDI), a philosophy to allow 
multiple methods of doing the same thing.
Use-centered design, which focuses on the goals and tasks associated with 
the use of the artifact, rather than focusing on the end user.
User-centered design, which focuses on the needs, wants, and limitations of 
the end user of the designed artifact.
Critical design uses designed artifacts as an embodied critique or 
commentary on existing values, morals, and practices in a culture.
Service design designing or organizing the experience around a product, the 
service associated with a product's use.
Transgenerational design, the practice of making products and environments 
compatible with those physical and sensory impairments associated with 
human aging and which limit major activities of daily living.
Speculative design, the speculative design process doesn t necessarily 
define a specific problem to solve, but establishes a provocative starting 
point from which a design process emerges. The result is an evolution of 
fluctuating iteration and reflection using designed objects to provoke 
questions and stimulate discussion in academic and research settings.
Methods of designing[edit]
Main article: Design methods
Design methods is a broad area that focuses on:

Exploring possibilities and constraints by focusing critical thinking skills to 
research and define problem spaces for existing products or services or the 
creation of new categories; (see also Brainstorming)
Redefining the specifications of design solutions which can lead to better 
guidelines for traditional design activities (graphic, industrial, architectural, 
etc.);
Managing the process of exploring, defining, creating artifacts continually 
over time
Prototyping possible scenarios, or solutions that incrementally or 
significantly improve the inherited situation
Trendspotting; understanding the trend process.
Terminology[edit]
The word "design" is often considered ambiguous, as it is applied differently 
in a varying contexts.


The new terminal at Barajas airport in Madrid, Spain
Design and art[edit]
Today the term design is widely associated with the Applied arts as initiated 
by Raymond Loewy and teachings at the Bauhaus and Ulm School of 
Design (HfG Ulm) in Germany during the 20th Century.

The boundaries between art and design are blurred, largely due to a range 
of applications both for the term 'art' and the term 'design'. Applied arts has 
been used as an umbrella term to define fields of industrial design, graphic 
design, fashion design, etc. The term 'decorative arts' is a traditional term 
used in historical discourses to describe craft objects, and also sits within 
the umbrella of Applied arts. In graphic arts (2D image making that ranges 
from photography to illustration) the distinction is often made between fine 
art and commercial art, based on the context within which the work is 
produced and how it is traded.

To a degree, some methods for creating work, such as employing intuition, 
are shared across the disciplines within the Applied arts and Fine art. Mark 
Getlein suggests the principles of design are "almost instinctive", "built-in", 
"natural", and part of "our sense of 'rightness'."[32] However, the intended 
application and context of the resulting works will vary greatly.


A drawing for a booster engine for steam locomotives. Engineering is applied 
to design, with emphasis on function and the utilization of mathematics and 
science.
Design and engineering[edit]
In engineering, design is a component of the engineering process. Many 
overlapping methods and processes can be seen when comparing Product 
design, Industrial design and Engineering. The American Heritage Dictionary 
defines design as: "To conceive or fashion in the mind; invent," and "To 
formulate a plan", and defines engineering as: "The application of scientific 
and mathematical principles to practical ends such as the design, 
manufacture, and operation of efficient and economical structures, 
machines, processes, and systems.".[33][34] Both are forms of problem-
solving with a defined distinction being the application of "scientific and 
mathematical principles". The increasingly scientific focus of engineering in 
practice, however, has raised the importance of new more "human-centered" 
fields of design.[35] How much science is applied in a design is a question 
of what is considered "science". Along with the question of what is 
considered science, there is social science versus natural science. Scientists 
at Xerox PARC made the distinction of design versus engineering at "moving 
minds" versus "moving atoms" (probably in cotradiction to the origin of term 
"engineering - engineer" from Latin "in genio" in meaning of a "genius" what 
assumes existence of a "mind" not of an "atom").


Jonathan Ive has received several awards for his design of Apple Inc. 
products like this MacBook. In some design fields, personal computers are 
also used for both design and production
Design and production[edit]
The relationship between design and production is one of planning and 
executing. In theory, the plan should anticipate and compensate for potential 
problems in the execution process. Design involves problem-solving and 
creativity. In contrast, production involves a routine or pre-planned process. A 
design may also be a mere plan that does not include a production or 
engineering processes although a working knowledge of such processes is 
usually expected of designers. In some cases, it may be unnecessary and/or 
impractical to expect a designer with a broad multidisciplinary knowledge 
required for such designs to also have a detailed specialized knowledge of 
how to produce the product.

Design and production are intertwined in many creative professional careers, 
meaning problem-solving is part of execution and the reverse. As the cost of 
rearrangement increases, the need for separating design from production 
increases as well. For example, a high-budget project, such as a skyscraper, 
requires separating (design) architecture from (production) construction. A 
Low-budget project, such as a locally printed office party invitation flyer, can 
be rearranged and printed dozens of times at the low cost of a few sheets of 
paper, a few drops of ink, and less than one hour's pay of a desktop 
publisher.

This is not to say that production never involves problem-solving or creativity, 
nor that design always involves creativity. Designs are rarely perfect and are 
sometimes repetitive. The imperfection of a design may task a production 
position (e.g. production artist, construction worker) with utilizing creativity or 
problem-solving skills to compensate for what was overlooked in the design 
process. Likewise, a design may be a simple repetition (copy) of a known 
preexisting solution, requiring minimal, if any, creativity or problem-solving 
skills from the designer.


An example of a business workflow process using Business Process 
Modeling Notation.
Process design[edit]
See also: Method engineering
"Process design" (in contrast to "design process" mentioned above) refers to 
the planning of routine steps of a process aside from the expected result. 
Processes (in general) are treated as a product of design, not the method of 
design. The term originated with the industrial designing of chemical 
processes. With the increasing complexities of the information age, 
consultants and executives have found the term useful to describe the 
design of business processes as well as manufacturing processes.



See also[edit]
Design elements and principles
Design-based learning
Footnotes[edit]
Jump up ^ Dictionary meanings in the Cambridge Dictionary of American 
English, at Dictionary.com (esp. meanings 1 5 and 7 8) and at AskOxford 
(esp. verbs).
Jump up ^ Brinkkemper, S. (1996). "Method engineering: engineering of 
information systems development methods and tools". Information and 
Software Technology 38 (4): 275 280. doi:10.1016/0950-5849(95)01059-9.
Jump up ^ Ralph, P. and Wand, Y. (2009). A proposal for a formal definition 
of the design concept. In Lyytinen, K., Loucopoulos, P., Mylopoulos, J., and 
Robinson, W., editors, Design Requirements Workshop (LNBIP 14), pp. 103 
136. Springer-Verlag, p. 109 doi:10.1007/978-3-540-92966-6_6.
Jump up ^ Don Kumaragamage, Y. (2011). Design Manual Vol 1
Jump up ^ Simon (1996)
Jump up ^ Alexander, C. (1964) Notes on the Synthesis of Form, Harvard 
University Press.
Jump up ^ Eekels, J. (2000). "On the Fundamentals of Engineering Design 
Science: The Geography of Engineering Design Science, Part 1". Journal of 
Engineering Design 11 (4): 377 397. doi:10.1080/09544820010000962.
^ Jump up to: a b Braha, D. and Maimon, O. (1998) A Mathematical Theory 
of Design, Springer.
Jump up ^ Dorst and Dijkhuis 1995, p. 261
^ Jump up to: a b Brooks 2010
^ Jump up to: a b c Sch n 1983
^ Jump up to: a b c d Ralph 2010
Jump up ^ Dorst and Cross 2001
Jump up ^ Newell and Simon 1972; Simon 1969
Jump up ^ Pahl and Beitz 1996
Jump up ^ Royce 1970
Jump up ^ Bourque and Dupuis 2004
Jump up ^ Pahl et al. 2007
Jump up ^ Cross, N., 2006. T211 Design and Designing: Block 2, p. 99. 
Milton Keynes: The Open University.
Jump up ^ Ullman, David G. (2009) The Mechanical Design Process, Mc 
Graw Hill, 4th edition ISBN 0-07-297574-1
^ Jump up to: a b Cross et al. 1992; Ralph 2010; Sch n 1983
Jump up ^ Brooks 2010; McCracken and Jackson 1982
Jump up ^ Beck et al. 2001
Jump up ^ Truex et al. 2000
Jump up ^ Ralph 2010, p. 67
Jump up ^ Thomas Fischer: Design Enigma. A typographical metaphor for 
enigmatic processes, including designing, in: T. Fischer, K. De Biswas, J.J. 
Ham, R. Naka, W.X. Huang, Beyond Codes and Pixels: Proceedings of the 
17th International Conference on Computer-Aided Architectural Design 
Research in Asia, p. 686
Jump up ^ Jane Anderson: Architectural Design, Basics Architecture 03, 
Lausanne, AVA academia, 2011, ISBN 978-2-940411-26-9, p. 40
Jump up ^ Headquarters, Department of the Army (May 2012). ADRP 5-0: 
The Operations Process. Washington D.C.: United States Army. pp. 2 4 to 2 
11.
Jump up ^ Holm, Ivar (2006). Ideas and Beliefs in Architecture and Industrial 
design: How attitudes, orientations and underlying assumptions shape the 
built environment. Oslo School of Architecture and Design. ISBN 82-547-
0174-1.
Jump up ^ First Things First 2000 a design manifesto. manifesto published 
jointly by 33 signatories in: Adbusters, the AIGA journal, Blueprint, Emigre, 
Eye, Form, Items fall 1999/spring 2000
Jump up ^ Simon (1996), p. 111.
Jump up ^ Mark Getlein, Living With Art, 8th ed. (New York: 2008) 121.
Jump up ^ American Psychological Association (APA): design. The American 
Heritage Dictionary of the English Language, Fourth Edition. Retrieved 
January 10, 2007
Jump up ^ American Psychological Association (APA): engineering. The 
American Heritage Dictionary of the English Language, Fourth Edition. 
Retrieved January 10, 2007
Jump up ^ Faste 2001
Bibliography[edit]
  Look up design in Wiktionary, the free dictionary.
  Wikiquote has quotations related to: Design
  Wikimedia Commons has media related to Design.
Library resources about
Design
Resources in your library
Beck, K., Beedle, M., van Bennekum, A., Cockburn, A., Cunningham, W., 
Fowler, M., Grenning, J., Highsmith, J., Hunt, A., Jeffries, R., Kern, J., 
Marick, B., Martin, R.C., Mellor, S., Schwaber, K., Sutherland, J., and 
Thomas, D. Manifesto for agile software development, 2001.
Bourque, P., and Dupuis, R. (eds.) Guide to the software engineering body 
of knowledge (SWEBOK). IEEE Computer Society Press, 2004 ISBN 0-7695
-2330-7.
Brooks, F.P. The design of design: Essays from a computer scientist, 
Addison-Wesley Professional, 2010 ISBN 0-201-36298-8.
Cross, N., Dorst, K., and Roozenburg, N. Research in design thinking, Delft 
University Press, Delft, 1992 ISBN 90-6275-796-0.
Dorst, K., and Cross, N. (2001). "Creativity in the design process: Co-
evolution of problem-solution". Design Studies 22 (2): 425 437. 
doi:10.1016/0142-694X(94)00012-3.
Dorst, K., and Dijkhuis, J. "Comparing paradigms for describing design 
activity," Design Studies (16:2) 1995, pp 261 274.
Faste, R. (2001). "The Human Challenge in Engineering Design" (PDF). 
International Journal of Engineering Education 17 (4 5): 327 331.
McCracken, D.D., and Jackson, M.A. (1982). "Life cycle concept considered 
harmful". SIGSOFT Software Engineering Notes 7 (2): 29 32. 
doi:10.1145/1005937.1005943.
Newell, A., and Simon, H. Human problem solving, Prentice-Hall, Inc., 1972.
Pahl, G., and Beitz, W. Engineering design: A systematic approach, 
Springer-Verlag, London, 1996 ISBN 3-540-19917-9.
Pahl, G., Beitz, W., Feldhusen, J., and Grote, K.-H. Engineering design: A 
systematic approach, (3rd ed.), Springer-Verlag, 2007 ISBN 1-84628-318-3.
Ralph, P. "Comparing two software design process theories," International 
Conference on Design Science Research in Information Systems and 
Technology (DESRIST 2010), Springer, St. Gallen, Switzerland, 2010, pp. 
139 153.
Royce, W.W. "Managing the development of large software systems: 
Concepts and techniques," Proceedings of Wescon, 1970.
Sch n, D.A. The reflective practitioner: How professionals think in action, 
Basic Books, USA, 1983.
Simon, H.A. The sciences of the artificial, MIT Press, Cambridge, MA, USA, 
1996 ISBN 0-262-69191-4.
Truex, D., Baskerville, R., and Travis, J. (2000). "Amethodical systems 
development: The deferred meaning of systems development methods". 
Accounting, Management and Information Technologies 10 (1): 53 79. 
doi:10.1016/S0959-8022(99)00009-0.

rchitecture
From Wikipedia, the free encyclopedia
For the professional, see Architect. For other uses, see Architecture 
(disambiguation).
View of Florence showing the dome, which dominates everything around it. It 
is octagonal in plan and ovoid in section. It has wide ribs rising to the apex 
with red tiles in between and a marble lantern on top.
Brunelleschi, in the building of the dome of Florence Cathedral in the early 
15th-century, not only transformed the building and the city, but also the role 
and status of the architect.[1][2]

Section of Beauvais Cathedral, gothic architecture of the 13th century.
Architecture (Latin architectura, from the Greek            arkhitekton 
"architect", from     - "chief" and        "builder") is both the process and the 
product of planning, designing, and constructing buildings and other 
physical structures. Architectural works, in the material form of buildings, are 
often perceived as cultural symbols and as works of art. Historical 
civilizations are often identified with their surviving architectural 
achievements.

"Architecture" can mean:

A general term to describe buildings and other physical structures.[3]
The art and science of designing buildings and (some) nonbuilding 
structures.[3]
The style of design and method of construction of buildings and other 
physical structures.[3]
The knowledge of art, science & technology and humanity.[3]
The practice of the architect, where architecture means offering or rendering 
professional services in connection with the design and construction of 
buildings, or built environments.[4]
The design activity of the architect,[3] from the macro-level (urban design, 
landscape architecture) to the micro-level (construction details and 
furniture).
Architecture has to do with planning and designing form, space and 
ambience to reflect functional, technical, social, environmental and aesthetic 
considerations. It requires the creative manipulation and coordination of 
materials and technology, and of light and shadow. Often, conflicting 
requirements must be resolved. The practice of Architecture also 
encompasses the pragmatic aspects of realizing buildings and structures, 
including scheduling, cost estimation and construction administration. 
Documentation produced by architects, typically drawings, plans and 
technical specifications, defines the structure and/or behavior of a building 
or other kind of system that is to be or has been constructed.

The word "architecture" has also been adopted to describe other designed 
systems, especially in information technology.[3]

Contents  [hide] 
1 Theory of architecture
1.1 Historic treatises
1.2 Modern concepts of architecture
2 History
2.1 Origins and vernacular architecture
2.2 Ancient architecture
2.3 Asian architecture
2.4 Islamic architecture
2.5 Middle Ages
2.6 Renaissance and the architect
2.7 Early modern and the industrial age
2.8 Modernism
2.9 Postmodernism
2.10  Architecture today
3 See also
4 Notes
5 References
6 External links
Theory of architecture[edit]
Main article: Architectural theory
Historic treatises[edit]
The Parthenon is a rectangular building of white marble with eight columns 
supporting a pediment at the front, and a long line of columns visible at the 
side
The Parthenon, Athens, Greece, "the supreme example among architectural 
sites." (Fletcher).[5]
The earliest surviving written work on the subject of architecture is De 
architectura, by the Roman architect Vitruvius in the early 1st century AD.[6] 
According to Vitruvius, a good building should satisfy the three principles of 
firmitas, utilitas, venustas,[7][8] commonly known by the original translation   
firmness, commodity and delight. An equivalent in modern English would be:

Durability   a building should stand up robustly and remain in good 
condition.
Utility   it should be suitable for the purposes for which it is used.
Beauty   it should be aesthetically pleasing.
According to Vitruvius, the architect should strive to fulfill each of these three 
attributes as well as possible. Leon Battista Alberti, who elaborates on the 
ideas of Vitruvius in his treatise, De Re Aedificatoria, saw beauty primarily as 
a matter of proportion, although ornament also played a part. For Alberti, the 
rules of proportion were those that governed the idealised human figure, the 
Golden mean. The most important aspect of beauty was therefore an 
inherent part of an object, rather than something applied superficially; and 
was based on universal, recognisable truths. The notion of style in the arts 
was not developed until the 16th century, with the writing of Vasari:[9] by the 
18th century, his Lives of the Most Excellent Painters, Sculptors, and 
Architects had been translated into Italian, French, Spanish and English.

The Houses of Parliament in London, seen across the river, are a large 
Victorian Gothic building with two big towers and many pinnacles
The Houses of Parliament, Westminster, master-planned by Charles Barry, 
with interiors and details by A.W.N. Pugin
In the early 19th century, Augustus Welby Northmore Pugin wrote Contrasts 
(1836) that, as the titled suggested, contrasted the modern, industrial world, 
which he disparaged, with an idealized image of neo-medieval world. Gothic 
architecture, Pugin believed, was the only "true Christian form of 
architecture."

The 19th-century English art critic, John Ruskin, in his Seven Lamps of 
Architecture, published 1849, was much narrower in his view of what 
constituted architecture. Architecture was the "art which so disposes and 
adorns the edifices raised by men ... that the sight of them" contributes "to 
his mental health, power, and pleasure".[10]

For Ruskin, the aesthetic was of overriding significance. His work goes on to 
state that a building is not truly a work of architecture unless it is in some 
way "adorned". For Ruskin, a well-constructed, well-proportioned, functional 
building needed string courses or rustication, at the very least.[10]

On the difference between the ideals of architecture and mere construction, 
the renowned 20th-century architect Le Corbusier wrote: "You employ stone, 
wood, and concrete, and with these materials you build houses and palaces: 
that is construction. Ingenuity is at work. But suddenly you touch my heart, 
you do me good. I am happy and I say: This is beautiful. That is 
Architecture".[11]

Le Corbusier's contemporary Ludwig Mies van der Rohe said "Architecture 
starts when you carefully put two bricks together. There it begins."[12]

 The view shows a 20th-century building with two identical towers very close 
to each other rising from a low building which has a dome at one end, and 
an inverted dome, like a saucer, at the other.
The National Congress of Brazil, designed by Oscar Niemeyer
Modern concepts of architecture[edit]
The notable 19th-century architect of skyscrapers, Louis Sullivan, promoted 
an overriding precept to architectural design: "Form follows function".

While the notion that structural and aesthetic considerations should be 
entirely subject to functionality was met with both popularity and skepticism, 
it had the effect of introducing the concept of "function" in place of Vitruvius' 
"utility". "Function" came to be seen as encompassing all criteria of the use, 
perception and enjoyment of a building, not only practical but also aesthetic, 
psychological and cultural.

The Sydney Opera House appears to float on the harbour. It has numerous 
roof-sections which are shaped like huge shining white sails
Sydney Opera House, Australia designed by J rn Utzon
Nunzia Rondanini stated, "Through its aesthetic dimension architecture goes 
beyond the functional aspects that it has in common with other human 
sciences. Through its own particular way of expressing values, architecture 
can stimulate and influence social life without presuming that, in and of 
itself, it will promote social development.'

To restrict the meaning of (architectural) formalism to art for art's sake is not 
only reactionary; it can also be a purposeless quest for perfection or 
originality which degrades form into a mere instrumentality".[13]

Among the philosophies that have influenced modern architects and their 
approach to building design are rationalism, empiricism, structuralism, 
poststructuralism, and phenomenology.

In the late 20th century a new concept was added to those included in the 
compass of both structure and function, the consideration of sustainability, 
hence sustainable architecture. To satisfy the contemporary ethos a building 
should be constructed in a manner which is environmentally friendly in terms 
of the production of its materials, its impact upon the natural and built 
environment of its surrounding area and the demands that it makes upon 
non-sustainable power sources for heating, cooling, water and waste 
management and lighting.

History[edit]
Main article: History of architecture
Origins and vernacular architecture[edit]
Main article: Vernacular architecture
A small hut composed entirely of split logs, and raised above the ground on 
stout upright stumps.
Vernacular architecture in Norway
Building first evolved out of the dynamics between needs (shelter, security, 
worship, etc.) and means (available building materials and attendant skills). 
As human cultures developed and knowledge began to be formalized 
through oral traditions and practices, building became a craft, and 
"architecture" is the name given to the most highly formalized and respected 
versions of that craft.

It is widely assumed that architectural success was the product of a process 
of trial and error, with progressively less trial and more replication as the 
results of the process proved increasingly satisfactory. What is termed 
vernacular architecture continues to be produced in many parts of the world. 
Indeed, vernacular buildings make up most of the built world that people 
experience every day. Early human settlements were mostly rural. Due to a 
surplus in production the economy began to expand resulting in 
urbanization thus creating urban areas which grew and evolved very rapidly 
in some cases, such as that of  atal H y k in Anatolia and Mohenjo Daro of 
the Indus Valley Civilization in modern-day Pakistan.

The three main Pyramids at Gizeh shown rising from the desert sands with 
three smaller pyramids in front of them
The Pyramids at Giza in Egypt
Ancient architecture[edit]
In many ancient civilizations, such as those of Egypt and Mesopotamia, 
architecture and urbanism reflected the constant engagement with the divine 
and the supernatural, and many ancient cultures resorted to monumentality 
in architecture to represent symbolically the political power of the ruler, the 
ruling elite, or the state itself.

The architecture and urbanism of the Classical civilizations such as the 
Greek and the Roman evolved from civic ideals rather than religious or 
empirical ones and new building types emerged. Architectural "style" 
developed in the form of the Classical orders.

Texts on architecture have been written since ancient time. These texts 
provided both general advice and specific formal prescriptions or canons. 
Some examples of canons are found in the writings of the 1st-century BCE 
Roman Architect Vitruvius. Some of the most important early examples of 
canonic architecture are religious.

 The Golden Pavilion is a building of three storeys with encircling balconies 
and curving roofs, overlooking a tranquil lake and woods
Kinkaku-ji (Golden Pavilion), Kyoto, Japan
Asian architecture[edit]
Early Asian writings on architecture include the Kao Gong Ji of China from 
the 7th 5th centuries BCE; the Shilpa Shastras of ancient India and Manjusri 
Vasthu Vidya Sastra of Sri Lanka.

The architecture of different parts of Asia developed along different lines 
from that of Europe; Buddhist, Hindu and Sikh architecture each having 
different characteristics. Buddhist architecture, in particular, showed great 
regional diversity. Hindu temple architecture, which developed around the 
3rd century BCE, is governed by concepts laid down in the Shastras, and is 
concerned with expressing the macrocosm and the microcosm. In many 
Asian countries, pantheistic religion led to architectural forms that were 
designed specifically to enhance the natural landscape.

The Taj Mahal is a mosque-like structure of white marble with an onion-
shaped dome, and a tall marble minaret at each corner
The Taj Mahal (1632 1653), in India
Islamic architecture[edit]
Main article: Islamic architecture
Islamic architecture began in the 7th century CE, incorporating architectural 
forms from the ancient Middle East and Byzantium, but also developing 
features to suit the religious and social needs of the society. Examples can 
be found throughout the Middle East, North Africa, Spain and the Indian 
Sub-continent. The widespread application of the pointed arch was to 
influence European architecture of the Medieval period.

Middle Ages[edit]
Notre Dame, Paris, is a grand Gothic cathedral with Towers at one end and a 
small spire rising from the centre of the roof.
Notre Dame de Paris, France
In Europe during the Medieval period, guilds were formed by craftsmen to 
organise their trades and written contracts have survived, particularly in 
relation to ecclesiastical buildings. The role of architect was usually one with 
that of master mason, or Magister lathomorum as they are sometimes 
described in contemporary documents.

The major architectural undertakings were the buildings of abbeys and 
cathedrals. From about 900 CE onwards, the movements of both clerics and 
tradesmen carried architectural knowledge across Europe, resulting in the 
pan-European styles Romanesque and Gothic.

La Rotunda is a domed domestic building of which two sides can be seen, 
with identical classical porticos, indicating that it is the same on all sides.
La Rotonda (1567), Italy by Palladio
Renaissance and the architect[edit]
Main article: Renaissance architecture
In Renaissance Europe, from about 1400 onwards, there was a revival of 
Classical learning accompanied by the development of Renaissance 
Humanism which placed greater emphasis on the role of the individual in 
society than had been the case during the Medieval period. Buildings were 
ascribed to specific architects   Brunelleschi, Alberti, Michelangelo, Palladio   
and the cult of the individual had begun. There was still no dividing line 
between artist, architect and engineer, or any of the related vocations, and 
the appellation was often one of regional preference.

A revival of the Classical style in architecture was accompanied by a 
burgeoning of science and engineering which affected the proportions and 
structure of buildings. At this stage, it was still possible for an artist to design 
a bridge as the level of structural calculations involved was within the scope 
of the generalist.

Early modern and the industrial age[edit]
The Opera House in Paris is an ornate 19th century building decorated with 
much sculptured detail.
Paris Opera by Charles Garnier (1875), France
With the emerging knowledge in scientific fields and the rise of new 
materials and technology, architecture and engineering began to separate, 
and the architect began to concentrate on aesthetics and the humanist 
aspects, often at the expense of technical aspects of building design. There 
was also the rise of the "gentleman architect" who usually dealt with wealthy 
clients and concentrated predominantly on visual qualities derived usually 
from historical prototypes, typified by the many country houses of Great 
Britain that were created in the Neo Gothic or Scottish Baronial styles. 
Formal architectural training in the 19th century, for example at  cole des 
Beaux-Arts in France, gave much emphasis to the production of beautiful 
drawings and little to context and feasibility. Effective architects generally 
received their training in the offices of other architects, graduating to the role 
from draughtsmen or clerks.

Meanwhile, the Industrial Revolution laid open the door for mass production 
and consumption. Aesthetics became a criterion for the middle class as 
ornamented products, once within the province of expensive craftsmanship, 
became cheaper under machine production.

Vernacular architecture became increasingly ornamental. House builders 
could use current architectural design in their work by combining features 
found in pattern books and architectural journals.

Modernism[edit]
Main article: Modern architecture

The Bauhaus Dessau architecture department from 1925 by Walter Gropius
Around the beginning of the 20th century, a general dissatisfaction with the 
emphasis on revivalist architecture and elaborate decoration gave rise to 
many new lines of thought that served as precursors to Modern Architecture. 
Notable among these is the Deutscher Werkbund, formed in 1907 to 
produce better quality machine made objects. The rise of the profession of 
industrial design is usually placed here. Following this lead, the Bauhaus 
school, founded in Weimar, Germany in 1919, redefined the architectural 
bounds prior set throughout history, viewing the creation of a building as the 
ultimate synthesis the apex of art, craft, and technology.

When modern architecture was first practiced, it was an avant-garde 
movement with moral, philosophical, and aesthetic underpinnings. 
Immediately after World War I, pioneering modernist architects sought to 
develop a completely new style appropriate for a new post-war social and 
economic order, focused on meeting the needs of the middle and working 
classes. They rejected the architectural practice of the academic refinement 
of historical styles which served the rapidly declining aristocratic order. The 
approach of the Modernist architects was to reduce buildings to pure forms, 
removing historical references and ornament in favor of functionalist details. 
Buildings displayed their functional and structural elements, exposing steel 
beams and concrete surfaces instead of hiding them behind decorative 
forms.


Fallingwater, organic architecture by Frank Lloyd Wright
Architects such as Frank Lloyd Wright developed Organic architecture, in 
which the form was defined by its environment and purpose, with an aim to 
promote harmony between human habitation and the natural world with 
prime examples being Robie House and Fallingwater.

The Crystal Cathedral is a built in a modern style with panels of glass set in 
metal frames making both the walls and roof. A tall tower of the same 
materials rises beside it
The Crystal Cathedral, California, by Philip Johnson (1980)
Architects such as Mies van der Rohe, Philip Johnson and Marcel Breuer 
worked to create beauty based on the inherent qualities of building materials 
and modern construction techniques, trading traditional historic forms for 
simplified geometric forms, celebrating the new means and methods made 
possible by the Industrial Revolution, including steel-frame construction, 
which gave birth to high-rise superstructures. By mid-century, Modernism 
had morphed into the International Style, an aesthetic epitomized in many 
ways by the Twin Towers of New York's World Trade Center designed by 
Minoru Yamasaki.

Postmodernism[edit]
Many architects resisted modernism, finding it devoid of the decorative 
richness of historical styles. As the first generation of modernists began to 
die after WWII, a second generation of architects including Paul Rudolph, 
Marcel Breuer, and Eero Saarinen tried to expand the aesthetics of 
modernism with Brutalism, buildings with expressive sculptural fa ades 
made of unfinished concrete. But an even new younger postwar generation 
critiqued modernism and Brutalism for being too austere, standardized, 
monotone, and not taking into account the richness of human experience 
offered in historical buildings across time and in different places and 
cultures.

One such reaction to the cold aesthetic of modernism and Brutalism is the 
school of metaphoric architecture, which includes such things as 
biomorphism and zoomorphic architecture, both using nature as the primary 
source of inspiration and design. While it is considered by some to be 
merely an aspect of postmodernism, others consider it to be a school in its 
own right and a later development of expressionist architecture.[14]

Beginning in the late 1950s and 1960s, architectural phenomenology 
emerged as an important movement in the early reaction against modernism, 
with architects like Charles Moore in the USA, Christian Norberg-Schulz in 
Norway, and Ernesto Nathan Rogers and Vittorio Gregotti in Italy, who 
collectively popularized an interest in a new contemporary architecture 
aimed at expanding human experience using historical buildings as models 
and precedents.[15] Postmodernism produced a style that combined 
contemporary building technology and cheap materials, with the aesthetics 
of older pre-modern and non-modern styles, from high classical architecture 
to popular or vernacular regional building styles. Robert Venturi famously 
defined postmodern architecture as a "decorated shed" (an ordinary building 
which is functionally designed inside and embellished on the outside), and 
upheld it against modernist and brutalist "ducks" (buildings with 
unnecessarily expressive tectonic forms).[16]

Architecture today[edit]
The Railway station in Lisbon has a fibreglass roof supported on piers with 
radiating arms resembling Gothic columns, arches and vaults
Postmodern design at Gare do Oriente, Lisbon, Portugal, by Spanish 
architect Santiago Calatrava
Since the 1980s, as the complexity of buildings began to increase (in terms 
of structural systems, services, energy and technologies), the field of 
architecture became multi-disciplinary with specializations for each project 
type, technological expertise or project delivery methods. In addition, there 
has been an increased separation of the 'design' architect [Notes 1] from the 
'project' architect who ensures that the project meets the required standards 
and deals with matters of liability.[Notes 2] The preparatory processes for the 
design of any large building have become increasingly complicated, and 
require preliminary studies of such matters as durability, sustainability, 
quality, money, and compliance with local laws. A large structure can no 
longer be the design of one person but must be the work of many. 
Modernism and Postmodernism have been criticised by some members of 
the architectural profession who feel that successful architecture is not a 
personal, philosophical, or aesthetic pursuit by individualists; rather it has to 
consider everyday needs of people and use technology to create liveable 
environments, with the design process being informed by studies of 
behavioral, environmental, and social sciences.

 A low building has a roof completely covered with soil and grass. It appears 
to be built into a hillside
Green roof planted with native species at L'Historial de la Vend e, a new 
museum in western France
Environmental sustainability has become a mainstream issue, with profound 
effect on the architectural profession. Many developers, those who support 
the financing of buildings, have become educated to encourage the 
facilitation of environmentally sustainable design, rather than solutions 
based primarily on immediate cost. Major examples of this can be found in 
Passive solar building design, greener roof designs, biodegradable 
materials, and more attention to a structure's energy usage. This major shift 
in architecture has also changed architecture schools to focus more on the 
environment. Sustainability in architecture was pioneered by Frank Lloyd 
Wright, in the 1960s by Buckminster Fuller and in the 1970s by architects 
such as Ian McHarg and Sim Van der Ryn in the US and Brenda and Robert 
Vale in the UK and New Zealand. There has been an acceleration in the 
number of buildings which seek to meet green building sustainable design 
principles. Sustainable practices that were at the core of vernacular 
architecture increasingly provide inspiration for environmentally and socially 
sustainable contemporary techniques.[17] The U.S. Green Building 
Council's LEED (Leadership in Energy and Environmental Design) rating 
system has been instrumental in this.[18]

Concurrently, the recent movements of New Urbanism, Metaphoric 
architecture and New Classical Architecture promote a sustainable approach 
towards construction, that appreciates and develops smart growth, 
architectural tradition and classical design.[19][20] This in contrast to 
modernist and globally uniform architecture, as well as leaning against 
solitary housing estates and suburban sprawl.[21]

See also[edit]

Angkor Wat, Cambodia, symmetry and elevation have often been utilised in 
the architectural expression of religious devotion or political power.

Machu Picchu, Peru, shows the adaptations of architecture and town 
planning to a rugged natural site

Lower Manhattan, March 2001. The 20th century saw cities across the world 
transformed by highrise buildings in the International Style
Architectural design competition
Architectural drawing
Architectural style
Architectural technology
Architectural theory
Architecture prizes
Building materials
Contemporary architecture
Glossary of architecture
List of human habitation forms
Mathematics and architecture
Organic architecture
Metaphoric Architecture
Zoomorphic architecture
Outline of architecture
Sociology of architecture
Sustainable architecture
Dravidian architecture
Notes[edit]
Jump up ^ A design architect is one who is responsible for the design.
Jump up ^ A project architect is one who is responsible for ensuring the 
design is built correctly and who administers building contracts   in non-
specialist architectural practices the project architect is also the design 
architect and the term refers to the differing roles the architect plays at 
differing stages of the process.
References[edit]
Jump up ^ Museo Galileo, Museum and Institute of History and Science, The 
Dome of Santa Maria del Fiore, (accessed 30 January 2013)
Jump up ^ Giovanni Fanelli, Brunelleschi, Becocci, Florence (1980), 
Chapter: The Dome pp. 10-41.
^ Jump up to: a b c d e f Shorter Oxford English Dictionary (1993), Oxford, 
ISBN 0 19 860575 7
Jump up ^ "Gov.ns.ca". Gov.ns.ca. Archived from the original on 21 July 
2011. Retrieved 2 July 2011.
Jump up ^ Banister Fletcher, A History of Architecture on the Comparative 
Method
Jump up ^ D. Rowland   T.N. Howe: Vitruvius. Ten Books on Architecture. 
Cambridge University Press, Cambridge 1999, ISBN 0-521-00292-3
Jump up ^ "Vitruvius Ten Books on Architecture, with regard to landscape 
and garden design". gardenvisit.com.
Jump up ^ "Vitruvius". Penelope.uchicago.edu. Retrieved 2 July 2011.
Jump up ^ Fran oise Choay, Alberti and Vitruvius, editor, Joseph Rykwert, 
Profile 21, Architectural Design, Vol 49 No 5-6
^ Jump up to: a b John Ruskin, The Seven Lamps of Architecture, G. Allen 
(1880), reprinted Dover, (1989) ISBN 0-486-26145-X
Jump up ^ Le Corbusier, Towards a New Architecture, Dover Publications
(1985). ISBN 0-486-25023-7
Jump up ^ "Architecture starts when you carefully put two bricks together. 
There it begins. - Ludwig Mies van der Rohe at BrainyQuote". BrainyQuote.
Jump up ^ Rondanini, Nunzia Architecture and Social Change Heresies II, 
Vol. 3, No. 3, New York, Neresies Collective Inc., 1981.
Jump up ^ Fez-Barringten, Barie (2012). Architecture: The Making of 
Metaphors. Newcastle upon Tyne: Cambridge Scholars Publishing. ISBN 
978-1-4438-3517-6.
Jump up ^ Otero-Pailos, Jorge (2010). Architecture's Historical Turn: 
Phenomenology and the Rise of the Postmodern. Minneapolis: University of 
Minnesota Press. ISBN 9780816666041.
Jump up ^ Venturi, Robert (1966). Complexity and Contradiction in 
Architecture. New York: Museum of Modern Art.
Jump up ^ OneWorld.net (31 March 2004). "Vernacular Architecture in 
India". El.doccentre.info. Retrieved 2 July 2011.
Jump up ^ Other energy efficiency and green building rating systems 
include Energy Star, Green Globes, and CHPS (Collaborative for High 
Performance Schools).
Jump up ^ "The Charter of the New Urbanism". cnu.org.
Jump up ^ "Beauty, Humanism, Continuity between Past and Future". 
Traditional Architecture Group. Retrieved 23 March 2014.
Jump up ^ Issue Brief: Smart-Growth: Building Livable Communities. 
American Institute of Architects. Retrieved on 23 March 2014.
External links[edit]
Find more about
Architecture
at Wikipedia's sister projects
Search Wiktionary Definitions from Wiktionary
Search Commons  Media from Commons
Search Wikinews News stories from Wikinews
Search Wikiquote  Quotations from Wikiquote
Search Wikisource Source texts from Wikisource
Search Wikibooks  Textbooks from Wikibooks
Search Wikiversity  Learning resources from Wikiversity
World Architecture Community
Architecture.com, published by Royal Institute of British Architects
Architectural centers and museums in the world, list of links from the UIA
Architecture Week
Architecture Arch2O
American Institute of Architects
Glossary of Architecture Terms (with dictionary definitions)
Cities and Buildings Database - Collection of digitized images of buildings 
and cities drawn from across time and throughout the world from the 
University of Washington Library
[show] v t e
Aesthetics

Modern architecture
From Wikipedia, the free encyclopedia
This article is about modern movement architecture. For architecture in the 
present day, see contemporary architecture.

Solomon R. Guggenheim Museum in New York City (1959), interior, by 
Frank Lloyd Wright.

Contrasts in modern architecture, as shown by adjacent high-rises in 
Chicago, Illinois. 330 North Wabash (also known as the AMA Center, or IBM 
Plaza) (right), by Ludwig Mies van der Rohe, is a later example of the clean 
rectilinear lines and glass of the International Style, whereas Marina City, 
(left), by his student Bertrand Goldberg, reflects a more sculptural Mid-
Century Modern aesthetic.
Modern architecture or modernist architecture is a term applied to an 
overarching movement, with its exact definition and scope varying widely.[1] 
The term is often applied to modernist movements at the turn of the 20th 
century, with efforts to reconcile the principles underlying architectural 
design with rapid technological advancement and the modernization of 
society. It would take the form of numerous movements, schools of design, 
and architectural styles, some in tension with one another, and often equally 
defying such classification.[1] The term Modern architecture may be used to 
differentiate from Classical architecture following Vitruvian ideals, while it is 
also applied to various contemporary architecture styles such as 
Postmodern, High-tech or even New Classical, depending on the context. In 
art history, the revolutionary and neoclassical styles that evolved around 
1800 are also called modern.

The concept of modernism is a central theme in the efforts of 20th century 
modern architecture. Gaining global popularity especially after the Second 
World War, architectural modernism was adopted by many architects and 
architectural educators, and continued as a dominant architectural style for 
institutional and corporate buildings into the 21st century. Modernism 
eventually generated reactions, most notably Postmodernism which sought 
to preserve pre-modern elements, while "Neo-modernism" has emerged as a 
reaction to Post-modernism.

Notable architects important to the history and development of the modernist 
movement include Ludwig Mies van der Rohe, Le Corbusier, Walter Gropius, 
Erich Mendelsohn, Frank Lloyd Wright, Joseph Eichler, Richard Neutra, 
Louis Sullivan, Gerrit Rietveld, Bruno Taut, Gunnar Asplund, Arne Jacobsen, 
Oscar Niemeyer and Alvar Aalto.

Contents  [hide] 
1 Characteristics
2 Context
3 Early modernism
3.1 In the United States
3.2 In Italy: Futurism
3.3 In Soviet Union: Constructivism
3.4 In Western Europe
3.4.1 Arts and Crafts movement
3.4.2 Expressionism
3.4.3 Modernism reaches critical mass
3.5 Style Moderne: tradition and modernism
3.6 Wartime innovation
4 International Style
5 Urban design and mass housing
6 Mid-Century reactions
6.1 Brutalism and monumentality
7 Late 20th-century reactions and movements
7.1 High-tech architecture
7.2 Postmodern architecture
7.3 Neomodern architecture
7.4 Neofuturistic architecture
7.5 New Urbanism and New Classical Architecture
8 Examples of contemporary modern architecture
9 Preservation
10  See also
11  References
12  External links
Characteristics[edit]

This section does not cite any sources. Please help improve this section by 
adding citations to reliable sources. Unsourced material may be challenged 
and removed. (March 2014)

The Salk Institute complex in La Jolla, California, by architect Louis Kahn.
Common themes of modern architecture include:

the notion that "Form follows function", a dictum originally expressed by 
Frank Lloyd Wright's early mentor Louis Sullivan, meaning that the result of 
design should derive directly from its purpose
simplicity and clarity of forms and elimination of "unnecessary detail"
materials at 90 degrees to each other
visual expression of structure (as opposed to the hiding of structural 
elements)
the related concept of "Truth to materials", meaning that the true nature or 
natural appearance of a material ought to be seen rather than concealed or 
altered to represent something else
use of industrially-produced materials; adoption of the machine aesthetic
particularly in International Style modernism, a visual emphasis on horizontal 
and vertical lines
Context[edit]

The Crystal Palace, 1851, was one of the first buildings to have vast 
amounts of glass supported by structural metal, foreshadowing trends in 
Modernist architecture.
There are multiple lenses through which the evolution of modern 
architecture may be viewed. Some historians see it as a social matter, 
closely tied to the project of Modernity and thus the Enlightenment. Modern 
architecture developed, in their opinion, as a result of social and political 
revolutions.[2] Others see Modern architecture as primarily driven by 
technological and engineering developments. Still other historians regard 
Modernism as a matter of taste, a reaction against eclecticism and the lavish 
stylistic excesses of Victorian and Edwardian architecture.

With the Industrial Revolution, the availability of newly-available building 
materials such as iron, steel, and sheet glass drove the invention of new 
building techniques. In 1796, Shrewsbury mill owner Charles Bage first used 
his 'fireproof' design, which relied on cast iron and brick with flag stone 
floors. Such construction greatly strengthened the structure of mills, which 
enabled them to accommodate much bigger machines. Due to poor 
knowledge of iron's properties as a construction material, a number of early 
mills collapsed. It was not until the early 1830s that Eaton Hodgkinson 
introduced the section beam, leading to widespread use of iron construction. 
This kind of austere industrial architecture utterly transformed the landscape 
of northern Britain, leading to the description of places like Manchester and 
parts of West Yorkshire as "Dark satanic mills". The Crystal Palace by 
Joseph Paxton at the Great Exhibition of 1851 was an early example of iron 
and glass construction, followed in 1864 by the first glass and metal curtain 
wall. A further development was that of the steel-framed skyscraper in 
Chicago around 1890 by William Le Baron Jenney and Louis Sullivan.

Early modernism[edit]
Around 1900, a number of architects and designers around the world began 
developing new solutions to integrate traditional precedents (classicism or 
Gothic, for instance) with new technological possibilities. The work of Louis 
Sullivan and Frank Lloyd Wright in Chicago, Victor Horta in Brussels, Antoni 
Gaudi in Barcelona, Otto Wagner and the Vienna Secession in Austria, and 
Charles Rennie Mackintosh in Glasgow, among many others, can be seen 
as a common struggle between old and new. The work of some of these 
were a part of what is broadly categorized as Art Nouveau ("New Art"). Note 
that the Russian word for Art Nouveau, "      ", and the Spanish word for Art 
Nouveau, "Modernismo" are cognates of the English word "Modern" though 
they carry different meanings. An early use of the term in print around this 
time, approaching its later meaning, was in the title of a book by Otto 
Wagner.[3][4] The fallout of the First World War resulted in additional 
experimentation and ideas. Following out of the experiments in Art Nouveau 
and its related movements around the world, modernism in architecture and 
design grew out of stylistic threads originating throughout the world.

In the United States[edit]

The Robie House, 1910, in Chicago, Illinois.
See also: Frank Lloyd Wright, Joseph Eichler and Richard Neutra

This section does not cite any sources. Please help improve this section by 
adding citations to reliable sources. Unsourced material may be challenged 
and removed. (March 2014)
Wright's Larkin Building (1904) in Buffalo, New York, Unity Temple (1905) in 
Oak Park, Illinois, and the Robie House (1910) in Chicago, Illinois were some 
of the first examples of modern architecture in the United States. Frank 
Lloyd Wright was a major influence on European architects, including both 
Walter Gropius (founder of the Bauhaus) and Ludwig Mies van der Rohe, as 
well as on the whole of organic architecture. Gropius claimed that his "bible" 
for forming the Bauhaus was 100 Frank Lloyd Wright drawings that the 
architect shared with Germany over a decade prior to this point, the 
Wasmuth Portfolio. While Wright's career would parallel that of European 
architects, he refused to be categorized with them, claiming that they copied 
his ideas.[citation needed] Many architects in Germany[who ] believed that 
Wright's life would be wasted in the United States, since the US was not 
ready for his newer architecture.[5] During the 1930s, Wright would 
experiment with his Usonian ideas for a uniquely U.S. American (i.e. "US-
onian") take on modernism. It would be several decades before European 
architects would in turn bring their version of modern architecture to the 
United States.

In Italy: Futurism[edit]
Main article: Futurist architecture

This section does not cite any sources. Please help improve this section by 
adding citations to reliable sources. Unsourced material may be challenged 
and removed. (March 2014)
Futurist architecture began in the early 20th century, characterized by anti-
historicism and long horizontal lines suggesting speed, motion and urgency. 
Technology and even violence were among the themes of the Futurists. The 
movement was founded by the poet Filippo Tommaso Marinetti, who 
produced its first manifesto, the Manifesto of Futurism in 1909. The 
movement attracted not only poets, musicians artist (such as Umberto 
Boccioni, Giacomo Balla, Fortunato Depero, and Enrico Prampolini) but also 
a number of architects. Among the latter there was Antonio Sant'Elia, who, 
though he built little (being killed in WWI), translated the Futurist vision into 
bold urban form. The unbuilt designs and theories of Futurists went on to 
influence both the Constructivists and a branch of Italian Fascist 
architecture.

In Soviet Union: Constructivism[edit]
Main article: Constructivist architecture

This section does not cite any sources. Please help improve this section by 
adding citations to reliable sources. Unsourced material may be challenged 
and removed. (March 2014)
Rusakov Workers' Club, Moscow, by Konstantin Melnikov (1928)
Rusakov Workers' Club, Moscow, by Konstantin Melnikov (1928)
Following the 1917 revolutions in Russia, the societal upheaval and change 
was coupled with a desire for a new aesthetic, one more in keeping with the 
Communist philosophy and societal goals of the new state, in contrast to the 
ornate Neoclassicism that had prevailed prior. This resulted in a new style, 
Constructivism, with a new set of buildings in the spotlight - namely, workers' 
clubs, commune-houses and communal 'factory-kitchens'. Constructivist 
architecture was proclaimed to be the architectural style aimed at 
promulgating a new, socialist society. Konstantin Melnikov, a Russian 
Constructivist architect, designed the number of working clubs - including 
Rusakov Workers' Club (1928) - and his own living house, Melnikov House 
(1929) near Arbat Street in Moscow. The leading group of constructivist 
architects, led by Vesnin brothers and Moisei Ginzburg, was publishing the 
'Contemporary Architecture' journal. This group created several major 
constructivist projects in the wake of the First Five Year Plan - including 
colossal Dnieper Hydroelectric Station (1932) - and made an attempt to start 
the 'typization' of living blocks with Ginzburg's Narkomfin building. A number 
of architects who already were recognized professional before 1917, like 
Alexey Shchusev[6] or Ivan Fomin, were successfully working under new 
conditions, providing several important examples of constructivist style, 
including Lenin's Mausoleum in Moscow (1930).

Derzhprom, Kharkiv, by Sergey Serafimovich, Samul Kravets and Marc 
Felger (1928)
Derzhprom (the House of Industry), Kharkiv, by Sergey Serafimovich, Samul 
Kravets and Marc Felger (1928)
The main centers of constructivist architecture were Moscow and Sain-
Petersburg; however, during the industrialization lots of constructivist 
buildings were erected in provincial cities. The regional industrial centers, 
like Ekaterinburg, Kharkiv or Ivanovo, were rebuilt in the constructivist 
manner; some cities, like Magnitogorsk or Zaporizhia, were constructed 
anew (the so-called socgorod, or 'socialist city').

The style prospered, but fell markedly out of favor during the design 
competition for the Palace of the Soviets from 1931 to 1933, losing to a more 
traditional revivalism of Russian architecture with nationalistic overtones, 
afterwards termed Postconstructivism. However, the whole process was 
rather complicated, and the influence of constructivism was still present in 
projects like Soviet pavilion at Paris World Exhibition (1937) designed by 
Boris Iofan.[7] This resulted in the ultimate demise of the Russian branch of 
early architectural modernism, though not before it had a chance to 
influence architects elsewhere, such as Le Corbusier.

In Western Europe[edit]
Arts and Crafts movement[edit]

This section needs additional citations for verification. Please help improve 
this article by adding citations to reliable sources. Unsourced material may 
be challenged and removed. (March 2014)

The AEG Turbinenfabrik ("turbine factory"), 1909, designed by Peter 
Behrens, illustrating the combination of industry and design.
Spanning the gap between the ideals of the Arts and Crafts movement, and 
the Modernism of the 1920s, was the Deutscher Werkbund (German Work 
Federation) a German association of architects, designers and industrialists. 
It was founded in 1907 in Munich at the instigation of Hermann Muthesius. 
Muthesius was the author of a three-volume "The English House" of 1905, a 
survey of the practical lessons of the English Arts and Crafts movement and 
a leading political and cultural commentator.[8] The purpose of the 
Werkbund was to sponsor the attempt to integrate traditional crafts with the 
techniques of industrial mass production. The organization originally 
included twelve architects and twelve business firms, but quickly expanded. 
The architects include Peter Behrens, Theodor Fischer (who served as its 
first president), Josef Hoffmann and Richard Riemerschmid. Joseph August 
Lux, an Austrian-born critic, helped formulate its agenda.[9]

As a result of isolation during World War I, an art and design movement 
developed unique to the Netherlands, known as De Stijl (literally "the style"), 
characterized by its use of line and primary colors. While producing little 
architectural design overall (with notable exception of the Rietveld Schr der 
House of 1924), its ideas went on to influence the architects and designers 
of the 1920s.

Expressionism[edit]

The Second Goetheanum, 1924 1928, in Basel, Switzerland, is an example 
of architectural Expressionism.
Main article: Expressionist architecture
Expressionism was an architectural movement that developed in Northern 
Europe during the first decades of the 20th century in parallel with the 
expressionist visual and performing arts. Making notable use of sculptural 
forms and the novel use of concrete as artistic elements, examples include 
Rudolf Steiner's Second Goetheanum, built from 1926 near Basel, 
Switzerland and the Einsteinturm in Potsdam, Germany.

The style was characterised by an early-modernist adoption of novel 
materials, formal innovation, and very unusual massing, sometimes inspired 
by natural biomorphic forms, sometimes by the new technical possibilities 
offered by the mass production of brick, steel and especially glass. Many 
expressionist architects fought in World War I and their experiences, 
combined with the political turmoil and social upheaval that followed the 
German Revolution of 1919, resulted in a utopian outlook and a romantic 
socialist agenda.[10] Economic conditions severely limited the number of 
built commissions between 1914 and the mid-1920s,[11] resulting in many of 
the most important expressionist works remaining as projects on paper, such 
as Bruno Taut's Alpine Architecture and Hermann Finsterlin's Formspiels. 
Ephemeral exhibition buildings were numerous and highly significant during 
this period. Scenography for theatre and films provided another outlet for the 
expressionist imagination,[12] and provided supplemental incomes for 
designers attempting to challenge conventions in a harsh economic climate. 
A particular type, using bricks to create its forms (rather than concrete) is 
known as Brick Expressionism.

Modernism reaches critical mass[edit]
See also: New Objectivity (architecture) and Bauhaus

This section does not cite any sources. Please help improve this section by 
adding citations to reliable sources. Unsourced material may be challenged 
and removed. (March 2014)

The Bauhaus building at Dessau, Germany, designed by Walter Gropius
It was at this time, during the 1920s, that the most important figures in 
Modern architecture established their reputations. The big three are 
commonly recognized as Le Corbusier in France, and Walter Gropius and 
Ludwig Mies van der Rohe in Germany, all of whom trained under Peter 
Behrens.

Gropius and Mies van der Rohe both served as directors of the Bauhaus, 
one of a number of European schools and associations concerned with 
reconciling craft tradition and industrial technology. Mies van der Rohe 
designed the German pavilion (known afterward as the Barcelona Pavilion) 
at the 1929 Barcelona International Exposition. Villa Savoye, by Le Corbusier 
and his cousin, was built from 1928 to 1931. As in Russia, political pressures 
turned against the modernists. With the rise of Nazism in 1933, the German 
experiments in modernism were replaced by more traditionalist architectural 
forms.

Style Moderne: tradition and modernism[edit]
Main articles: Art Deco and Streamline Moderne

This section needs additional citations for verification. Please help improve 
this article by adding citations to reliable sources. Unsourced material may 
be challenged and removed. (March 2014)

Greyhound Bus Station in Cleveland, Ohio, showing the Streamline 
Moderne aesthetic.
Following World War I, a stylistic movement developed that embraced ideas 
of both modernism (or at least modernization) and traditionalism. It is 
characterized by the adoption of the machine aesthetic, glorification of 
technological advancement and new materials, while at the same time 
adopting or loosely retaining revivalist forms and motifs, and the continued 
use of ornament.

In the case of the Art deco, decorative motifs included both those evocative 
of technology (such as the lightning bolt (electricity) or the tire (the 
automobile)), and those of the exotic (such as drawing elements from 
Mesoamerican, African, and Ancient Egyptian designs). Frank Lloyd Wright 
himself experimented with Mayan Revival, culminating in the concrete 
cube-based Ennis House of 1924 in Los Angeles.

A later variant, Streamline Moderne, simultaneously both played a role in 
industrial design and borrowed forms from machines themselves.

More restrained forms with national imagery were adopted. In the United 
States, it took the form of "Stripped Classicism" (alternatively, "PWA 
Moderne" or "WPA Moderne") a stark version of the Neoclassicism of Federal 
buildings earlier in the century.[13] It application ranged in scale from local 
post-offices to the Pentagon. At the same time (as noted above), the rise in 
nationalism was reflected in the Stalinist architecture of the Soviet Union, 
Fascist architecture of Italy, and Nazi architecture of Germany, what historian 
Kenneth Frampton termed the "New Tradition".[14] To a less political extent, 
such an idea of modernized tradition could also be seen in 
contemporaneous Mycenaean Revival architecture.

During and following World War II, this broad branch of modern architecture 
declined, with the rise of the International Style and other mid-century 
architecture.

Wartime innovation[edit]

Quonset hut en route to Japan
World War II (1939 1945) and its aftermath was a major factor in driving 
innovation in building technology, and in turn, architectural possibilities.[13]
[15] The wartime industrial demands resulting in a supply shortage (of such 
things as steel and other metals), in turn leading to the adoption of new 
materials, and advancement or novel use of old ones. Similarly, surplus 
postwar industrial capacity accelerated the use of new materials and 
techniques, particular architectural aluminium (as a result of advances made 
in its use in aircraft, etc., during the war).[15] At the same time, there was a 
rapid demand for structures during the war (such as military and 
governmental facilities) as well as for housing after the war.

These factors encouraged experiments with prefabricated building. Though 
examples of prefabrication have existed since the beginning of the Industrial 
Revolution, with notable examples during the Interwar period such as the 
diner, the semi-circular metal Nissen hut of World War I revived as the 
Quonset hut, the post-war enameled-steel Lustron house (1947 1950), and 
Buckminster Fuller's experimental aluminum Dymaxion House.[16]

International Style[edit]
Main article: International Style (architecture)

This section needs additional citations for verification. Please help improve 
this article by adding citations to reliable sources. Unsourced material may 
be challenged and removed. (March 2014)

The Seagram Building, New York City, 1958, by Ludwig Mies van der Rohe, 
is regarded as one of the finest examples of the functionalist aesthetic and a 
masterpiece of corporate modernism.
In 1932 (prior to World War II), the International Exhibition of Modern 
Architecture was held at the Museum of Modern Art in New York City. Philip 
Johnson and collaborator Henry-Russell Hitchcock drew together many 
distinct threads and trends in architecture, identified them as stylistically 
similar and having a common purpose, and consolidated them into the 
International style. This was a turning point. However, for the remainder of 
the Interwar period, the Moderne styles overshadowed this movement.

With the labeling of modernist art and architecture in Germany as 
degenerate, followed by World War II, important figures of the Bauhaus and 
New Objectivity fled to the United States: Marcel Breuer and Walter Gropius 
went to the Harvard Graduate School of Design (the former becoming part of 
a group known as the "Harvard Five"), Ludwig Mies van der Rohe to 
Chicago, with others going to Black Mountain College. Still others fled to 
British Palestine, contributing to the design of the White City of Tel Aviv.

While high-style modernist architectural design never became dominant in 
single-dwelling residential buildings in the United States, in institutional and 
commercial architecture Modernism became the pre-eminent, and in the 
schools (for leaders of the architectural profession) the only acceptable, 
design solution from about 1932 to about 1984.[citation needed]

Architects who worked in the International style wanted to break with 
architectural tradition and design simple, unornamented buildings. The most 
commonly used materials are glass for the facade (usually a curtain wall), 
steel for exterior support, and concrete for the floors and interior supports; 
floor plans were functional and logical. The style became most evident in the 
design of skyscrapers. Perhaps its most famous manifestations include the 
United Nations headquarters (Le Corbusier, Oscar Niemeyer, Sir Howard 
Robertson), the Seagram Building and the Toronto-Dominion Centre (Ludwig 
Mies van der Rohe), and Lever House (Skidmore, Owings & Merrill).

In the United States, a prominent early residential example was the Lovell 
House in Los Angeles, designed by Austrian expatriate Richard Neutra in the 
1920s. Other examples include the Case Study Houses. Commissioned 
between 1945 and 1966, the twenty or so homes that were built primarily in 
and around Los Angeles, designed by architects such as Neutra and 
Americans Charles and Ray Eames (the Eames House) have attracted 
hundreds of thousands of visitors since their completion, and have 
influenced many architects over the years, notably the British architect, 
Michael Manser, whose domestic work is best exemplified by Capel Manor 
House in Kent. These and other Modern residences tend to focus on 
humanizing the otherwise harsh ideal, making them more livable and 
ultimately more appealing to real people. Many of these designs use a 
similar tactic: blurring the line between indoor and outdoor spaces.[17] This 
is achieved by embracing "the box" while at the same time dissolving it into 
the background with minimal structure and large glass walls, as was 
particularly the case with the Farnsworth House by Mies van der Rohe and 
the Glass House by Philip Johnson, the later part of a set of residences by 
the "Harvard Five" in New Canaan, Connecticut. Some critics claim that 
these spaces remain too cold and static for the average person to function, 
however. The materials utilized in a large number of Modern homes are not 
hidden behind a softening facade. While this may make them somewhat 
less desirable for the general public, most modernist architects see this as a 
necessary and pivotal tenet of Modernism: uncluttered and purely Minimal 
design.[citation needed]

Urban design and mass housing[edit]

"Horseshoe Estate", Berlin (1925 1933), by Bruno Taut and Martin Wagner

National Congress of Brazil, by Oscar Niemeyer, in the modernist-designed 
city of Bras lia.
Main articles: Congr s International d'Architecture Moderne and Athens 
Charter
See also: Urban renewal
During the interwar period high-quality architecture was built on a large 
scale in some growing European cities including Berlin, Frankfurt, Vienna, 
and Rotterdam for broad sections of the population, including poorer people. 
In particular the Berlin housing estates built before the beginning of National 
Socialism set standards worldwide. They are seen right up to today as a 
major political and organisational achievement and therefore have been 
added to the UNESCO World heritage list in 2008.[18]

As a result of the economically difficult situation during the Weimar 
Republic, housing construction, which up to that time had been mainly 
privately financed and profit-oriented, had found itself at a dead end. 
Inflation was on the up and for citizens on low incomes decent housing was 
becoming increasingly unaffordable.

Consequently, the search was on to find new models for state-initiated 
housing construction, which could then be implemented with a passion from 
1920 on following the creation of Greater Berlin and the accompanying 
reform of local and regional government. The requirements for the type of 
flats to be built and the facilities they were to have were clearly defined, and 
the city was divided into different building zones. Following some basic ideas 
of the Garden city movement two- to three-storey housing estates that were 
well integrated into the landscape of the suburbs of the city were planned. 
The first large estate of this type with more than 2,000 residential units was 
the so-called Hufeisensiedlung (Horseshoe Estate) designed by Bruno Taut 
in Berlin.

After World War II the Congr s Internationaux d'Architecture Moderne (CIAM) 
was a force in shaping modernist urban planning, and consequently the 
design of cities and the structures within, from 1928 to 1959. Its 1933 
meeting resulted in the basis of what became the Athens Charter, which 
would drive urban planning practice for much of the mid-20th century. 
Following its principles, in the late 1950s the entirely-new city of Bras lia was 
built as a new capital for Brazil, designed by Lucio Costa, with prominent 
works for it designed by Oscar Niemeyer. Le Corbusier applied CIAM's 
principles in his design for the city of Chandigarh in India.

The devastation that WWII wrought in Europe, Asia, and the Pacific and 
subsequent post-war housing shortages resulted in a vast building and 
rebuilding of cities, with a variety of techniques employed for the creation of 
mass-housing. One attempt to solve this was by using the Tower block. In 
the Eastern Bloc, mass housing took the form of prefabricated panel 
buildings, such as the Plattenbau of East Germany, Khrushchyovka of 
Russia and the Panel k of Czechoslovakia.

Mid-Century reactions [edit]

Saint John's Abbey Church, Collegeville, Minnesota, United States, by 
Marcel Breuer, 1958-1961
Further information: Mid-Century modern
As the International Style took hold, others architects reacted to or strayed 
from its purely functionalist forms, while at the same time retaining highly 
modernist characteristics. Eero Saarinen, Alvar Aalto and Oscar Niemeyer 
were three of the most prolific architects and designers in this movement, 
which has influenced contemporary modernism.


TWA Terminal, John F. Kennedy Airport, New York, 1962, by Eero Saarinen

Lincoln Center for the Performing Arts

Central Library of UNAM, in Mexico City, 1950-1956, showing the detailed 
artwork of plastic integration.
Le Corbusier once described buildings as "machines for living", but people 
are not machines and it was suggested that they do not want to live in 
machines.[citation needed] During the middle of the century, some architects 
began experimenting in organic forms that they felt were more human and 
accessible. Mid-century modernism, or organic modernism, was very 
popular, due to its democratic and playful nature. Expressionist exploration 
of form was revived, such as in the Sydney Opera House in Australia by J rn 
Utzon. Eero Saarinen invoked suggestions of flight in his designs for the 
terminal at Dulles International Airport outside of Washington, D.C, or the 
TWA Terminal in New York, both finished in 1962.[19] The Mission 66 project 
of the United States National Park Service was also built during this time.

Contributing to these expressions were structural advances that enabled 
new forms to be possible or desirable. F lix Candela, a Spanish expatriate 
living in Mexico, and Italian engineer Pier Luigi Nervi, made particular strides 
in the use of reinforced concrete and concrete shell construction. In 1954, 
Buckminster Fuller patented the geodesic dome.

Another stylistic reaction was "New Formalism" (or "Neo-Formalism", 
sometimes shortened to "Formalism").[19][20] Like the pre-war "Stripped 
Classicism", "New Formalism" blended elements of classicism (at their most 
abstracted levels) with modernist designs.[21] Characteristics drawing on 
classicism include rigid symmetry, use of columns and colonnades or 
arcades, and use of high-end materials (such as marble or granite), yet 
works in this vein also characteristically use the flat roofs common with the 
International Style.[19][21] Architects working in this mode included Edward 
Durrell Stone, Minoru Yamasaki, and some of the middle-period work of 
Philip Johnson, with examples in the United States including the Kennedy 
Center (1971) and the National Museum of American History (1964) in 
Washington, D.C., and the Lincoln Center for the Performing Arts (mid-
1960s) in New York.[19][21]


The Theme Building and control tower in Los Angeles International Airport.
Arising shortly after the end of World War II, a particular set of stylistic 
tendencies in the United States during this time is known as Googie (or 
"populuxe"), derived from futuristic visions inspired by the imagery of the 
Atomic Age and Space Age, with motifs such as atomic orbital patterns and 
"flying saucers", respectively, such as in the Space Needle in Seattle. 
Though the style was unique to the United States, similar iconography can 
be seen in the Atomium in Brussels.

A distinctly Mexican take on modernism, "plastic integration", was a 
syncretization of Mexican artistic traditions (such as muralism) with 
International Style forms,[22] and can be seen in the later works of Luis 
Barrag n and Juan O'Gorman, epitomized by the Ciudad Universitaria of 
UNAM in Mexico City.[23]

Brutalism and monumentality[edit]
Main article: Brutalist architecture

This section needs additional citations for verification. Please help improve 
this article by adding citations to reliable sources. Unsourced material may 
be challenged and removed. (March 2014)

The National Assembly Building of Bangladesh by Louis Kahn; compare its 
"weightiness" with works above.
Architects such as Louis Kahn, Paul Rudolph, Marcel Breuer, I.M. Pei and 
others responded to the "light" glass curtain walls advocated by Ludwig Mies 
van der Rohe, by creating architecture with an emphasis on more substantial 
materials, such as concrete and brick, and creating works with a 
"monumental" quality. "Brutalism" is a term derived from the use of "B ton 
brut" ("raw concrete"), unadorned, often with the mold marks remaining, 
though as a stylistic tendency, Brutalism would ultimately be applied more 
broadly to include the use of other materials such as brickwork in a similar 
fashion. The term was first used in architecture by Le Corbusier.

Late 20th-century reactions and movements[edit]
High-tech architecture[edit]
Further information: High-tech architecture
High-tech architecture, also known as Late Modernism or Structural 
Expressionism, is an architectural style that emerged in the 1970s, 
incorporating elements of high-tech industry and technology into building 
design. High-tech architecture appeared as a revamped modernism, an 
extension of those previous ideas helped by even more technological 
advances. This category serves as a bridge between modernism and post-
modernism, however there remain gray areas as to where one category ends 
and the other begins. In the 1980s, high-tech architecture became more 
difficult to distinguish from post-modern architecture. Some of its themes 
and ideas were later absorbed into the style of neo-futurism art and 
architectural movement.

Postmodern architecture[edit]
Main article: Postmodern architecture

This section needs additional citations for verification. Please help improve 
this article by adding citations to reliable sources. Unsourced material may 
be challenged and removed. (March 2014)

The Sony Tower (formerly AT&T building) in New York City, 1984, by Philip 
Johnson, illustrating a Postmodern spin on the boxy office towers that 
preceded it with the inclusion of a classical broken pediment on the top.
Modern architecture met with some criticism, which began in the 1960s on 
the grounds that it seemed universal, elitist, and lacked meaning. Siegfried 
Giedion in the 1961 introduction to his evolving text, Space, Time and 
Architecture (first written in 1941), began "At the moment a certain confusion 
exists in contemporary architecture, as in painting; a kind of pause, even a 
kind of exhaustion." At the Metropolitan Museum of Art, a 1961 symposium 
discussed the question "Modern Architecture: Death or Metamorphosis "


The Kaleida Health Gates Vascular Institute in Buffalo, New York, illustrates 
a cube like design wrapped with modern accents.
The loss of traditionalist structures to make way for new modernist 
construction, especially via the Urban Renewal movement, led to further 
criticism, particularly the demolition of New York Penn Station in 1963. That 
same year, controversy materialized around the Pan Am Building that 
loomed over Grand Central Terminal, taking advantage of the modernist real 
estate concept of "air rights",[24] In criticism by Ada Louise Huxtable and 
Douglass Haskell it was seen to "sever" the Park Avenue streetscape and 
"tarnish" the reputations of its consortium of architects: Walter Gropius, 
Pietro Belluschi and the builders Emery Roth & Sons. The proposal for a 
tower over the terminal itself resulted in the landmark U.S. Supreme Court 
case Penn Central Transportation Co. v. New York City, upholding the city's 
landmark laws. Alongside these preservation efforts came the increasing 
respectability and fashionability of more traditional styles.

Architects explored Postmodern architecture which offered a blend of some 
pre-modern elements, and deliberately sought to move away from rectilinear 
designs, towards more eclectic styles. Even Philip Johnson came to admit 
that he was "bored with the box." By the 1980s, postmodern architecture 
appeared to trend over modernism.

High Postmodern aesthetics lacked traction and by the mid-1990s, a new 
surge of modern architecture once again established international pre-
eminence. As part of this revival, much of the criticism of the modernists was 
re-evaluated; and a modernistic style once again dominates in institutional 
and commercial contemporary practice. Although modern and postmodern 
design compete with a revival of traditional architectural design in 
commercial and institutional architecture; residential design continues to be 
dominated by a traditional aesthetic.

Neomodern architecture[edit]
Further information: Neomodern
Neomodernism is a reaction to Postmodernism and its embrace of pre-
modern elements of design. Examples of modern architecture in the 21st 
century include One World Trade Center (2013) in New York City and Tour 
First (2011), the tallest office building in the Paris metropolitan area. Emporis 
named Chicago's Modern Aqua Tower (2009) its skyscraper of the year.[25]

Neofuturistic architecture[edit]
Further information: Neo-Futurism
Neo-futurism is a departure from post-modernism connected with an 
idealistic belief in a better future. Neofuturist urbanists, architects, designers 
and artists believe in cities releasing emotions, driven by eco-sustainability 
and ethical values and implementing new materials and new technologies
[26] to provide a better quality of life for residents.[27] Pioneered from early 
60s and late 70s by Finnish architect Eero Saarinen;[28][29] American 
architect Adrian Wilson[30] and Charles Luckman;[31][32] Danish architects 
Henning Larsen[33] and J rn Utzon;[34] the architectural movement was 
later named Neo-Futurism by French architect Denis Laming. He designed 
all of the buildings in Futuroscope, whose Kinemax is the flagship building.
[35] In the early 21st century, Neo-Futurism has been relaunched in 
December 2006 by innovation designer Vito Di Bari with the futuristic vision 
for the city of Milan[36] at the time of the Universal Expo 2015 included in the 
candidature presented to BIE (Bureau of International Expositions)[37] and 
envisioning "the convergence of art, cutting edge technologies and ethical 
values", later defined by Spanish architect Santiago Calatrava as "a fusion of 
architecture, art and engineering"[38] and by Danish architect Bjarke Ingels 
as "a pragmatic utopian architecture that takes on the creation of socially 
and environmentally perfect places. [39] Architects working in this mode 
include Pritzker Architecture Prize Iraqi-British architect Zaha Hadid[40][41]
[42] and Japanese Ryue Nishizawa;[43] Lubetkin Prize Winner British 
Thomas Heatherwick,[44][45] Spanish architects Santiago Calatrava,[46][47]
[48] Ferm n V zquez,[49] and Enric Massip-Bosch[50] and artists such as 
Indian sculptor Anish Kapoor,[51][52] Italian large-scale buildings artist Mario 
Arlati and Dutch kinetic sculptor Theo Jansen.[53]

New Urbanism and New Classical Architecture[edit]
Concurrently, the recent movements of New Urbanism and New Classical 
Architecture promote a sustainable approach towards construction, that 
appreciates and develops smart growth, architectural tradition and classical 
design.[54][55] This in contrast to modernist and globally uniform 
architecture, as well as leaning against solitary housing estates and 
suburban sprawl.[56] Both trends started in the 1980s. The Driehaus 
Architecture Prize is an award that recognizes efforts in New Urbanism and 
New Classical Architecture, and is endowed with a prize money twice as high 
as that of the modernist Pritzker Prize.[57]

Examples of contemporary modern architecture[edit]

Warszawa Centralna railway station (1975) in Warsaw
 

Crystal Cathedral (1980) in Garden Grove, California
 

Tour Total (1985) in the Paris suburb Courbevoie, La D fense district
 

Auditorio de Tenerife in Santa Cruz de Tenerife (2003)
 

Borgata (2003) in Atlantic City
 

Eureka Tower (2006) in Melbourne
 

Trump International Hotel and Tower (2009) in Chicago
 

Reina Sof a Museum in Madrid (2013)
 

Ciudad de las Artes y las Ciencias in Valencia (1998)
 

The University Library (2015) in Freiburg
Preservation[edit]

This section does not cite any sources. Please help improve this section by 
adding citations to reliable sources. Unsourced material may be challenged 
and removed. (March 2014)

In 2007, the Sydney Opera House by J rn Utzon was listed as a World 
Heritage Site.
Several works or collections of modern architecture have been designated 
by UNESCO as World Heritage Sites. In addition to the early experiments 
associated with Art Nouveau, these include a number of the structures 
mentioned above in this article: the Rietveld Schr der House in Utrecht, the 
Bauhaus structures in Weimar and Dessau, the Berlin Modernism Housing 
Estates, the White City of Tel Aviv, the city of Brasilia, the Ciudad 
Universitaria of UNAM in Mexico City and the University City of Caracas in 
Venezuela, and the Sydney Opera House.

Private organizations such as Docomomo International, the World 
Monuments Fund, and the Recent Past Preservation Network are working to 
safeguard and document imperiled Modern architecture. In 2006, the World 
Monuments Fund launched Modernism at Risk, an advocacy and 
conservation program.

Following the destruction caused by Hurricane Katrina, Modern structures in 
New Orleans have been increasingly slated for demolition. Plans are 
underway to demolish many of the city's Modern public schools, as well as 
large portions of the city's Civic Plaza. Federal Emergency Management 
Agency (FEMA) funds will contribute to razing the State Office Building and 
State Supreme Court Building, both designed by the collaborating 
architectural firms of August Perez and Associates; Goldstein, Parham and 
Labouisse; and Favrot, Reed, Mathes and Bergman. The New Orleans 
Recovery School District has proposed demolitions of schools designed by 
Charles R. Colbert, Curtis and Davis, and Ricciuti Associates. The 1959 
Lawrence and Saunders building for the New Orleans International 
Longshoremen's Association Local 1419 is currently threatened with 
demolition although the union supports its conservation.

See also[edit]
Portal icon Architecture portal
Modern furniture
Modern art
International style (architecture)
Organic architecture
Critical regionalism
Congr s International d'Architecture Moderne
References[edit]
^ Jump up to: a b "Growth, Efficiency, and Modernism" (PDF). U.S. General 
Services Administration. 2006 [2003]. pp. 14 15. Retrieved March 2011.
Jump up ^ Crouch, Christopher. 2000. "Modernism in Art Design and 
Architecture", New York: St. Martins Press. ISBN 0-312-21830-3 (cloth) ISBN 
0-312-21832-X (pbk)
Jump up ^ "Moderne Architektur: seinen Sch lern ein F hrer auf diesem 
Kunstgebiete - Otto Wagner - Google Books". Books.google.com. Retrieved 
2015-09-27.
Jump up ^ Otto Wagner. Translated by Harry Francis Mallgrave. Modern 
Architecture: A Guidebook for His Students to This Field of Art. Getty Center 
for the History of Art and the Humanities. 1988. ISBN 0-226-86938-5
Jump up ^ "Frank Lloyd Wright Dies; Famed Architect Was 89". 
Nytimes.com. 2010. Retrieved 16 December 2014.
Jump up ^ "Alexey Shchusev (1873-1949)". Retrieved 2015-08-16.
Jump up ^ Udovi ki-Selb, Danilo (2012-01-01). "Facing Hitler s Pavilion: The 
Uses of Modernity in the Soviet Pavilion at the 1937 Paris International 
Exhibition". Journal of Contemporary History 47 (1): 13 47. 
doi:10.1177/0022009411422369. ISSN 0022-0094.
Jump up ^ Lucius Burckhardt (1987) . The Werkbund.   : Hyperion Press. 
ISBN. Frederic J. Schwartz (1996). The Werkbund: Design Theory and Mass 
Culture Before the First World War. New Haven, Conn. : Yale University 
Press. ISBN.
Jump up ^ Mark Jarzombek. "Joseph August Lux: Werkbund Promoter, 
Historian of a Lost Modernity," Journal of the Society of Architectural 
Historians 63/1 (June 2004): 202 219.
Jump up ^ Jencks, p. 59
Jump up ^ Sharp, p. 68
Jump up ^ Pehnt, p. 163
^ Jump up to: a b "Growth, Efficiency, and Modernism" (PDF). U.S. General 
Services Administration. 2006 [2003]. p. 27. Retrieved March 2011.
Jump up ^ Frampton, Kenneth (1980). Modern Architecture: A Critical History 
(3rd ed.). Thames and Hudson. pp. 210 218. ISBN 0-500-20257-5.
^ Jump up to: a b Thomas C. Jester, ed. (1995). Twentieth-Century Building 
Materials. McGraw-Hill. pp. 41 42, 48 49. ISBN 0-07-032573-1.
Jump up ^ Thomas C. Jester, ed. (1995). Twentieth-Century Building 
Materials. McGraw-Hill. p. 259. ISBN 0-07-032573-1.
Jump up ^ [1] Archived July 21, 2011, at the Wayback Machine.
Jump up ^ Berlin Modernism Housing Estates. Inscription on the UNESCO 
World Heritage List; German/English; Editor: Berlin Monument Authority - 
ISBN 978-3-03768-000-1
^ Jump up to: a b c d "Growth, Efficiency, and Modernism" (PDF). U.S. 
General Services Administration. 2006 [2003]. pp. 16, 34. Retrieved March 
2011.
Jump up ^ Handlin, David P. (2004) [1985]. American Architecture. Thames & 
Hudson. pp. 247 248. ISBN 0-500-20373-3.
^ Jump up to: a b c "New Formalism". Performing Arts Center of Los Angeles 
County. Retrieved March 2011.; excerpting from HABS documentation: "Los 
Angeles Music Center". Historic American Building Survey.
Jump up ^ "Plastic Integration". Patrimonio Cultural de la Humanidad 
(Website). UNAM. Retrieved March 2011.
Jump up ^ "Central University City Campus of the Universidad Nacional Aut 
noma de M xico (UNAM)". World Heritage List. UNESCO. Retrieved March 
2011.
Jump up ^ Meredith L. Clausen, 2005. The Pan Am building and the 
shattering of the Modernist Dream (Cambridge: MIT Press) (On-line 
analytical review)
Jump up ^ "Aqua Named 2009 Skyscraper of the Year". NBC Chicago. 
Retrieved 25 September 2015.
Jump up ^ Hal Foster (1987). "Neo-Futurism: Architecture and Technology". 
Architectural Association School of Architecture (Jstor.org). Retrieved 2015-
09-27.
Jump up ^ "Neofuturism Architecture And Technology, SCI-Arc Media 
Archive". Sma.sciarc.edu. 1987-10-05. Retrieved 2014-01-25.
Jump up ^ Rory Stott (31 August 2015). "Eero Saarinen - ArchDaily". 
Archdaily.com. Retrieved 25 September 2015.
Jump up ^ "Eero Saarinen's TWA Terminal To Become A Luxury Hotel". 
Co.Design. Retrieved 25 September 2015.
Jump up ^ "Adrian Wilson". Architectural Digest. Retrieved 25 September 
2015.
Jump up ^ "Airports: A Century of Architecture: Hugh Pearman: 
9780810950122: Amazon.com: Books". Amazon.com. Retrieved 2015-09-27.
Jump up ^ "December 2012 Newsletter" (PDF). Preservationdallas.org. 
Retrieved 2015-09-27.
Jump up ^ "Opera Cake: Neo-Futurism at Danish Royal Opera". Opera-
cake.blogspot.com. Retrieved 25 September 2015.
Jump up ^ "Sydney Opera House, Sydney - SkyscraperPage.com". 
Skyscraperpage.com. Retrieved 25 September 2015.
Jump up ^ "Denis Laming Architectes". Laming.fr. Retrieved 25 September 
2015.
Jump up ^ "Expo 2015: Innovation Design by Vito Di Bari". YouTube. 
Retrieved 2014-01-25
Jump up ^ [2] Archived December 25, 2013, at the Wayback Machine.
Jump up ^ "Santiago Calatrava. Complete Works 1979Industrial Revolution
From Wikipedia, the free encyclopedia

A Watt steam engine. James Watt transformed the steam engine from a 
reciprocating motion that was used for pumping to a rotating motion suited 
to industrial applications. Watt and others significantly improved the 
efficiency of the steam engine.

Iron and Coal, 1855 60, by William Bell Scott illustrates the rise of coal and 
iron working in the Industrial Revolution and the heavy engineering projects 
they made possible.
The Industrial Revolution was the transition to new manufacturing processes 
in the period from about 1760 to sometime between 1820 and 1840. This 
transition included going from hand production methods to machines, new 
chemical manufacturing and iron production processes, improved efficiency 
of water power, the increasing use of steam power, the development of 
machine tools and the rise of the factory system. Textiles were the dominant 
industry of the Industrial Revolution in terms of employment, value of output 
and capital invested; the textile industry was also the first to use modern 
production methods.[1]:40

The Industrial Revolution marks a major turning point in history; almost every 
aspect of daily life was influenced in some way. In particular, average income 
and population began to exhibit unprecedented sustained growth. Some 
economists say that the major impact of the Industrial Revolution was that 
the standard of living for the general population began to increase 
consistently for the first time in history, although others have said that it did 
not begin to meaningfully improve until the late 19th and 20th centuries.[2]
[3][4] At approximately the same time the Industrial Revolution was 
occurring, Britain was undergoing an agricultural revolution, which also 
helped to improve living standards.

The Industrial Revolution began in the United Kingdom and most of the 
important technological innovations were British. Mechanized textile 
production spread to continental Europe in the early 19th century, with 
important centers in France. A major iron making center developed in 
Belgium. Since then industrialisation has spread throughout the world.[1] 
The precise start and end of the Industrial Revolution is still debated among 
historians, as is the pace of economic and social changes.[5][6][7][8] GDP 
per capita was broadly stable before the Industrial Revolution and the 
emergence of the modern capitalist economy,[9] while the Industrial 
Revolution began an era of per-capita economic growth in capitalist 
economies.[10] Economic historians are in agreement that the onset of the 
Industrial Revolution is the most important event in the history of humanity 
since the domestication of animals and plants.[11]

The First Industrial Revolution evolved into the Second Industrial Revolution 
in the transition years between 1840 and 1870, when technological and 
economic progress continued with the increasing adoption of steam 
transport (steam-powered railways, boats and ships), the large-scale 
manufacture of machine tools and the increasing use of machinery in 
steam-powered factories.[12][13][14]

Contents  [hide] 
1 Etymology
2 Important technological developments
2.1 Textile manufacture
2.2 Metallurgy
2.3 Steam power
2.4 Machine tools
2.5 Chemicals
2.6 Cement
2.7 Gas lighting
2.8 Glass making
2.9 Paper machine
2.10  Agriculture
2.11  Mining
2.12  Other developments
2.13  Transportation
2.13.1  Canals
2.13.2  Roads
2.13.3  Railways
3 Social effects
3.1 Factory system
3.2 Standards of living
3.2.1 Food and nutrition
3.2.2 Housing
3.2.3 Clothing and consumer goods
3.3 Population increase
3.4 Labour conditions
3.4.1 Social structure and working conditions
3.4.2 Factories and urbanisation
3.4.3 Child labour
3.4.4 Luddites
3.4.5 Organisation of labour
3.5 Other effects
4 Industrialisation beyond the United Kingdom
4.1 Continental Europe
4.1.1 Belgium
4.1.1.1 Demographic effects
4.1.2 France
4.1.3 Germany
4.1.4 Sweden
4.2 United States
4.3 Japan
5 Second Industrial Revolutions
6 Intellectual paradigms and criticism
6.1 Capitalism
6.2 Socialism
6.3 Romanticism
7 Causes
7.1 Causes in Europe
7.2 Causes in Britain
7.3 Transfer of knowledge
7.3.1 Protestant work ethic
8 See also
9 References
9.1 Bibliography
9.2 Historiography
9.3 Notes
10  External links
Etymology
The earliest recorded use of the term "Industrial Revolution" seems to have 
been in a letter from 6 July 1799 written by French envoy Louis-Guillaume 
Otto, announcing that France had entered the race to industrialise.[15] In his 
1976 book Keywords: A Vocabulary of Culture and Society, Raymond 
Williams states in the entry for "Industry": "The idea of a new social order 
based on major industrial change was clear in Southey and Owen, between 
1811 and 1818, and was implicit as early as Blake in the early 1790s and 
Wordsworth at the turn of the [19th] century." The term Industrial Revolution 
applied to technological change was becoming more common by the late 
1830s, as in J r me-Adolphe Blanqui's description in 1837 of la r volution 
industrielle.[16] Friedrich Engels in The Condition of the Working Class in 
England in 1844 spoke of "an industrial revolution, a revolution which at the 
same time changed the whole of civil society". However, although Engels 
wrote in the 1840s, his book was not translated into English until the late 
1800s, and his expression did not enter everyday language until then. Credit 
for popularising the term may be given to Arnold Toynbee, whose 1881 
lectures gave a detailed account of the term.[17]

Some historians, such as John Clapham and Nicholas Crafts, have argued 
that the economic and social changes occurred gradually and the term 
revolution is a misnomer. This is still a subject of debate among historians.

Important technological developments
The commencement of the Industrial Revolution is closely linked to a small 
number of innovations,[18] beginning in the second half of the 18th century. 
By the 1830s the following gains had been made in important technologies:

Textiles   Mechanised cotton spinning powered by steam or water greatly 
increased the output of a worker. The power loom increased the output of a 
worker by a factor of over 40.[19] The cotton gin increased productivity of 
removing seed from cotton by a factor of 50.[13] Large gains in productivity 
also occurred in spinning and weaving of wool and linen, but they were not 
as great as in cotton.[1]
Steam power   The efficiency of steam engines increased so that they used 
between one-fifth and one-tenth as much fuel. The adaptation of stationary 
steam engines to rotary motion made them suitable for industrial uses.[1]:82 
The high pressure engine had a high power to weight ratio, making it 
suitable for transportation.[20] Steam power underwent a rapid expansion 
after 1800.
Iron making   The substitution of coke for charcoal greatly lowered the fuel 
cost for pig iron and wrought iron production.[1]:89 93 Using coke also 
allowed larger blast furnaces,[1]:218[21] resulting in economies of scale. The 
cast iron blowing cylinder was first used in 1760. It was later improved by 
making it double acting, which allowed higher furnace temperatures. The 
puddling process produced a structural grade iron at a lower cost than the 
finery forge[1]:91 The rolling mill was fifteen times faster than hammering 
wrought iron. Hot blast (1828) greatly increased fuel efficiency in iron 
production in the following decades.
Textile manufacture
Main article: Textile manufacture during the Industrial Revolution
In the late 17th and early 18th centuries the British government passed a 
series of Calico Acts in order to protect the domestic woollen industry from 
the increasing amounts of cotton fabric imported from India.[1]:82[22]

The demand for heavier fabric was met by a domestic industry based around 
Lancashire that produced fustian, a cloth with flax warp and cotton weft. Flax 
was used for the warp because wheel spun cotton did not have sufficient 
strength, but the resulting blend was not as soft as 100% cotton and was 
more difficult to sew.[22]

On the eve of the Industrial Revolution, spinning and weaving were done in 
households, for domestic consumption and as a cottage industry under the 
putting-out system. Occasionally the work was done in the workshop of a 
master weaver. Under the putting-out system, home-based workers 
produced under contract to merchant sellers, who often supplied the raw 
materials. In the off season the women, typically farmers' wives, did the 
spinning and the men did the weaving. Using the spinning wheel it took 
anywhere from four to eight spinners to supply one hand loom weaver.[1]
[22][23]:823 The flying shuttle patented in 1733 by John Kay, with a number 
of subsequent improvements including an important one in 1747, doubled 
the output of a weaver, worsening the imbalance between spinning and 
weaving. It became widely used around Lancashire after 1760 when John's 
son, Robert, invented the drop box.[23]:821 22

Watch video: Demonstration of fly shuttle on YouTube
Lewis Paul patented the roller spinning frame and the flyer-and-bobbin 
system for drawing wool to a more even thickness. The technology was 
developed with the help of John Wyatt of Birmingham. Paul and Wyatt 
opened a mill in Birmingham which used their new rolling machine powered 
by a donkey. In 1743, a factory opened in Northampton with fifty spindles on 
each of five of Paul and Wyatt's machines. This operated until about 1764. A 
similar mill was built by Daniel Bourn in Leominster, but this burnt down. 
Both Lewis Paul and Daniel Bourn patented carding machines in 1748. 
Based on two sets of rollers that travelled at different speeds, it was later 
used in the first cotton spinning mill. Lewis's invention was later developed 
and improved by Richard Arkwright in his water frame and Samuel Crompton 
in his spinning mule.


Model of the spinning jenny in a museum in Wuppertal. Invented by James 
Hargreaves in 1764, the spinning jenny was one of the innovations that 
started the revolution.
In 1764 in the village of Stanhill, Lancashire, James Hargreaves invented the 
spinning jenny, which he patented in 1770. It was the first practical spinning 
frame with multiple spindles.[24] The jenny worked in a similar manner to 
the spinning wheel, by first clamping down on the fibres, then by drawing 
them out, followed by twisting.[25] It was a simple, wooden framed machine 
that only cost about  6 for a 40 spindle model in 1792,[1]:63 and was used 
mainly by home spinners. The jenny produced a lightly twisted yarn only 
suitable for weft, not warp.[23]:825 27

The spinning frame or water frame was developed by Richard Arkwright who, 
along with two partners, patented it in 1769. The design was partly based on 
a spinning machine built for Thomas High by clock maker John Kay, who 
was hired by Arkwright.[23]:827 30 For each spindle, the water frame used a 
series of four pairs of rollers, each operating at a successively higher rotating 
speed, to draw out the fibre, which was then twisted by the spindle. The 
roller spacing was slightly longer than the fibre length. Too close a spacing 
caused the fibres to break while too distant a spacing caused uneven 
thread. The top rollers were leather covered and loading on the rollers was 
applied by a weight. The weights kept the twist from backing up before the 
rollers. The bottom rollers were wood and metal, with fluting along the 
length. The water frame was able to produce a hard, medium count thread 
suitable for warp, finally allowing 100% cotton cloth to be made in Britain. A 
horse powered the first factory to use the spinning frame. Arkwright and his 
partners used water power at a factory in Cromford, Derbyshire in 1771, 
giving the invention its name.

Watch video: Demonstration of water frame on YouTube

The only surviving example of a spinning mule built by the inventor Samuel 
Crompton. The mule produced superior quality thread with minimal labor.
Samuel Crompton's Spinning Mule, introduced in 1779, was a combination 
of the spinning jenny and the water frame in which the spindles were placed 
on a carriage, which went through an operational sequence during which the 
rollers stopped while the carriage moved away from the drawing roller to 
finish drawing out the fibres as the spindles started rotating.[23]:832 
Crompton's mule was able to produce finer thread than hand spinning and 
at a lower cost. Mule spun thread was of suitable strength to be used as 
warp, and finally allowed Britain to produce good quality calico cloth.[23]:832

Watch video: Demonstration of spinning mule on YouTube

Interior of Marshall's Temple Works
Realising that the expiration of the Arkwright patent would greatly increase 
the supply of spun cotton and lead to a shortage of weavers, Edmund 
Cartwright developed a vertical power loom which he patented in 1785. In 
1776 he patented a two-man operated loom, that was more conventional.
[23]:834 Cartwright built two factories; the first burned down and the second 
was sabotaged by his workers. Cartwright's loom design had several flaws, 
the most serious being thread breakage. Samuel Horrocks patented a fairly 
successful loom in 1813. Horock's loom was improved by Richard Roberts in 
1822 and these were produced in large numbers by Roberts, Hill & Co.[26]

The demand for cotton presented an opportunity to planters in the Southern 
United States, who thought upland cotton would be a profitable crop if a 
better way could be found to remove the seed. Eli Whitney responded to the 
challenge by inventing the inexpensive cotton gin. With a cotton gin a man 
could remove seed from as much upland cotton in one day as would have 
previously taken a woman working two months to process at one pound per 
day.[13]

Other inventors increased the efficiency of the individual steps of spinning 
(carding, twisting and spinning, and rolling) so that the supply of yarn 
increased greatly. This in turn fed a weaving industry that advanced with 
improvements to shuttles and the loom or 'frame'. The output of an individual 
labourer increased dramatically, with the effect that the new machines were 
seen as a threat to employment, and early innovators were attacked and 
their inventions destroyed.

To capitalise upon these advances, it took a class of entrepreneurs, of whom 
the best known is Richard Arkwright. He is credited with a list of inventions, 
but these were actually developed by such people as Thomas Highs and 
John Kay; Arkwright nurtured the inventors, patented the ideas, financed the 
initiatives, and protected the machines. He created the cotton mill which 
brought the production processes together in a factory, and he developed 
the use of power first horse power and then water power which made cotton 
manufacture a mechanised industry. Before long steam power was applied 
to drive textile machinery. Manchester acquired the nickname Cottonopolis 
during the early 19th century owing to its sprawl of textile factories.[27]

Metallurgy

The Reverberatory Furnace could produce cast iron using mined coal. The 
burning coal remained separate from the iron ore and so did not 
contaminate the iron with impurities like sulphur and ash. This opened the 
way to increased iron production.

The Iron Bridge, Shropshire, England

Coalbrookdale by Night by Philip James de Loutherbourg, painted 1801. 
This shows Madeley Wood (or Bedlam) Furnaces, which belonged to the 
Coalbrookdale Company from 1776 to 1796.
A major change in the metal industries during the era of the Industrial 
Revolution was the replacement of wood and other bio-fuels with coal. For a 
given amount of heat, coal required much less labour to mine than cutting 
wood and converting it to charcoal,[28] and coal was more abundant than 
wood.[1]

Use of coal in smelting started somewhat before the Industrial Revolution, 
based on innovations by Sir Clement Clerke and others from 1678, using 
coal reverberatory furnaces known as cupolas. These were operated by the 
flames playing on the ore and charcoal or coke mixture, reducing the oxide 
to metal. This has the advantage that impurities (such as sulfur ash) in the 
coal do not migrate into the metal. This technology was applied to lead from 
1678 and to copper from 1687. It was also applied to iron foundry work in the 
1690s, but in this case the reverberatory furnace was known as an air 
furnace. The foundry cupola is a different (and later) innovation.

This was followed by Abraham Darby, who made great strides using coke to 
fuel his blast furnaces at Coalbrookdale in 1709. However, the coke pig iron 
he made was used mostly for the production of cast-iron goods, such as 
pots and kettles. He had the advantage over his rivals in that his pots, cast 
by his patented process, were thinner and cheaper than theirs. Coke pig iron 
was hardly used to produce bar iron in forges until the mid-1750s, when his 
son Abraham Darby II built Horsehay and Ketley furnaces (not far from 
Coalbrookdale). By then, coke pig iron was cheaper than charcoal pig iron. 
Since cast iron was becoming cheaper and more plentiful, it began being a 
structural material following the building of the innovative Iron Bridge in 1778 
by Abraham Darby III.

Bar iron for smiths to forge into consumer goods was still made in finery 
forges, as it long had been. However, new processes were adopted in the 
ensuing years. The first is referred to today as potting and stamping, but this 
was superseded by Henry Cort's puddling process.

Henry Cort developed two significant iron manufacturing processes: rolling 
in 1783 and puddling in 1784.[1]:91 Rolling replaced hammering for 
consolidating wrought iron and expelling some of the dross. Rolling was 15 
times faster than hammering with a trip hammer. Roller mills were first used 
for making sheets, but also were developed for rolling structural shapes 
such as angles and rails.

Puddling produced a structural grade iron at a relatively low cost.Puddling 
was a means of decarburizing pig iron by slow oxidation, with iron ore as the 
oxygen source, as the iron was manually stirred using a long rod. The 
decarburized iron, having a higher melting point than cast iron, was raked 
into globs by the puddler. When the glob was large enough the puddler 
would remove it. Puddling was backbreaking and extremely hot work. Few 
puddlers lived to be 40.[29] Puddling was done in a reverberatory furnace, 
allowing coal or coke to be used as fuel. The puddling process continued to 
be used until the late 19th century when iron was being displaced by steel. 
Because puddling required human skill in sensing the iron globs, it was 
never successfully mechanised.

Up to that time, British iron manufacturers had used considerable amounts 
of imported iron to supplement native supplies. This came principally from 
Sweden from the mid-17th century and later also from Russia from the end 
of the 1720s. However, from 1785, imports decreased because of the new 
iron making technology, and Britain became an exporter of bar iron as well 
as manufactured wrought iron consumer goods.

Hot blast, patented by James Beaumont Neilson in 1828, was the most 
important development of the 19th century for saving energy in making pig 
iron. By using waste exhaust heat to preheat combustion air, the amount of 
fuel to make a unit of pig iron was reduced at first by between one-third 
using coal or two-thirds using coke;[1]:92 however, the efficiency gains 
continued as the technology improved.[30] Hot blast also raised the 
operating temperature of furnaces, increasing their capacity. Using less coal 
or coke meant introducing fewer impurities into the pig iron. This meant that 
lower quality coal or anthracite could be used in areas where coking coal 
was unavailable or too expensive;[31] however, by the end of the 19th 
century transportation costs fell considerably.

Two decades before the Industrial Revolution an improvement was made in 
the production of steel, which was an expensive commodity and used only 
where iron would not do, such as for cutting edge tools and for springs. 
Benjamin Huntsman developed his crucible steel technique in the 1740s. 
The raw material for this was blister steel, made by the cementation process.

The supply of cheaper iron and steel aided a number of industries, such as 
those making nails, hinges, wire and other hardware items. The 
development of machine tools allowed better working of iron, causing it to be 
increasingly used in the rapidly growing machinery and engine industries.

Steam power
Main article: Steam power during the Industrial Revolution

The 1698 Savery Engine (piston-less steam pump)  the world's first 
commercially useful steam powered device: built by Thomas Savery.
The development of the stationary steam engine was an important element 
of the Industrial Revolution; however, during the early period of the Industrial 
Revolution, the majority of industrial power was supplied by water and wind. 
In Britain by 1800 an estimated 10,000 horsepower was being supplied by 
steam. By 1815 steam power had grown to 210,000 hp.[1]:104 Small power 
requirements continued to be provided by animal and human muscle until 
the late 19th century.[32]

The first commercially successful industrial use of steam power was due to 
Thomas Savery in 1698. He constructed and patented in London a low-lift 
combined vacuum and pressure water pump, that generated about one 
horsepower (hp) and was used in numerous water works and in a few mines 
(hence its "brand name", The Miner's Friend). Savery's pump was 
economical in small horsepower ranges, but was prone to boiler explosions 
in larger sizes. Savery pumps continued to be produced until the late 18th 
century.


Newcomen's steam powered atmospheric engine was the first practical 
piston steam engine. Subsequent steam engines were to power the 
Industrial Revolution.
The first successful piston steam engine was introduced by Thomas 
Newcomen before 1712. A number of Newcomen engines were successfully 
put to use in Britain for draining hitherto unworkable deep mines, with the 
engine on the surface; these were large machines, requiring a lot of capital 
to build, and produced about 5 hp (3.7 kW). They were extremely inefficient 
by modern standards, but when located where coal was cheap at pit heads, 
opened up a great expansion in coal mining by allowing mines to go deeper. 
Despite their disadvantages, Newcomen engines were reliable and easy to 
maintain and continued to be used in the coalfields until the early decades 
of the 19th century. By 1729, when Newcomen died, his engines had spread 
(first) to Hungary in 1722, Germany, Austria, and Sweden. A total of 110 are 
known to have been built by 1733 when the joint patent expired, of which 14 
were abroad. In the 1770s, the engineer John Smeaton built some very large 
examples and introduced a number of improvements. A total of 1,454 
engines had been built by 1800.[33]


Scottish mechanical engineer and inventor James Watt
A fundamental change in working principles was brought about by 
Scotsman James Watt. In close collaboration with Englishman Matthew 
Boulton, he had succeeded by 1778 in perfecting his steam engine, which 
incorporated a series of radical improvements, notably the closing off of the 
upper part of the cylinder thereby making the low pressure steam drive the 
top of the piston instead of the atmosphere, use of a steam jacket and the 
celebrated separate steam condenser chamber. The separate condenser did 
away with the cooling water that had been injected directly into the cylinder, 
which cooled the cylinder and wasted steam. Likewise, the steam jacket kept 
steam from condensing in the cylinder, also improving efficiency. These 
improvements increased engine efficiency so that Boulton & Watts engines 
used only 20 25% as much coal per horsepower-hour as Newcomen's. 
Boulton and Watt opened the Soho Foundry, for the manufacture of such 
engines, in 1795.

By 1783 the Watt steam engine had been fully developed into a double-
acting rotative type, which meant that it could be used to directly drive the 
rotary machinery of a factory or mill. Both of Watt's basic engine types were 
commercially very successful, and by 1800, the firm Boulton & Watt had 
constructed 496 engines, with 164 driving reciprocating pumps, 24 serving 
blast furnaces, and 308 powering mill machinery; most of the engines 
generated from 5 to 10 hp (7.5 kW).

The development of machine tools, such as the engine lathe, planing, 
milling and shaping machines powered by these engines, enabled all the 
metal parts of the engines to be easily and accurately cut and in turn made 
it possible to build larger and more powerful engines.

Until about 1800, the most common pattern of steam engine was the beam 
engine, built as an integral part of a stone or brick engine-house, but soon 
various patterns of self-contained rotative engines (readily removable, but 
not on wheels) were developed, such as the table engine. Around the start 
of the 19th century, the Cornish engineer Richard Trevithick, and the 
American, Oliver Evans began to construct higher pressure non-condensing 
steam engines, exhausting against the atmosphere. High pressure yielded 
an engine and boiler compact enough to be used on mobile road and rail 
locomotives and steam boats.

Machine tools
Main article: Machine tool
See also: Interchangeable parts

Maudslay's famous early screw-cutting lathes of circa 1797 and 1800

The Middletown milling machine of circa 1818, associated with Robert 
Johnson and Simeon North

The milling machine built by James Nasmyth between 1829 and 1831 for 
milling the six sides of a hex nut using an indexing fixture

Sir Joseph Whitworth, a leading machine tool maker and namesake of the 
British Standard Whitworth thread for machine screws
The Industrial Revolution created a demand for metal parts used in 
machinery. This led to the development of several machine tools for cutting 
metal parts. They have their origins in the tools developed in the 18th 
century by makers of clocks and watches and scientific instrument makers to 
enable them to batch-produce small mechanisms.

Before the advent of machine tools, metal was worked manually using the 
basic hand tools of hammers, files, scrapers, saws and chisels. 
Consequently, the use of metal was kept to a minimum. Wooden 
components had the disadvantage of changing dimensions with temperature 
and humidity, and the various joints tended to rack (work loose) over time. As 
the Industrial Revolution progressed, machines with metal parts and frames 
became more common. Hand methods of production were very laborious 
and costly and precision was difficult to achieve. Pre-industrial machinery 
was built by various craftsmen millwrights built water and wind mills, 
carpenters made wooden framing, and smiths and turners made metal 
parts.

The first large machine tool was the cylinder boring machine used for boring 
the large-diameter cylinders on early steam engines. The planing machine, 
the milling machine and the shaping machine were developed in the early 
decades of the 19th century. Although the milling machine was invented at 
this time, it was not developed as a serious workshop tool until somewhat 
later in the 19th century.

Watch video: Demonstration of industrial lathe on YouTube
Watch video: Demonstration of milling machine on YouTube
Watch video: Demonstration of metal planer on YouTube
Henry Maudslay, who trained a school of machine tool makers early in the 
19th century, was a mechanic with superior ability who had been employed 
at the Royal Arsenal, Woolwich. He was hired away by Joseph Bramah for 
the production of high security metal locks that required precision 
craftsmanship. Bramah patented a lathe that had similarities to the slide rest 
lathe. Maudslay perfected the slide rest lathe, which could cut machine 
screws of different thread pitches by using changeable gears between the 
spindle and the lead screw. Before its invention screws could not be cut to 
any precision using various earlier lathe designs, some of which copied from 
a template.[13][23]:392 95 The slide rest lathe was called one of history's 
most important inventions, although not entirely Maudslay's idea.[13]:31, 36

Maudslay left Bramah's employment and set up his own shop. He was 
engaged to build the machinery for making ships' pulley blocks for the Royal 
Navy in the Portsmouth Block Mills. These machines were all-metal and 
were the first machines for mass production and making components with a 
degree of interchangeability. The lessons Maudslay learned about the need 
for stability and precision he adapted to the development of machine tools, 
and in his workshops he trained a generation of men to build on his work, 
such as Richard Roberts, Joseph Clement and Joseph Whitworth.

James Fox of Derby had a healthy export trade in machine tools for the first 
third of the century, as did Matthew Murray of Leeds. Roberts was a maker 
of high-quality machine tools and a pioneer of the use of jigs and gauges for 
precision workshop measurement.

The impact of machine tools during the Industrial Revolution was not that 
great because other than firearms, threaded fasteners and a few other 
industries there were few mass-produced metal parts.[34] In the half century 
following the invention of the fundamental machine tools the machine 
industry became the largest industrial sector of the economy, by value 
added, in the U.S.[35]

Chemicals

The Thames Tunnel (opened 1843).
Cement was used in the world's first underwater tunnel.
The large scale production of chemicals was an important development 
during the Industrial Revolution. The first of these was the production of 
sulphuric acid by the lead chamber process invented by the Englishman 
John Roebuck (James Watt's first partner) in 1746. He was able to greatly 
increase the scale of the manufacture by replacing the relatively expensive 
glass vessels formerly used with larger, less expensive chambers made of 
riveted sheets of lead. Instead of making a small amount each time, he was 
able to make around 100 pounds (50 kg) in each of the chambers, at least a 
tenfold increase.

The production of an alkali on a large scale became an important goal as 
well, and Nicolas Leblanc succeeded in 1791 in introducing a method for the 
production of sodium carbonate. The Leblanc process was a reaction of 
sulphuric acid with sodium chloride to give sodium sulphate and 
hydrochloric acid. The sodium sulphate was heated with limestone (calcium 
carbonate) and coal to give a mixture of sodium carbonate and calcium 
sulphide. Adding water separated the soluble sodium carbonate from the 
calcium sulphide. The process produced a large amount of pollution (the 
hydrochloric acid was initially vented to the air, and calcium sulphide was a 
useless waste product). Nonetheless, this synthetic soda ash proved 
economical compared to that from burning specific plants (barilla) or from 
kelp, which were the previously dominant sources of soda ash,[36] and also 
to potash (potassium carbonate) derived from hardwood ashes.

These two chemicals were very important because they enabled the 
introduction of a host of other inventions, replacing many small-scale 
operations with more cost-effective and controllable processes. Sodium 
carbonate had many uses in the glass, textile, soap, and paper industries. 
Early uses for sulphuric acid included pickling (removing rust) iron and steel, 
and for bleaching cloth.

The development of bleaching powder (calcium hypochlorite) by Scottish 
chemist Charles Tennant in about 1800, based on the discoveries of French 
chemist Claude Louis Berthollet, revolutionised the bleaching processes in 
the textile industry by dramatically reducing the time required (from months 
to days) for the traditional process then in use, which required repeated 
exposure to the sun in bleach fields after soaking the textiles with alkali or 
sour milk. Tennant's factory at St Rollox, North Glasgow, became the largest 
chemical plant in the world.

After 1860 the focus on chemical innovation was in dyestuffs, and Germany 
took world leadership, building a strong chemical industry.[37] Aspiring 
chemists flocked to German universities in the 1860 1914 era to learn the 
latest techniques. British scientists by contrast, lacked research universities 
and did not train advanced students; instead the practice was to hire 
German-trained chemists.[38]

Cement
In 1824 Joseph Aspdin, a British bricklayer turned builder, patented a 
chemical process for making portland cement which was an important 
advance in the building trades. This process involves sintering a mixture of 
clay and limestone to about 1,400  C (2,552  F), then grinding it into a fine 
powder which is then mixed with water, sand and gravel to produce 
concrete. Portland cement was used by the famous English engineer Marc 
Isambard Brunel several years later when constructing the Thames Tunnel.
[39] Cement was used on a large scale in the construction of the London 
sewerage system a generation later.

Gas lighting
Main article: Gas lighting
Another major industry of the later Industrial Revolution was gas lighting. 
Though others made a similar innovation elsewhere, the large-scale 
introduction of this was the work of William Murdoch, an employee of 
Boulton and Watt, the Birmingham steam engine pioneers. The process 
consisted of the large-scale gasification of coal in furnaces, the purification 
of the gas (removal of sulphur, ammonia, and heavy hydrocarbons), and its 
storage and distribution. The first gas lighting utilities were established in 
London between 1812 and 1820. They soon became one of the major 
consumers of coal in the UK. Gas lighting had an impact on social and 
industrial organisation because it allowed factories and stores to remain 
open longer than with tallow candles or oil. Its introduction allowed night life 
to flourish in cities and towns as interiors and streets could be lighted on a 
larger scale than before.

Glass making
Main article: Glass production

The Crystal Palace held the Great Exhibition of 1851
A new method of producing glass, known as the cylinder process, was 
developed in Europe during the early 19th century. In 1832, this process was 
used by the Chance Brothers to create sheet glass. They became the 
leading producers of window and plate glass. This advancement allowed for 
larger panes of glass to be created without interruption, thus freeing up the 
space planning in interiors as well as the fenestration of buildings. The 
Crystal Palace is the supreme example of the use of sheet glass in a new 
and innovative structure.

Paper machine
Main article: Paper machine
A machine for making a continuous sheet of paper on a loop of wire fabric 
was patented in 1798 by Nicholas Louis Robert who worked for Saint-L ger 
Didot family in France. The paper machine is known as a Fourdrinier after 
the financiers, brothers Sealy and Henry Fourdrinier, who were stationers in 
London. Although greatly improved and with many variations, the Fourdriner 
machine is the predominant means of paper production today.

The method of continuous production demonstrated by the paper machine 
influenced the development of continuous rolling of iron and later steel and 
other continuous production processes.[40]

Agriculture
Main article: British Agricultural Revolution
The British Agricultural Revolution is considered one of the causes of the 
Industrial Revolution because improved agricultural productivity freed up 
workers to work in other sectors of the economy.[41]

Industrial technologies that affected farming included the seed drill, the 
Dutch plough, which contained iron parts, and the threshing machine.

Jethro Tull invented an improved seed drill in 1701. It was a mechanical 
seeder which distributed seeds evenly across a plot of land and planted 
them at the correct depth. This was important because the yield of seeds 
harvested to seeds planted at that time was around four or five. Tull's seed 
drill was very expensive and not very reliable and therefore did not have 
much of an impact. Good quality seed drills were not produced until the mid 
18th century.[42]

Joseph Foljambe's Rotherham plough of 1730, was the first commercially 
successful iron plough.[43][44][45][46] The threshing machine, invented by 
Andrew Meikle in 1784, displaced hand threshing with a flail, a laborious job 
that took about one-quarter of agricultural labour.[47]:286 It took several 
decades to diffuse[48] and was the final straw for many farm labourers, who 
faced near starvation, leading to the 1830 agricultural rebellion of the Swing 
Riots.

Machine tools and metalworking techniques developed during the Industrial 
Revolution eventually resulted in precision manufacturing techniques in the 
late 19th century for mass-producing agricultural equipment, such as 
reapers, binders and combine harvesters.[34]

Mining

Coal works near Neath, south Wales. 1798
Coal mining in Britain, particularly in South Wales started early. Before the 
steam engine, pits were often shallow bell pits following a seam of coal 
along the surface, which were abandoned as the coal was extracted. In 
other cases, if the geology was favourable, the coal was mined by means of 
an adit or drift mine driven into the side of a hill. Shaft mining was done in 
some areas, but the limiting factor was the problem of removing water. It 
could be done by hauling buckets of water up the shaft or to a sough (a 
tunnel driven into a hill to drain a mine). In either case, the water had to be 
discharged into a stream or ditch at a level where it could flow away by 
gravity. The introduction of the steam pump by Savery in 1698 and the 
Newcomen steam engine in 1712 greatly facilitated the removal of water and 
enabled shafts to be made deeper, enabling more coal to be extracted. 
These were developments that had begun before the Industrial Revolution, 
but the adoption of John Smeaton's improvements to the Newcomen engine 
followed by James Watt's more efficient steam engines from the 1770s 
reduced the fuel costs of engines, making mines more profitable.

Coal mining was very dangerous owing to the presence of firedamp in many 
coal seams. Some degree of safety was provided by the safety lamp which 
was invented in 1816 by Sir Humphry Davy and independently by George 
Stephenson. However, the lamps proved a false dawn because they became 
unsafe very quickly and provided a weak light. Firedamp explosions 
continued, often setting off coal dust explosions, so casualties grew during 
the entire 19th century. Conditions of work were very poor, with a high 
casualty rate from rock falls.

Other developments
Other developments included more efficient water wheels, based on 
experiments conducted by the British engineer John Smeaton[49] the 
beginnings of a machine industry[13][50] and the rediscovery of concrete 
(based on hydraulic lime mortar) by John Smeaton, which had been lost for 
1300 years.[51]

Transportation
Main article: Transport during the British Industrial Revolution
See also: Productivity improving technologies (economic history)   
Infrastructures
At the beginning of the Industrial Revolution, inland transport was by 
navigable rivers and roads, with coastal vessels employed to move heavy 
goods by sea. Wagon ways were used for conveying coal to rivers for further 
shipment, but canals had not yet been widely constructed. Animals supplied 
all of the motive power on land, with sails providing the motive power on the 
sea. The first horse railways were introduced toward the end of the 18th 
century, with steam locomotives being introduced in the early decades of the 
19th century.

The Industrial Revolution improved Britain's transport infrastructure with a 
turnpike road network, a canal and waterway network, and a railway 
network. Raw materials and finished products could be moved more quickly 
and cheaply than before. Improved transportation also allowed new ideas to 
spread quickly.

Canals
Main article: History of the British canal system

The Bridgewater Canal, famous because of its commercial success, crossing 
the Manchester Ship Canal, one of the last canals to be built.
Canals were the first technology to allow bulk materials to be economically 
transported long distances inland. This was because a horse could pull a 
barge with a load dozens of times larger than the load that could be drawn 
in a cart.[23][52]

Building of canals dates to ancient times. The Grand Canal in China, "the 
world's largest artificial waterway and oldest canal still in existence," parts of 
which were started between the 6th and 4th centuries BC, is 1,121 miles 
(1,804 km) long and links Hangzhou with Beijing.[53]

In the UK, canals began to be built in the late 18th century to link the major 
manufacturing centres across the country. Known for its huge commercial 
success, the Bridgewater Canal in North West England, which opened in 
1761 and was mostly funded by The 3rd Duke of Bridgewater. From Worsley 
to the rapidly growing town of Manchester its construction cost  168,000 ( 
22,589,130 as of 2013),[54][55] but its advantages over land and river 
transport meant that within a year of its opening in 1761, the price of coal in 
Manchester fell by about half.[56] This success helped inspire a period of 
intense canal building, known as Canal Mania.[57] New canals were hastily 
built in the aim of replicating the commercial success of the Bridgewater 
Canal, the most notable being the Leeds and Liverpool Canal and the 
Thames and Severn Canal which opened in 1774 and 1789 respectively.

By the 1820s, a national network was in existence. Canal construction 
served as a model for the organisation and methods later used to construct 
the railways. They were eventually largely superseded as profitable 
commercial enterprises by the spread of the railways from the 1840s on. The 
last major canal to be built in the United Kingdom was the Manchester Ship 
Canal, which upon opening in 1894 was the largest ship canal in the world,
[58] and opened Manchester as a port. However it never achieved the 
commercial success its sponsors had hoped for and signalled canals as a 
dying mode of transport in an age dominated by railways, which were 
quicker and often cheaper.

Britain's canal network, together with its surviving mill buildings, is one of the 
most enduring features of the early Industrial Revolution to be seen in 
Britain.

Roads

Construction of the first macadamized road in the United States (1823). In 
the foreground, workers are breaking stones "so as not to exceed 6 ounces 
in weight or to pass a two-inch ring".[59]
Much of the original British road system was poorly maintained by 
thousands of local parishes, but from the 1720s (and occasionally earlier) 
turnpike trusts were set up to charge tolls and maintain some roads. 
Increasing numbers of main roads were turnpiked from the 1750s to the 
extent that almost every main road in England and Wales was the 
responsibility of a turnpike trust. New engineered roads were built by John 
Metcalf, Thomas Telford and most notably John McAdam, with the first 
'macadamised' stretch of road being Marsh Road at Ashton Gate, Bristol in 
1816.[60] The major turnpikes radiated from London and were the means by 
which the Royal Mail was able to reach the rest of the country. Heavy goods 
transport on these roads was by means of slow, broad wheeled, carts 
hauled by teams of horses. Lighter goods were conveyed by smaller carts or 
by teams of pack horse. Stage coaches carried the rich, and the less 
wealthy could pay to ride on carriers carts.

Railways
Main article: History of rail transport in Great Britain

Painting depicting the opening of the Liverpool and Manchester Railway in 
1830, the first inter-city railway in the world and which spawned Railway 
Mania due to its success.
Reducing friction was one of the major reasons for the success of railroads 
compared to wagons. This was demonstrated on an iron plate covered 
wooden tramway in 1805 at Croydon, England.

  A good horse on an ordinary turnpike road can draw two thousand pounds, 
or one ton. A party of gentlemen were invited to witness the experiment, that 
the superiority of the new road might be established by ocular 
demonstration. Twelve wagons were loaded with stones, till each wagon 
weighed three tons, and the wagons were fastened together. A horse was 
then attached, which drew the wagons with ease, six miles in two hours, 
having stopped four times, in order to show he had the power of starting, as 
well as drawing his great load. [61]

Railways were made practical by the widespread introduction of inexpensive 
puddled iron after 1800, the rolling mill for making rails, and the 
development of the high pressure steam engine also around 1800.

Wagonways for moving coal in the mining areas had started in the 17th 
century and were often associated with canal or river systems for the further 
movement of coal. These were all horse drawn or relied on gravity, with a 
stationary steam engine to haul the wagons back to the top of the incline. 
The first applications of the steam locomotive were on wagon or plate ways 
(as they were then often called from the cast-iron plates used). Horse-drawn 
public railways did not begin until the early years of the 19th century when 
improvements to pig and wrought iron production were lowering costs. See: 
Metallurgy

Steam locomotives began being built after the introduction of high pressure 
steam engines around 1800. These engines exhausted used steam to the 
atmosphere, doing away with the condenser and cooling water. They were 
also much lighter weight and smaller in size for a given horsepower than the 
stationary condensing engines. A few of these early locomotives were used 
in mines. Steam-hauled public railways began with the Stockton and 
Darlington Railway in 1825.

The rapid introduction of railways followed the 1829 Rainhill Trials, which 
demonstrated Robert Stephenson's successful locomotive design and the 
1828 development of hot blast, which dramatically reduced the fuel 
consumption of making iron and increased the capacity the blast furnace.

On 15 September 1830, the Liverpool and Manchester Railway was opened, 
the first inter-city railway in the world and was attended by Prime Minister, 
the Duke of Wellington.[62] The railway was engineered by Joseph Locke 
and George Stephenson, linked the rapidly expanding industrial town of 
Manchester with the port town of Liverpool. The opening was marred by 
problems, due to the primitive nature of the technology being employed, 
however problems were gradually ironed out and the railway became highly 
successful, transporting passengers and freight. The success of the inter-
city railway, particularly in the transport of freight and commodities, led to 
Railway Mania.

Construction of major railways connecting the larger cities and towns began 
in the 1830s but only gained momentum at the very end of the first Industrial 
Revolution. After many of the workers had completed the railways, they did 
not return to their rural lifestyles but instead remained in the cities, providing 
additional workers for the factories.

Social effects
Main article: Life in Great Britain during the Industrial Revolution

A Middleton miner in 1814
Factory system
Main article: Factory system
Prior to the Industrial Revolution most of the workforce was employed in 
agriculture, either as self-employed farmers as land owners or tenants, or as 
landless agricultural laborers. By the time of the Industrial Revolution the 
putting-out system whereby farmers and townspeople produced goods in 
their homes, often described as cottage industry, was the standard. Typical 
putting out system goods included spinning and weaving. Merchant 
capitalist provided the raw materials, typically paid workers by the piece, and 
were responsible for the sale of the goods. Embezzlement of supplies by 
workers and poor quality were common problems. The logistical effort in 
procuring and distributing raw materials and picking up finished goods were 
also limitations of the putting out system.[63]

Some early spinning and weaving machinery, such as a 40 spindle jenny for 
about 6 pounds in 1792, was affordable for cottagers.[64] Later machinery 
such as spinning frames, spinning mules and power looms were expensive 
(especially if water powered), giving rise to capitalist ownership of factories. 
Many workers, who had nothing but their labor to sell, became factory 
workers out of necessity.

The change in the social relationship of the factory worker compared to 
farmers and cottagers was viewed unfavorably by Karl Marx, however, he 
recognized the increase in productivity made possible by technology.[65]

Standards of living
The effects on living conditions the industrial revolution have been very 
controversial, and were hotly debated by economic and social historians 
from the 1950s to the 1980s.[66] A series of 1950s essays by Henry Phelps 
Brown and Sheila V. Hopkins later set the academic consensus that the bulk 
of the population, that was at the bottom of the social ladder, suffered severe 
reductions in their living standards.[66] During 1813 1913, there was a 
significant increase in worker wages.[67][68][69]

Some economists, such as Robert E. Lucas, Jr., say that the real impact of 
the Industrial Revolution was that "for the first time in history, the living 
standards of the masses of ordinary people have begun to undergo 
sustained growth ... Nothing remotely like this economic behavior is 
mentioned by the classical economists, even as a theoretical possibility."[2] 
Others, however, argue that while growth of the economy's overall 
productive powers was unprecedented during the Industrial Revolution, 
living standards for the majority of the population did not grow meaningfully 
until the late 19th and 20th centuries, and that in many ways workers' living 
standards declined under early capitalism: for instance, studies have shown 
that real wages in Britain only increased 15% between the 1780s and 1850s, 
and that life expectancy in Britain did not begin to dramatically increase until 
the 1870s.[3][4]

Food and nutrition
Main article: British Agricultural Revolution
Chronic hunger and malnutrition were the norm for the majority of the 
population of the world including Britain and France, until the late 19th 
century. Until about 1750, in large part due to malnutrition, life expectancy in 
France was about 35 years, and only slightly higher in Britain. The US 
population of the time was adequately fed, much taller on average and had 
life expectancy of 45 50 years.[70]

In Britain and the Netherlands, food supply had been increasing and prices 
falling before the Industrial Revolution due to better agricultural practices; 
however, population grew too, as noted by Thomas Malthus.[1][47][71][72] 
Before the Industrial Revolution, advances in agriculture or technology soon 
led to an increase in population, which again strained food and other 
resources, limiting increases in per capita income. This condition is called 
the Malthusian trap, and it was finally overcome by industrialisation.[47]

Transportation improvements, such as canals and improved roads, also 
lowered food costs. Railroads were introduced near the end of the Industrial 
Revolution.

Housing

Over London by Rail Gustave Dor  c. 1870. Shows the densely populated 
and polluted environments created in the new industrial cities.
Living conditions during the Industrial Revolution varied from splendour for 
factory owners to squalor for workers.[citation needed]

In The Condition of the Working Class in England in 1844 Friedrich Engels 
described backstreet sections of Manchester and other mill towns, where 
people lived in crude shanties and shacks, some not completely enclosed, 
some with dirt floors. These shantytowns had narrow walkways between 
irregularly shaped lots and dwellings. There were no sanitary facilities. 
Population density was extremely high. Eight to ten unrelated mill workers 
often shared a room, often with no furniture, and slept on a pile of straw or 
sawdust.[73] Toilet facilities were shared if they existed. Disease spread 
through a contaminated water supply. Also, people were at risk of 
developing pathologies due to persistent dampness.

The famines that troubled rural areas did not happen in industrial areas. But 
urban people especially small children died due to diseases spreading 
through the cramped living conditions. Tuberculosis (spread in congested 
dwellings), lung diseases from the mines, cholera from polluted water and 
typhoid were also common.

Not everyone lived in such poor conditions. The Industrial Revolution also 
created a middle class of professionals, such as lawyers and doctors, who 
lived in much better conditions.

Conditions improved over the course of the 19th century due to new public 
health acts regulating things such as sewage, hygiene and home 
construction. In the introduction of his 1892 edition, Engels notes that most 
of the conditions he wrote about in 1844 had been greatly improved.

Clothing and consumer goods
Consumers benefited from falling prices for clothing and household articles 
such as cast iron cooking utensils, and in the following decades, stoves for 
cooking and space heating.

Population increase
According to Robert Hughes in The Fatal Shore, the population of England 
and Wales, which had remained steady at 6 million from 1700 to 1740, rose 
dramatically after 1740. The population of England had more than doubled 
from 8.3 million in 1801 to 16.8 million in 1850 and, by 1901, had nearly 
doubled again to 30.5 million.[74] Improved conditions led to the population 
of Britain increasing from 10 million to 40 million in the 1800s.[75][76] 
Europe's population increased from about 100 million in 1700 to 400 million 
by 1900.[77]

The Industrial Revolution was the first period in history during which there 
was a simultaneous increase in population and in per capita income.[78]

Labour conditions
Social structure and working conditions
In terms of social structure, the Industrial Revolution witnessed the triumph 
of a middle class of industrialists and businessmen over a landed class of 
nobility and gentry. Ordinary working people found increased opportunities 
for employment in the new mills and factories, but these were often under 
strict working conditions with long hours of labour dominated by a pace set 
by machines. As late as the year 1900, most industrial workers in the United 
States still worked a 10-hour day (12 hours in the steel industry), yet earned 
from 20% to 40% less than the minimum deemed necessary for a decent 
life.[79] However, harsh working conditions were prevalent long before the 
Industrial Revolution took place. Pre-industrial society was very static and 
often cruel child labour, dirty living conditions, and long working hours were 
just as prevalent before the Industrial Revolution.[80]

Factories and urbanisation

Manchester, England ("Cottonopolis"), pictured in 1840, showing the mass 
of factory chimneys
Industrialisation led to the creation of the factory. Arguably the first highly 
mechanised was John Lombe's water-powered silk mill at Derby, operational 
by 1721. Lombe learned silk thread manufacturing by taking a job in Italy 
and acting as an industrial spy; however, since the silk industry there was a 
closely guarded secret, the state of the industry there is unknown. Because 
Lombe's factory was not successful and there was no follow through, the 
rise of the modern factory dates to somewhat later when cotton spinning was 
mechanised.

The factory system contributed to the growth of urban areas, as large 
numbers of workers migrated into the cities in search of work in the factories. 
Nowhere was this better illustrated than the mills and associated industries 
of Manchester, nicknamed "Cottonopolis", and the world's first industrial 
city.[81] Manchester experienced a six-times increase in its population 
between 1771 and 1831. Bradford grew by 50% every ten years between 
1811 and 1851 and by 1851 only 50% of the population of Bradford was 
actually born there.[82]

For much of the 19th century, production was done in small mills, which 
were typically water-powered and built to serve local needs. Later, each 
factory would have its own steam engine and a chimney to give an efficient 
draft through its boiler.

The transition to industrialisation was not without difficulty. For example, a 
group of English workers known as Luddites formed to protest against 
industrialisation and sometimes sabotaged factories.

In other industries the transition to factory production was not so divisive. 
Some industrialists themselves tried to improve factory and living conditions 
for their workers. One of the earliest such reformers was Robert Owen, 
known for his pioneering efforts in improving conditions for workers at the 
New Lanark mills, and often regarded as one of the key thinkers of the early 
socialist movement.

By 1746, an integrated brass mill was working at Warmley near Bristol. Raw 
material went in at one end, was smelted into brass and was turned into 
pans, pins, wire, and other goods. Housing was provided for workers on site. 
Josiah Wedgwood and Matthew Boulton (whose Soho Manufactory was 
completed in 1766) were other prominent early industrialists, who employed 
the factory system.

Child labour

A young "drawer" pulling a coal tub along a mine gallery.[83] In Britain laws 
passed in 1842 and 1844 improved mine working conditions.

Wheaton Glass Works, November 1909. Photographed by Lewis Hine.
The Industrial Revolution led to a population increase but the chances of 
surviving childhood did not improve throughout the Industrial Revolution, 
although infant mortality rates were reduced markedly.[84][85] There was 
still limited opportunity for education and children were expected to work. 
Employers could pay a child less than an adult even though their 
productivity was comparable; there was no need for strength to operate an 
industrial machine, and since the industrial system was completely new, 
there were no experienced adult labourers. This made child labour the 
labour of choice for manufacturing in the early phases of the Industrial 
Revolution between the 18th and 19th centuries. In England and Scotland in 
1788, two-thirds of the workers in 143 water-powered cotton mills were 
described as children.[86]

Child labour existed before the Industrial Revolution but with the increase in 
population and education it became more visible. Many children were forced 
to work in relatively bad conditions for much lower pay than their elders,[87] 
10 20% of an adult male's wage.[88] Children as young as four were 
employed.[88] Beatings and long hours were common, with some child coal 
miners and hurriers working from 4 am until 5 pm.[88] Conditions were 
dangerous, with some children killed when they dozed off and fell into the 
path of the carts, while others died from gas explosions.[88] Many children 
developed lung cancer and other diseases and died before the age of 25.
[88] Workhouses would sell orphans and abandoned children as "pauper 
apprentices", working without wages for board and lodging.[88] Those who 
ran away would be whipped and returned to their masters, with some 
masters shackling them to prevent escape.[88] Children employed as mule 
scavengers by cotton mills would crawl under machinery to pick up cotton, 
working 14 hours a day, six days a week. Some lost hands or limbs, others 
were crushed under the machines, and some were decapitated.[88] Young 
girls worked at match factories, where phosphorus fumes would cause many 
to develop phossy jaw.[88] Children employed at glassworks were regularly 
burned and blinded, and those working at potteries were vulnerable to 
poisonous clay dust.[88]

Reports were written detailing some of the abuses, particularly in the coal 
mines[89] and textile factories,[90] and these helped to popularise the 
children's plight. The public outcry, especially among the upper and middle 
classes, helped stir change in the young workers' welfare.

Politicians and the government tried to limit child labour by law but factory 
owners resisted; some felt that they were aiding the poor by giving their 
children money to buy food to avoid starvation, and others simply welcomed 
the cheap labour. In 1833 and 1844, the first general laws against child 
labour, the Factory Acts, were passed in Britain: Children younger than nine 
were not allowed to work, children were not permitted to work at night, and 
the work day of youth under the age of 18 was limited to twelve hours. 
Factory inspectors supervised the execution of the law, however, their 
scarcity made enforcement difficult.[88] About ten years later, the 
employment of children and women in mining was forbidden. These laws 
decreased the number of child labourers, however child labour remained in 
Europe and the United States up to the 20th century.[91]

Luddites
Main article: Luddite
Refer to caption
Luddites smashing a power loom in 1812

The Great Chartist Meeting on Kennington Common, 1848
The rapid industrialisation of the English economy cost many craft workers 
their jobs. The movement started first with lace and hosiery workers near 
Nottingham and spread to other areas of the textile industry owing to early 
industrialisation. Many weavers also found themselves suddenly 
unemployed since they could no longer compete with machines which only 
required relatively limited (and unskilled) labour to produce more cloth than 
a single weaver. Many such unemployed workers, weavers and others, 
turned their animosity towards the machines that had taken their jobs and 
began destroying factories and machinery. These attackers became known 
as Luddites, supposedly followers of Ned Ludd, a folklore figure. The first 
attacks of the Luddite movement began in 1811. The Luddites rapidly gained 
popularity, and the British government took drastic measures, using the 
militia or army to protect industry. Those rioters who were caught were tried 
and hanged, or transported for life.

Unrest continued in other sectors as they industrialised, such as with 
agricultural labourers in the 1830s when large parts of southern Britain were 
affected by the Captain Swing disturbances. Threshing machines were a 
particular target, and hayrick burning was a popular activity. However, the 
riots led to the first formation of trade unions, and further pressure for 
reform.

Organisation of labour
See also: Trade union   History
The Industrial Revolution concentrated labour into mills, factories and mines, 
thus facilitating the organisation of combinations or trade unions to help 
advance the interests of working people. The power of a union could 
demand better terms by withdrawing all labour and causing a consequent 
cessation of production. Employers had to decide between giving in to the 
union demands at a cost to themselves or suffering the cost of the lost 
production. Skilled workers were hard to replace, and these were the first 
groups to successfully advance their conditions through this kind of 
bargaining.

The main method the unions used to effect change was strike action. Many 
strikes were painful events for both sides, the unions and the management. 
In Britain, the Combination Act 1799 forbade workers to form any kind of 
trade union until its repeal in 1824. Even after this, unions were still severely 
restricted.

In 1832, the Reform Act extended the vote in Britain but did not grant 
universal suffrage. That year six men from Tolpuddle in Dorset founded the 
Friendly Society of Agricultural Labourers to protest against the gradual 
lowering of wages in the 1830s. They refused to work for less than ten 
shillings a week, although by this time wages had been reduced to seven 
shillings a week and were due to be further reduced to six. In 1834 James 
Frampton, a local landowner, wrote to the Prime Minister, Lord Melbourne, to 
complain about the union, invoking an obscure law from 1797 prohibiting 
people from swearing oaths to each other, which the members of the 
Friendly Society had done. James Brine, James Hammett, George Loveless, 
George's brother James Loveless, George's brother in-law Thomas 
Standfield, and Thomas's son John Standfield were arrested, found guilty, 
and transported to Australia. They became known as the Tolpuddle Martyrs. 
In the 1830s and 1840s, the Chartist movement was the first large-scale 
organised working class political movement which campaigned for political 
equality and social justice. Its Charter of reforms received over three million 
signatures but was rejected by Parliament without consideration.

Working people also formed friendly societies and co-operative societies as 
mutual support groups against times of economic hardship. Enlightened 
industrialists, such as Robert Owen also supported these organisations to 
improve the conditions of the working class.

Unions slowly overcame the legal restrictions on the right to strike. In 1842, a 
general strike involving cotton workers and colliers was organised through 
the Chartist movement which stopped production across Great Britain.[92]

Eventually, effective political organisation for working people was achieved 
through the trades unions who, after the extensions of the franchise in 1867 
and 1885, began to support socialist political parties that later merged to 
become the British Labour Party.

Other effects
The application of steam power to the industrial processes of printing 
supported a massive expansion of newspaper and popular book publishing, 
which reinforced rising literacy and demands for mass political participation.

During the Industrial Revolution, the life expectancy of children increased 
dramatically. The percentage of the children born in London who died before 
the age of five decreased from 74.5% in 1730 1749 to 31.8% in 1810 1829.
[84]

The growth of modern industry since the late 18th century led to massive 
urbanisation and the rise of new great cities, first in Europe and then in other 
regions, as new opportunities brought huge numbers of migrants from rural 
communities into urban areas. In 1800, only 3% of the world's population 
lived in cities,[93] compared to nearly 50% today (the beginning of the 21st 
century).[94] Manchester had a population of 10,000 in 1717, but by 1911 it 
had burgeoned to 2.3 million.[95]

Industrialisation beyond the United Kingdom
Continental Europe
Eric Hobsbawm held that the Industrial Revolution began in Britain in the 
1780s and was not fully felt until the 1830s or 1840s,[5] while T. S. Ashton 
held that it occurred roughly between 1760 and 1830.[6] The Industrial 
Revolution on Continental Europe came a little later than in Great Britain. In 
many industries, this involved the application of technology developed in 
Britain in new places. Often the technology was purchased from Britain or 
British engineers and entrepreneurs moved abroad in search of new 
opportunities. By 1809, part of the Ruhr Valley in Westphalia was called 
'Miniature England' because of its similarities to the industrial areas of 
England. The German, Russian and Belgian governments all provided state 
funding to the new industries. In some cases (such as iron), the different 
availability of resources locally meant that only some aspects of the British 
technology were adopted.

Belgium

Workers' housing at Bois-du-Luc (1838 1853) in La Louvi re
Belgium was the second country, after Britain, in which the Industrial 
Revolution took place and the first in continental Europe: Wallonia (French 
speaking southern Belgium) was the first region to follow the British model 
successfully. Starting in the middle of the 1820s, and especially after 
Belgium became an independent nation in 1830, numerous works 
comprising coke blast furnaces as well as puddling and rolling mills were 
built in the coal mining areas around Li ge and Charleroi. The leader was a 
transplanted Englishman John Cockerill. His factories at Seraing integrated 
all stages of production, from engineering to the supply of raw materials, as 
early as 1825.[96]

Wallonia exemplified the radical evolution of industrial expansion. Thanks to 
coal (the French word "houille" was coined in Wallonia),[97] the region 
geared up to become the 2nd industrial power in the world after Britain. But 
it is also pointed out by many researchers, with its Sillon industriel, 
'Especially in the Haine, Sambre and Meuse valleys, between the Borinage 
and Li ge, (...) there was a huge industrial development based on coal-
mining and iron-making...'.[98] Philippe Raxhon wrote about the period after 
1830: "It was not propaganda but a reality the Walloon regions were 
becoming the second industrial power all over the world after Britain."[99] 
"The sole industrial centre outside the collieries and blast furnaces of 
Walloon was the old cloth making town of Ghent."[100] Michel De Coster, 
Professor at the Universit  de Li ge wrote also: "The historians and the 
economists say that Belgium was the second industrial power of the world, 
in proportion to its population and its territory (...) But this rank is the one of 
Wallonia where the coal-mines, the blast furnaces, the iron and zinc 
factories, the wool industry, the glass industry, the weapons industry... were 
concentrated." [101]

Demographic effects

Wallonia's Sillon industriel (the blue area in the north is not in Wallonia)

Gallow frame of the Crachet in Frameries IN Wallonia's French Ch ssis   
molettes or Belfleur (French Chevalement)

Official Poster of the Li ge's World fair in 1905
Wallonia was also the birthplace of a strong Socialist party and strong 
trade-unions in a particular sociological landscape. At the left, the Sillon 
industriel, which runs from Mons in the west, to Verviers in the east (except 
part of North Flanders, in another period of the industrial revolution, after 
1920). Even if Belgium is the second industrial country after Britain, the 
effect of the industrial revolution there was very different. In 'Breaking 
stereotypes', Muriel Neven and Isabelle Devious say:

The industrial revolution changed a mainly rural society into an urban one, 
but with a strong contrast between northern and southern Belgium. During 
the Middle Ages and the Early Modern Period, Flanders was characterised 
by the presence of large urban centres (...) at the beginning of the 
nineteenth century this region (Flanders), with an urbanisation degree of 
more than 30 per cent, remained one of the most urbanised in the world. By 
comparison, this proportion reached only 17 per cent in Wallonia, barely 10 
per cent in most West European countries, 16 per cent in France and 25 per 
cent in Britain. Nineteenth century industrialisation did not affect the 
traditional urban infrastructure, except in Ghent (...) Also, in Wallonia the 
traditional urban network was largely unaffected by the industrialisation 
process, even though the proportion of city-dwellers rose from 17 to 45 per 
cent between 1831 and 1910. Especially in the Haine, Sambre and Meuse 
valleys, between the Borinage and Li ge, where there was a huge industrial 
development based on coal-mining and iron-making, urbanisation was fast. 
During these eighty years the number of municipalities with more than 5,000 
inhabitants increased from only 21 to more than one hundred, concentrating 
nearly half of the Walloon population in this region. Nevertheless, 
industrialisation remained quite traditional in the sense that it did not lead to 
the growth of modern and large urban centres, but to a conurbation of 
industrial villages and towns developed around a coal-mine or a factory. 
Communication routes between these small centres only became populated 
later and created a much less dense urban morphology than, for instance, 
the area around Li ge where the old town was there to direct migratory 
flows.[102]

France
Main article: Economic history of France
The industrial revolution in France followed a particular course as it did not 
correspond to the main model followed by other countries. Notably, most 
French historians argue France did not go through a clear take-off.[103] 
Instead, France's economic growth and industrialisation process was slow 
and steady through the 18th and 19th centuries. However, some stages 
were identified by Maurice L vy-Leboyer:

French Revolution and Napoleonic wars (1789 1815),
industrialisation, along with Britain (1815 1860),
economic slowdown (1860 1905),
renewal of the growth after 1905.
Germany
Main article: Economic history of Germany

The BASF-chemical factories in Ludwigshafen, Germany, 1881
Based on its leadership in chemical research in the universities and 
industrial laboratories, Germany, which was unified in 1871, became 
dominant in the world's chemical industry in the late 19th century. At first the 
production of dyes based on aniline was critical.[104]

Germany's political disunity with three dozen states and a pervasive 
conservatism made it difficult to build railways in the 1830s. However, by the 
1840s, trunk lines linked the major cities; each German state was 
responsible for the lines within its own borders. Lacking a technological base 
at first, the Germans imported their engineering and hardware from Britain, 
but quickly learned the skills needed to operate and expand the railways. In 
many cities, the new railway shops were the centres of technological 
awareness and training, so that by 1850, Germany was self-sufficient in 
meeting the demands of railroad construction, and the railways were a major 
impetus for the growth of the new steel industry. Observers found that even 
as late as 1890, their engineering was inferior to Britain's. However, German 
unification in 1870 stimulated consolidation, nationalisation into state-owned 
companies, and further rapid growth. Unlike the situation in France, the goal 
was support of industrialisation, and so heavy lines crisscrossed the Ruhr 
and other industrial districts, and provided good connections to the major 
ports of Hamburg and Bremen. By 1880, Germany had 9,400 locomotives 
pulling 43,000 passengers and 30,000 tons of freight, and pulled ahead of 
France[105]

Sweden
Main article: Economic history of Sweden
During the period 1790 1815 Sweden experienced two parallel economic 
movements: an agricultural revolution with larger agricultural estates, new 
crops and farming tools and a commercialisation of farming, and a 
protoindustrialisation, with small industries being established in the 
countryside and with workers switching between agricultural work in summer 
and industrial production in winter. This led to economic growth benefiting 
large sections of the population and leading up to a consumption revolution 
starting in the 1820s.

During 1815 1850 the protoindustries developed into more specialized and 
larger industries. This period witnessed increasing regional specialisation 
with mining in Bergslagen, textile mills in Sjuh radsbygden and forestry in 
Norrland. Several important institutional changes took place in this period, 
such as free and mandatory schooling introduced 1842 (as first country in 
the world), the abolition of the national monopoly on trade in handicrafts in 
1846, and a stock company law in 1848.

During 1850 1890, Sweden experienced a veritable explosion in export, 
dominated by crops, wood and steel. Sweden abolished most tariffs and 
other barriers to free trade in the 1850s and joined the gold standard in 
1873.

During 1890 1930, Sweden experienced the second industrial revolution. 
New industries developed with their focus on the domestic market: 
mechanical engineering, power utilities, papermaking and textile.

United States
Main articles: Economic history of the United States and Technological and 
industrial history of the United States

Slater's Mill
See also: History of Lowell, Massachusetts
During the late 18th an early 19th centuries when the UK and parts of 
Western Europe began to industrialize, the US was primarily an agricultural 
and natural resource producing and processing economy.[106] The building 
of roads and canals, the introduction of steamboats and the building of 
railroads were important for handling agricultural and natural resource 
products in the large and sparsely populated country of the period.[107]
[108]

Important American technological contributions during the period of the 
Industrial Revolution were the cotton gin and the development of a system 
for making interchangeable parts, the latter aided by the development of the 
milling machine in the US. The development of machine tools and the 
system of interchangeable parts were the basis for the rise of the US as the 
world's leading industrial nation in the late 19th century.

Oliver Evans invented an automated flour mill in the mid 1780s that used 
control mechanisms and conveyors so that no labor was needed from the 
time grain was loaded into the elevator buckets until flour was discharged 
into a wagon. This is considered to be the first modern materials handling 
system an important advance in the progress toward mass production.[34]

The United States originally used horse-powered machinery to power its 
earliest factories, but eventually switched to water power. As a result, 
industrialisation was essentially limited to New England and the rest of 
Northeastern United States, which has fast-moving rivers. The newer water-
powered production lines proved more economical than horse-drawn 
production. However, raw materials (especially cotton) came from the 
Southern United States. It was not until after the Civil War in the 1860s that 
steam-powered manufacturing overtook water-powered manufacturing, 
allowing the industry to fully spread across the nation.

Thomas Somers and the Cabot Brothers founded the Beverly Cotton 
Manufactory in 1787, the first cotton mill in America, the largest cotton mill of 
its era,[109] and a significant milestone in the research and development of 
cotton mills in the future. This mill was designed to use horse power, but the 
operators quickly learned that the horse-drawn platform was economically 
unstable, and had economic losses for years. Despite the losses, the 
Manufactory served as a playground of innovation, both in turning a large 
amount of cotton, but also developing the water-powered milling structure 
used in Slater's Mill.[110]


Bethlehem Steel, founded in 1857, was once the second-largest 
manufacturer of steel in the United States; its Bethlehem, Pennsylvania, 
location has been transformed into a casino.
In 1793, Samuel Slater (1768 1835) founded the Slater Mill at Pawtucket, 
Rhode Island. He had learned of the new textile technologies as a boy 
apprentice in Derbyshire, England, and defied laws against the emigration of 
skilled workers by leaving for New York in 1789, hoping to make money with 
his knowledge. After founding Slater's Mill, he went on to own 13 textile 
mills.[111] Daniel Day established a wool carding mill in the Blackstone 
Valley at Uxbridge, Massachusetts in 1809, the third woollen mill established 
in the US (The first was in Hartford, Connecticut, and the second at 
Watertown, Massachusetts.) The John H. Chafee Blackstone River Valley 
National Heritage Corridor retraces the history of "America's Hardest-
Working River', the Blackstone. The Blackstone River and its tributaries, 
which cover more than 45 miles (72 km) from Worcester, Massachusetts to 
Providence, Rhode Island, was the birthplace of America's Industrial 
Revolution. At its peak over 1100 mills operated in this valley, including 
Slater's mill, and with it the earliest beginnings of America's Industrial and 
Technological Development.


Men working their own coal mines. Early 1900s, United States.
Merchant Francis Cabot Lowell from Newburyport, Massachusetts 
memorised the design of textile machines on his tour of British factories in 
1810. Realising that the War of 1812 had ruined his import business but that 
a demand for domestic finished cloth was emerging in America, on his return 
to the United States, he set up the Boston Manufacturing Company. Lowell 
and his partners built America's second cotton-to-cloth textile mill at 
Waltham, Massachusetts, second to the Beverly Cotton Manufactory. After 
his death in 1817, his associates built America's first planned factory town, 
which they named after him. This enterprise was capitalised in a public stock 
offering, one of the first uses of it in the United States. Lowell, 
Massachusetts, using 5.6 miles (9.0 km) of canals and 10,000 horsepower 
delivered by the Merrimack River, is considered by some as a major 
contributor to the success of the American Industrial Revolution. The short-
lived utopia-like Waltham-Lowell system was formed, as a direct response to 
the poor working conditions in Britain. However, by 1850, especially following 
the Irish Potato Famine, the system had been replaced by poor immigrant 
labour.

The industrialisation of the watch industry started 1854 also in Waltham, 
Massachusetts, at the Waltham Watch Company, with the development of 
machine tools, gauges and assembling methods adapted to the micro 
precision required for watches.

Japan
Main articles: Meiji Restoration and Economic history of Japan
The industrial revolution began about 1870 as Meiji period leaders decided 
to catch up with the West. The government built railroads, improved roads, 
and inaugurated a land reform program to prepare the country for further 
development. It inaugurated a new Western-based education system for all 
young people, sent thousands of students to the United States and Europe, 
and hired more than 3,000 Westerners to teach modern science, 
mathematics, technology, and foreign languages in Japan (O-yatoi 
gaikokujin).

In 1871, a group of Japanese politicians known as the Iwakura Mission 
toured Europe and the United States to learn western ways. The result was 
a deliberate state-led industrialisation policy to enable Japan to quickly catch 
up. The Bank of Japan, founded in 1882,[112] used taxes to fund model 
steel and textile factories. Education was expanded and Japanese students 
were sent to study in the west.

Modern industry first appeared in textiles, including cotton and especially 
silk, which was based in home workshops in rural areas.[113]

Second Industrial Revolutions
Main articles: Second Industrial Revolution and Suez Canal

S chsische Maschinenfabrik in Chemnitz, Germany, 1868

Bessemer converter
Steel is often cited as the first of several new areas for industrial mass-
production, which are said to characterise a "Second Industrial Revolution", 
beginning around 1850, although a method for mass manufacture of steel 
was not invented until the 1860s, when Sir Henry Bessemer invented a new 
furnace which could convert molten pig iron into steel in large quantities. 
However, it only became widely available in the 1870s after the process was 
modified to produce more uniform quality.[23][114] Bessemer steel was 
being displaced by the open hearth furnace near the end of the 19th 
century.

This second Industrial Revolution gradually grew to include chemicals, 
mainly the chemical industries, petroleum (refining and distribution), and, in 
the 20th century, the automotive industries, and was marked by a transition 
of technological leadership from Britain to the United States and Germany.

The increasing availability of economical petroleum products also reduced 
the importance of coal and further widened the potential for industrialisation.

A new revolution began with electricity and electrification in the electrical 
industries. The introduction of hydroelectric power generation in the Alps 
enabled the rapid industrialisation of coal-deprived northern Italy, beginning 
in the 1890s.

By the 1890s, industrialisation in these areas had created the first giant 
industrial corporations with burgeoning global interests, as companies like 
U.S. Steel, General Electric, Standard Oil and Bayer AG joined the railroad 
and ship companies on the world's stock markets.

Intellectual paradigms and criticism
Capitalism
Main article: Capitalism
The advent of the Age of Enlightenment provided an intellectual framework 
which welcomed the practical application of the growing body of scientific 
knowledge a factor evidenced in the systematic development of the steam 
engine, guided by scientific analysis, and the development of the political 
and sociological analyses, culminating in Scottish economist Adam Smith's 
The Wealth of Nations. One of the main arguments for capitalism, presented 
for example in the book The Improving State of the World, is that 
industrialisation increases wealth for all, as evidenced by raised life 
expectancy, reduced working hours, and no work for children and the 
elderly.

Socialism
Main article: Socialism
Socialism emerged as a critique of capitalism. Marxism began essentially as 
a reaction to the Industrial Revolution.[115] According to Karl Marx, 
industrialisation polarised society into the bourgeoisie (those who own the 
means of production, the factories and the land) and the much larger 
proletariat (the working class who actually perform the labour necessary to 
extract something valuable from the means of production). He saw the 
industrialisation process as the logical dialectical progression of feudal 
economic modes, necessary for the full development of capitalism, which he 
saw as in itself a necessary precursor to the development of socialism and 
eventually communism.

Romanticism
Main article: Romanticism
During the Industrial Revolution an intellectual and artistic hostility towards 
the new industrialisation developed, associated with the Romantic 
movement. Its major exponents in English included the artist and poet 
William Blake and poets William Wordsworth, Samuel Taylor Coleridge, John 
Keats, Lord Byron and Percy Bysshe Shelley. The movement stressed the 
importance of "nature" in art and language, in contrast to "monstrous" 
machines and factories; the "Dark satanic mills" of Blake's poem "And did 
those feet in ancient time". Mary Shelley's novel Frankenstein reflected 
concerns that scientific progress might be two-edged.

Causes

Regional GDP per capita changed very little for most of human history 
before the Industrial Revolution.
The causes of the Industrial Revolution were complicated and remain a topic 
for debate, with some historians believing the Revolution was an outgrowth 
of social and institutional changes brought by the end of feudalism in Britain 
after the English Civil War in the 17th century. As national border controls 
became more effective, the spread of disease was lessened, thereby 
preventing the epidemics common in previous times.[116] The percentage of 
children who lived past infancy rose significantly, leading to a larger 
workforce. The Enclosure movement and the British Agricultural Revolution 
made food production more efficient and less labour-intensive, forcing the 
surplus population who could no longer find employment in agriculture into 
cottage industry, for example weaving, and in the longer term into the cities 
and the newly developed factories.[117] The colonial expansion of the 17th 
century with the accompanying development of international trade, creation 
of financial markets and accumulation of capital are also cited as factors, as 
is the scientific revolution of the 17th century.[118]

Until the 1980s, it was universally believed by academic historians that 
technological innovation was the heart of the Industrial Revolution and the 
key enabling technology was the invention and improvement of the steam 
engine.[119] However, recent research into the Marketing Era has 
challenged the traditional, supply-oriented interpretation of the Industrial 
Revolution.[120]

Lewis Mumford has proposed that the Industrial Revolution had its origins in 
the Early Middle Ages, much earlier than most estimates.[121] He explains 
that the model for standardised mass production was the printing press and 
that "the archetypal model for the industrial era was the clock". He also cites 
the monastic emphasis on order and time-keeping, as well as the fact that 
medieval cities had at their centre a church with bell ringing at regular 
intervals as being necessary precursors to a greater synchronisation 
necessary for later, more physical, manifestations such as the steam engine.

The presence of a large domestic market should also be considered an 
important driver of the Industrial Revolution, particularly explaining why it 
occurred in Britain. In other nations, such as France, markets were split up 
by local regions, which often imposed tolls and tariffs on goods traded 
among them.[122] Internal tariffs were abolished by Henry VIII of England, 
they survived in Russia till 1753, 1789 in France and 1839 in Spain.

Governments' grant of limited monopolies to inventors under a developing 
patent system (the Statute of Monopolies in 1623) is considered an 
influential factor. The effects of patents, both good and ill, on the 
development of industrialisation are clearly illustrated in the history of the 
steam engine, the key enabling technology. In return for publicly revealing 
the workings of an invention the patent system rewarded inventors such as 
James Watt by allowing them to monopolise the production of the first steam 
engines, thereby rewarding inventors and increasing the pace of 
technological development. However, monopolies bring with them their own 
inefficiencies which may counterbalance, or even overbalance, the beneficial 
effects of publicising ingenuity and rewarding inventors.[123] Watt's 
monopoly may have prevented other inventors, such as Richard Trevithick, 
William Murdoch or Jonathan Hornblower, from introducing improved steam 
engines, thereby retarding the industrial revolution by about 16 years.[124]
[125]

Causes in Europe
Main article: Great Divergence

A 1623 Dutch East India Company bond.
European 17th-century colonial expansion, international trade, and creation 
of financial markets produced a new legal and financial environment, one 
which supported and enabled 18th-century industrial growth.
One question of active interest to historians is why the Industrial Revolution 
occurred in Europe and not in other parts of the world in the 18th century, 
particularly China, India, and the Middle East, or at other times like in 
Classical Antiquity[126] or the Middle Ages.[127] Numerous factors have 
been suggested, including education, technological changes[128] (see 
Scientific Revolution in Europe), "modern" government, "modern" work 
attitudes, ecology, and culture.[129] However, most historians contest the 
assertion that Europe and China were roughly equal because modern 
estimates of per capita income on Western Europe in the late 18th century 
are of roughly 1,500 dollars in purchasing power parity (and Britain had a 
per capita income of nearly 2,000 dollars[130]) whereas China, by 
comparison, had only 450 dollars.

Some historians such as David Landes and Max Weber credit the different 
belief systems in Asia and Europe with dictating where the revolution 
occurred.[1]:20 32 The religion and beliefs of Europe were largely products 
of Judaeo-Christianity and Greek thought. Conversely, Chinese society was 
founded on men like Confucius, Mencius, Han Feizi (Legalism), Lao Tzu 
(Taoism), and Buddha (Buddhism), resulting in very different worldviews.
[131] Other factors include the considerable distance of China's coal 
deposits, though large, from its cities as well as the then unnavigable Yellow 
River that connects these deposits to the sea.[132]

Regarding India, the Marxist historian Rajani Palme Dutt said: "The capital to 
finance the Industrial Revolution in India instead went into financing the 
Industrial Revolution in Britain."[133] In contrast to China, India was split up 
into many competing kingdoms, with the three major ones being the 
Marathas, Sikhs and the Mughals. In addition, the economy was highly 
dependent on two sectors agriculture of subsistence and cotton, and there 
appears to have been little technical innovation. It is believed that the vast 
amounts of wealth were largely stored away in palace treasuries by 
totalitarian monarchs prior to the British take over.

Causes in Britain

As the Industrial Revolution developed British manufactured output surged 
ahead of other economies. After the Industrial Revolution, it was overtaken 
later by the United States.
Great Britain provided the legal and cultural foundations that enabled 
entrepreneurs to pioneer the industrial revolution.[134] Key factors fostering 
this environment were: (1) The period of peace and stability which followed 
the unification of England and Scotland; (2) no trade barriers between 
England and Scotland; (3) the rule of law (respecting the sanctity of 
contracts); (4) a straightforward legal system which allowed the formation of 
joint-stock companies (corporations); and (5) a free market (capitalism).[1]

Geographical and natural resource advantages of Great Britain were the fact 
that it had extensive coast lines and many navigable rivers in an age where 
water was the easiest means of transportation and having the highest quality 
coal in Europe.[1]

There were two main values that really drove the Industrial Revolution in 
Britain. These values were self-interest and an entrepreneurial spirit. 
Because of these interests, many industrial advances were made that 
resulted in a huge increase in personal wealth. These advancements also 
greatly benefitted the British society as a whole. Countries around the world 
started to recognise the changes and advancements in Britain and use them 
as an example to begin their own Industrial Revolutions.[135]

The debate about the start of the Industrial Revolution also concerns the 
massive lead that Great Britain had over other countries. Some have 
stressed the importance of natural or financial resources that Britain received 
from its many overseas colonies or that profits from the British slave trade 
between Africa and the Caribbean helped fuel industrial investment. 
However, it has been pointed out that slave trade and West Indian 
plantations provided only 5% of the British national income during the years 
of the Industrial Revolution.[136] Even though slavery accounted for so little, 
Caribbean-based demand accounted for 12% of Britain's industrial output.
[137]

Instead, the greater liberalisation of trade from a large merchant base may 
have allowed Britain to produce and use emerging scientific and 
technological developments more effectively than countries with stronger 
monarchies, particularly China and Russia. Britain emerged from the 
Napoleonic Wars as the only European nation not ravaged by financial 
plunder and economic collapse, and having the only merchant fleet of any 
useful size (European merchant fleets were destroyed during the war by the 
Royal Navy[138]). Britain's extensive exporting cottage industries also 
ensured markets were already available for many early forms of 
manufactured goods. The conflict resulted in most British warfare being 
conducted overseas, reducing the devastating effects of territorial conquest 
that affected much of Europe. This was further aided by Britain's 
geographical position an island separated from the rest of mainland Europe.

Another theory is that Britain was able to succeed in the Industrial 
Revolution due to the availability of key resources it possessed. It had a 
dense population for its small geographical size. Enclosure of common land 
and the related agricultural revolution made a supply of this labour readily 
available. There was also a local coincidence of natural resources in the 
North of England, the English Midlands, South Wales and the Scottish 
Lowlands. Local supplies of coal, iron, lead, copper, tin, limestone and water 
power, resulted in excellent conditions for the development and expansion of 
industry. Also, the damp, mild weather conditions of the North West of 
England provided ideal conditions for the spinning of cotton, providing a 
natural starting point for the birth of the textiles industry.

The stable political situation in Britain from around 1688, and British society's 
greater receptiveness to change (compared with other European countries) 
can also be said to be factors favouring the Industrial Revolution. Peasant 
resistance to industrialisation was largely eliminated by the Enclosure 
movement, and the landed upper classes developed commercial interests 
that made them pioneers in removing obstacles to the growth of capitalism.
[139] (This point is also made in Hilaire Belloc's The Servile State.)

Britain's population grew 280% 1550 1820, while the rest of Western Europe 
grew 50 80%. Seventy percent of European urbanisation happened in Britain 
1750 1800. By 1800, only the Netherlands was more urbanised than Britain. 
This was only possible because coal, coke, imported cotton, brick and slate 
had replaced wood, charcoal, flax, peat and thatch. The latter compete with 
land grown to feed people while mined materials do not. Yet more land 
would be freed when chemical fertilisers replaced manure and horse's work 
was mechanised. A workhorse needs 3 to 5 acres (1.21 to 2.02 ha) for fodder 
while even early steam engines produced four times more mechanical 
energy.

In 1700, 5/6 of coal mined worldwide was in Britain, while the Netherlands 
had none; so despite having Europe's best transport, most urbanised, well 
paid, literate people and lowest taxes, it failed to industrialise. In the 18th 
century, it was the only European country whose cities and population 
shrank. Without coal, Britain would have run out of suitable river sites for 
mills by the 1830s.[140]

Transfer of knowledge

A Philosopher Lecturing on the Orrery (ca. 1766). Informal philosophical 
societies spread scientific advances.
Knowledge of innovation was spread by several means. Workers who were 
trained in the technique might move to another employer or might be 
poached. A common method was for someone to make a study tour, 
gathering information where he could. During the whole of the Industrial 
Revolution and for the century before, all European countries and America 
engaged in study-touring; some nations, like Sweden and France, even 
trained civil servants or technicians to undertake it as a matter of state policy. 
In other countries, notably Britain and America, this practice was carried out 
by individual manufacturers eager to improve their own methods. Study 
tours were common then, as now, as was the keeping of travel diaries. 
Records made by industrialists and technicians of the period are an 
incomparable source of information about their methods.

Another means for the spread of innovation was by the network of informal 
philosophical societies, like the Lunar Society of Birmingham, in which 
members met to discuss 'natural philosophy' (i.e. science) and often its 
application to manufacturing. The Lunar Society flourished from 1765 to 
1809, and it has been said of them, "They were, if you like, the revolutionary 
committee of that most far reaching of all the eighteenth century revolutions, 
the Industrial Revolution".[141] Other such societies published volumes of 
proceedings and transactions. For example, the London-based Royal 
Society of Arts published an illustrated volume of new inventions, as well as 
papers about them in its annual Transactions.

There were publications describing technology. Encyclopaedias such as 
Harris's Lexicon Technicum (1704) and Abraham Rees's Cyclopaedia (1802 
1819) contain much of value. Cyclopaedia contains an enormous amount of 
information about the science and technology of the first half of the 
Industrial Revolution, very well illustrated by fine engravings. Foreign printed 
sources such as the Descriptions des Arts et M tiers and Diderot's Encyclop 
die explained foreign methods with fine engraved plates.

Periodical publications about manufacturing and technology began to 
appear in the last decade of the 18th century, and many regularly included 
notice of the latest patents. Foreign periodicals, such as the Annales des 
Mines, published accounts of travels made by French engineers who 
observed British methods on study tours.

Protestant work ethic
Main article: Protestant work ethic
Another theory is that the British advance was due to the presence of an 
entrepreneurial class which believed in progress, technology and hard 
work.[142] The existence of this class is often linked to the Protestant work 
ethic (see Max Weber) and the particular status of the Baptists and the 
dissenting Protestant sects, such as the Quakers and Presbyterians that 
had flourished with the English Civil War. Reinforcement of confidence in the 
rule of law, which followed establishment of the prototype of constitutional 
monarchy in Britain in the Glorious Revolution of 1688, and the emergence 
of a stable financial market there based on the management of the national 
debt by the Bank of England, contributed to the capacity for, and interest in, 
private financial investment in industrial ventures.

Dissenters found themselves barred or discouraged from almost all public 
offices, as well as education at England's only two universities at the time 
(although dissenters were still free to study at Scotland's four universities). 
When the restoration of the monarchy took place and membership in the 
official Anglican Church became mandatory due to the Test Act, they 
thereupon became active in banking, manufacturing and education. The 
Unitarians, in particular, were very involved in education, by running 
Dissenting Academies, where, in contrast to the universities of Oxford and 
Cambridge and schools such as Eton and Harrow, much attention was given 
to mathematics and the sciences areas of scholarship vital to the 
development of manufacturing technologies.

Historians sometimes consider this social factor to be extremely important, 
along with the nature of the national economies involved. While members of 
these sects were excluded from certain circles of the government, they were 
considered fellow Protestants, to a limited extent, by many in the middle 
class, such as traditional financiers or other businessmen. Given this relative 
tolerance and the supply of capital, the natural outlet for the more 
enterprising members of these sects would be to seek new opportunities in 
the technologies created in the wake of the scientific revolution of the 17th 
century.

See also
Portal icon Business and economics portal
General
Industrial Age
Machine Age
Capitalism in the nineteenth century
Capitalist mode of production
Deindustrialization
Division of labour
Law of the handicap of a head start   Dialectics of progress
Dual revolution
Economic history of the United Kingdom
Information revolution
The Protestant Ethic and the Spirit of Capitalism
Other
Chinese industrialization
Petroleum Revolution
Science and invention in Birmingham
References
Bibliography
Ashton, Thomas S. (1948). "The Industrial Revolution (1760 1830)". Oxford 
University Press.
Berlanstein, Lenard R., ed. (1992). The Industrial Revolution and work in 
nineteenth-century Europe. London and New York: Routledge.
Clapham, J. H. (1926). "An Economic History of Modern Britain: The Early 
Railway Age, 1820 1850". Cambridge University Press.
Clapham, J. H. The Economic Development of France and Germany 1815 
1914 (1936)
Clark, Gregory (2007). A Farewell to Alms: A Brief Economic History of the 
World. Princeton University Press. ISBN 0-691-12135-4.
Daunton, M. J. (1995). "Progress and Poverty: An Economic and Social 
History of Britain, 1700 1850". Oxford University Press.
Dodd, William (1847). The Laboring Classes of England : especially those 
engaged in agriculture and manufactures; in a series of letters. Boston: John 
Putnam.
Dunham, Arthur Louis (1955). "The Industrial Revolution in France, 1815 
1848". New York: Exposition Press.
Gatrell, Peter (2004). "Farm to factory: a reinterpretation of the Soviet 
industrial revolution". The Economic History Review 57 (4): 794. 
doi:10.1111/j.1468-0289.2004.00295_21.x.
Griffin, Emma (2010). Short History of the British Industrial Revolution. 
Palgrave.
Haber, Ludwig Fritz (1958). The Chemical Industry During the Nineteenth 
Century: A Study of the Economic Aspect of Applied Chemistry in Europe 
and North America.
Haber, Ludwig Fritz (1971). The Chemical Industry: 1900 1930: International 
Growth and Technological Change.
Jacob, Margaret C. (1997). "Scientific Culture and the Making of the 
Industrial West". Oxford, UK: Oxford University Press.
Kindleberger, Charles Poor (1993). A Financial History of Western Europe. 
Oxford University Press US. ISBN 0-19-507738-5.
Kisch, Herbert (1989). "From Domestic Manufacture to Industrial Revolution 
The Case of the Rhineland Textile Districts". Oxford University Press.
Kornblith, Gary. The Industrial Revolution in America (1997)
Landes, David S. (1969). The Unbound Prometheus: Technological Change 
and Industrial Development in Western Europe from 1750 to the Present. 
Cambridge, New York: Press Syndicate of the University of Cambridge. ISBN 
0-521-09418-6.
McNeil, Ian, ed. (1990). An Encyclopedia of the History of Technology. 
London: Routledge. ISBN 0-415-14792-1.
Maddison, Angus (2003). "The World Economy: Historical Statistics". Paris: 
Organisation for Economic Co-operation and Development (OECD).
Mantoux, Paul (1961) [1928]. "The Industrial Revolution in the Eighteenth 
Century" (First English translation 1928 ed.).
McLaughlin Green, Constance (1939). "Holyoke, Massachusetts: A Case 
History of the Industrial Revolution in America". New Haven, CT: Yale 
University Press.
Milward, Alan S. and S. B. Saul. The Development of the Economies of 
Continental Europe: 1850 1914 (1977)
Milward, Alan S. and S. B. Saul. The Economic Development of Continental 
Europe 1780 1870 (1973)
Mokyr, Joel (1999). "The British Industrial Revolution: An Economic 
Perspective".
More, Charles (2000). "Understanding the Industrial Revolution". London: 
Routledge.
Olson, James S. Encyclopedia of the Industrial Revolution in America (2001)
Pollard, Sidney (1981). "Peaceful Conquest: The Industrialization of Europe, 
1760 1970". Oxford University Press.
Rider, Christine, ed. Encyclopedia of the Age of the Industrial Revolution, 
1700 1920 (2 vol. 2007)
Roe, Joseph Wickham (1916), English and American Tool Builders, New 
Haven, Connecticut: Yale University Press, LCCN 16011753. Reprinted by 
McGraw-Hill, New York and London, 1926 (LCCN 27-24075); and by Lindsay 
Publications, Inc., Bradley, Illinois, (ISBN 978-0-917914-73-7).
Smelser, Neil J. (1959). "Social Change in the Industrial Revolution: An 
Application of Theory to the British Cotton Industry". University of Chicago 
Press.
Staley, David J. ed. Encyclopedia of the History of Invention and Technology 
(3 vol 2011), 2000pp
Stearns, Peter N. (1998). "The Industrial Revolution in World History". 
Westview Press.
Smil, Vaclav (1994). "Energy in World History". Westview Press. Archived 
from the original on 18 July 2007.
Snooks, G.D. (2000). "Was the Industrial Revolution Necessary ". London: 
Routledge.
Szostak, Rick (1991). "The Role of Transportation in the Industrial 
Revolution: A Comparison of England and France". Montreal: McGill-
Queen's University Press.
Timbs, John (1860). Stories of Inventors and Discoverers in Science and the 
Useful Arts: A Book for Old and Young. Harper & Brothers.
Toynbee, Arnold (1884). Lectures on the Industrial Revolution of the 
Eighteenth Century in England. ISBN 1-4191-2952-X. Retrieved 2016-02-12.
Uglow, Jenny (2002). "The Lunar Men: The Friends who made the Future 
1730 1810". London: Faber and Faber.
Usher, Abbott Payson (1920). "An Introduction to the Industrial History of 
England". University of Michigan Press.
Historiography
Chambliss, William J. (editor), Problems of Industrial Society, Reading, 
Massachusetts: Addison-Wesley Publishing Co, December 1973. ISBN 978
-0-201-00958-3
Hawke, Gary. "Reinterpretations of the Industrial Revolution" in Patrick 
O'Brien and Roland Quinault, eds. The Industrial Revolution and British 
Society (1993) pp 54 78
McCloskey, Deirdre (2004). "Review of The Cambridge Economic History of 
Britain (edited by Roderick Floud and Paul Johnson)". Times Higher 
Education Supplement. 15 (January). Retrieved 2016-02-12.
Notes
^ Jump up to: a b c d e f g h i j k l m n o p q r Landes 1969
^ Jump up to: a b Lucas, Robert E., Jr. (2002). Lectures on Economic 
Growth. Cambridge: Harvard University Press. pp. 109 10. ISBN 978-0-674-
01601-9.
^ Jump up to: a b Feinstein, Charles (September 1998). "Pessimism 
Perpetuated: Real Wages and the Standard of Living in Britain during and 
after the Industrial Revolution". Journal of Economic History 58 (3): 625 58. 
doi:10.1017/s0022050700021100. Retrieved 6 May 2014.
^ Jump up to: a b Szreter & Mooney; Mooney (February 1998). 
"Urbanization, Mortality, and the Standard of Living Debate: New Estimates 
of the Expectation of Life at Birth in Nineteenth-Century British Cities". The 
Economic History Review 51 (1): 104. doi:10.1111/1468-0289.00084. 
Retrieved 6 May 2014.
^ Jump up to: a b Eric Hobsbawm, The Age of Revolution: Europe 1789 
1848, Weidenfeld & Nicolson Ltd., p. 27 ISBN 0-349-10484-0
^ Jump up to: a b Joseph E Inikori. Africans and the Industrial Revolution in 
England, Cambridge University Press. ISBN 0-521-01079-9 Read it
Jump up ^ Berg, Maxine; Hudson, Pat (1992). "Rehabilitating the Industrial 
Revolution". The Economic History Review (The Economic History Review, 
Vol. 45, No. 1) 45 (1): 24 50. doi:10.2307/2598327. JSTOR 2598327.
Jump up ^ Rehabilitating the Industrial Revolution by Julie Lorenzen, 
Central Michigan University. Retrieved November 2006.
Jump up ^ Robert Lucas, Jr. (2003). "The Industrial Revolution". Federal 
Reserve Bank of Minneapolis. Archived from the original on 27 November 
2007. Retrieved 14 November 2007. it is fairly clear that up to 1800 or maybe 
1750, no society had experienced sustained growth in per capita income. 
(Eighteenth century population growth also averaged one-third of 1 percent, 
the same as production growth.) That is, up to about two centuries ago, per 
capita incomes in all societies were stagnated at around $400 to $800 per 
year.
Jump up ^ Lucas, Robert (2003). "The Industrial Revolution Past and 
Future". Archived from the original on 27 November 2007. [consider] annual 
growth rates of 2.4 percent for the first 60 years of the 20th century, of 1 
percent for the entire 19th century, of one-third of 1 percent for the 18th 
century
Jump up ^ McCloskey, Deidre (2004). "Review of The Cambridge Economic 
History of Modern Britain (edited by Roderick Floud and Paul Johnson), 
Times Higher Education Supplement, 15 January 2004".
Jump up ^ Taylor, George Rogers. The Transportation Revolution, 1815 
1860. ISBN 978-0-87332-101-3. No name is given to the transition years. The 
Transportation Revolution began with improved roads in the late 18th 
century.
^ Jump up to: a b c d e f Roe, Joseph Wickham (1916), English and 
American Tool Builders, New Haven, Connecticut: Yale University Press, 
LCCN 16011753. Reprinted by McGraw-Hill, New York and London, 1926 
(LCCN 27-24075); and by Lindsay Publications, Inc., Bradley, Illinois, (ISBN 
978-0-917914-73-7).
Jump up ^ Hunter 1985
Jump up ^ Crouzet, Fran ois (1996). "France". In Teich, Mikul  ; Porter, Roy. 
The industrial revolution in national context: Europe and the USA. 
Cambridge University Press. p. 45. ISBN 978-0-521-40940-7. LCCN 
95025377.
Jump up ^ BLANQUI J r me-Adolphe, Histoire de l' conomie politique en 
Europe depuis les anciens jusqu'  nos jours, 1837, ISBN 978-0-543-94762-8
Jump up ^ Hudson, Pat (1992). The Industrial Revolution. London: Edward 
Arnold. p. 11. ISBN 978-0-7131-6531-9.
Jump up ^ Eric Bond, Sheena Gingerich, Oliver Archer-Antonsen, Liam 
Purcell, Elizabeth Macklem (17 February 2003). "The Industrial Revolution   
Innovations". Industrialrevolution.sea.ca. Retrieved 30 January 2011.
Jump up ^ Ayres 1989, pp. 17
Jump up ^ Hunter year-1985
Jump up ^ Rosen, William (2012). The Most Powerful Idea in the World: A 
Story of Steam, Industry and Invention. University Of Chicago Press. p. 149. 
ISBN 978-0-226-72634-2.
^ Jump up to: a b c Ayres, Robert (1989). "Technological Transformations 
and Long Waves" (PDF): 16 17.
^ Jump up to: a b c d e f g h i j McNeil 1990
Jump up ^ R. Ray Gehani (1998). "Management of Technology and 
Operations". P. 63. John Wiley and Sons, 1998
Jump up ^ Ayres 1989, pp. 1
Jump up ^ Ayres 1989, pp. 18
Jump up ^ G. E. Mingay (1986). "The Transformation of Britain, 1830 1939". 
p. 25. Routledge, 1986
Jump up ^ Gordon, Robert B (1996). American Iron 1607 1900. Baltimore 
and London: Johns Hopkins University Press. p. 156. ISBN 0-8018-6816-5.
Jump up ^ Landes year-1969, pp. 218
Jump up ^ Ayres 1989, pp. 21
Jump up ^ Rosenberg, Nathan (1982). Inside the Black Box: Technology and 
Economics. Cambridge, New York: Cambridge University Press. p. 90. ISBN 
0-521-27367-6.
Jump up ^ Hunter&Bryant 1991
Jump up ^ Rolt and Allen, 145
^ Jump up to: a b c Hounshell, David A. (1984), From the American System 
to Mass Production, 1800-1932: The Development of Manufacturing 
Technology in the United States, Baltimore, Maryland: Johns Hopkins 
University Press, ISBN 978-0-8018-2975-8, LCCN 83016269
Jump up ^ Economics 323-2: Economic History of the United States Since 
1865 http://faculty.wcas.northwestern.edu/~jmokyr/Graphs-and-Tables.PDF
Jump up ^ Clow, Archibald; Clow, Nan L. (June 1952). "Chemical 
Revolution". Ayer Co: 65 90. ISBN 0-8369-1909-2.
Jump up ^ Lion Hirth, State, Cartels and Growth: The German Chemical 
Industry (2007) p 20
Jump up ^ Johann P. Murmann, Knowledge and competitive advantage: the 
coevolution of firms, technology, and national institutions (2003) pp 53 54
Jump up ^ Properties of Concrete Published lecture notes from University of 
Memphis Department of Civil Engineering. Retrieved 17 October 2007.
Jump up ^ Misa, Thomas J. (1995). A Nation of Steel: The Making of Modern 
America 1965 1925. Baltimore and London: Johns Hopkins University Press. 
p. 243. ISBN 978-0-8018-6502-2.
Jump up ^ Overton, Mark (1996). Agricultural Revolution in England: The 
transformation if the agrarian economy 1500 1850. Cambridge University 
Press. ISBN 978-0-521-56859-3.
Jump up ^ Temple 1986, pp. 26
Jump up ^ Overton 1996, pp. 122
Jump up ^ "The Rotherham Plow". Rotherham: The Unofficial Website.
Jump up ^ Temple 1986, pp. 18, 20
Jump up ^ "The Rotherham Plow". Rotherham.co.uk.
^ Jump up to: a b c Clark 2007
Jump up ^ Atack, Jeremy; Passell, Peter (1994). A New Economic View of 
American History. New York: W.W. Norton and Co. p. 282. ISBN 0-393-
96315-2.
Jump up ^ Rosen, William (2012). The Most Powerful Idea in the World: A 
Story of Steam, Industry and Invention. University Of Chicago Press. p. 127. 
ISBN 978-0-226-72634-2.
Jump up ^ Musson; Robinson (1969). Science and Technology in the 
Industrial Revolution. University of Toronto Press. p. 477.
Jump up ^ Encyclop dia Britannica (2008) "Building construction: the 
reintroduction of modern concrete"
Jump up ^ Gr bler, Arnulf (1990). The Rise and Fall of Infrastructures: 
Dynamics of Evolution and Technological Change in Transport (PDF). 
Heidelberg and New York: Physica-Verlag.
Jump up ^ Donald Langmead. Encyclopedia of Architectural and 
Engineering Feats. ABC-CLIO. p. 37. ISBN 978-1-57607-112-0. Retrieved 15 
February 2013.
Jump up ^ UK CPI inflation numbers based on data available from Gregory 
Clark (2016), "The Annual RPI and Average Earnings for Britain, 1209 to 
Present (New Series)" MeasuringWorth.
Jump up ^ Timbs 1860, p. 363
Jump up ^ The Times newspaper: Bridgewater Collieries, London, 1 
December 1913, retrieved 19 July 2008
Jump up ^ Kindleberger 1993, pp. 192 193
Jump up ^ "1 January 1894: Opening of the Manchester ship canal". The 
Guardian. 1 January 1894. Retrieved 28 July 2012. Six years in the making, 
the world's largest navigation canal gives the city direct access to the sea
Jump up ^ "1823   First American Macadam Road" (Painting   Carl 
Rakeman) US Department of Transportation   Federal Highway 
Administration (Accessed 10 October 2008)
Jump up ^ Richard Brown (1991). "Society and Economy in Modern Britain 
1700 1850" p. 136. Routledge, 1991
Jump up ^ Fling, Harry M. (1868). Railroads of the United States, Their 
History and Statistics. Philadelphia: John. E. Potter and Co. pp. 12, 13.
Jump up ^ Herbert L. Sussman (2009). "Victorian Technology: Invention, 
Innovation, and the Rise of the Machine". p. 2. ABC-CLIO, 2009
Jump up ^ Landes year-1969, pp. 57 9
Jump up ^ Landes year-1969, pp. 59
Jump up ^ Hunt, E. K.; Lautzenheiser, Mark (2014). History of Economic 
Thought: A Critical Perspective. PHI Learning. ISBN 978-0765625991.
^ Jump up to: a b Woodward, D. (1981) Wage rates and living standards in 
pre-industrial England Past & Present 1981 91(1):28 46
Jump up ^ Crafts, N; Mills, Terence C. (1994). "Trends in Real Wages in 
Britain, 1750 1913". Explorations in Economic History 31 (2): 176. 
doi:10.1006/exeh.1994.1007.
Jump up ^ Industrial Revolution and the Standard of Living From 
www.econlib.org, downloaded 17 July 2006.
Jump up ^ R.M. Hartwell, The Rising Standard of Living in England, 1800 
1850, Economic History Review, 1963, page 398 ISBN 0-631-18071-0
Jump up ^ Fogel, Robert W. (2004). The Escape from Hunger and 
Premature Death, 1700 2100. London: Cambridge University Press. ISBN 0
-521-80878-2.
Jump up ^ Malthus, Thomas (1798). An Essay on the Principle of Population 
(PDF). London. Retrieved 2016-02-12.
Jump up ^ Temple, Robert; Needham, Joseph (1986). The Genius of China: 
3000 years of science, discovery and invention. New York: Simon and 
Schuster<Based on the works of Joseph Needham>
Jump up ^ Engels, Friedrich (1892). The Condition of the Working-Class in 
England in 1844. London: Swan Sonnenschein & Co. pp. 45, 48 53.
Jump up ^ "The UK population: past, present and future   Chapter 1" (PDF). 
Statistics.gov.uk
Jump up ^ "A portrait of Britain in 2031". The Independent. 24 October 2007.
Jump up ^ BBC   History   Victorian Medicine   From Fluke to Theory. 
Published: 1 February 2002.
Jump up ^ "Modernization   Population Change". Encyclop dia Britannica.
Jump up ^ Hudson, Pat (1992). The Industrial Revolution. New York: 
Routledge, Chapman and Hall, Inc. p. 3. ISBN 0-7131-6531-6.
Jump up ^ "United States History   The Struggles of Labor". Library of 
Congress Country Studies.
Jump up ^ R.M. Hartwell, The Industrial Revolution and Economic Growth, 
Methuen and Co., 1971, page 339 341 ISBN 0-416-19500-8
Jump up ^ "Manchester   the first industrial city". Entry on Sciencemuseum 
website. Archived from the original on 9 March 2012. Retrieved 17 March 
2012.
Jump up ^ "Life in Industrial Towns".
Jump up ^ Dunn, James (1905). From Coal Mine Upwards: or Seventy Years 
of an Eventful Life. ISBN 1-4344-6870-4.
^ Jump up to: a b Mabel C. Buer, Health, Wealth and Population in the Early 
Days of the Industrial Revolution, London: George Routledge & Sons, 1926, 
page 30 ISBN 0-415-38218-1
Jump up ^ Bar, Michael; Leukhina, Oksana (2007). "Demographic Transition 
and Industrial Revolution: A Macroeconomic Investigation" (PDF). Archived 
from the original (PDF) on 27 November 2007. Retrieved 5 November 2007. 
The decrease [in mortality] beginning in the second half of the 18th century 
was due mainly to declining adult mortality. Sustained decline of the 
mortality rates for the age groups 5 10, 10 15, and 15 25 began in the mid-
19th century, while that for the age group 0 5 began three decades later
[dead link]. Although the survival rates for infants and children were static 
over this period, the birth rate & overall life expectancy increased. Thus the 
population grew, but the average Briton was about as old in 1850 as in 1750 
(see figures 5 & 6, page 28). Population size statistics from mortality.org put 
the mean age at about 26.
Jump up ^ "Child Labour and the Division of Labour in the Early English 
Cotton Mills". Douglas A. Galbi. Centre for History and Economics, King's 
College, Cambridge CB2 1ST.
Jump up ^ The Life of the Industrial Worker in Nineteenth-Century England, 
Laura Del Col, West Virginia University.
^ Jump up to: a b c d e f g h i j k Venning, Annabel (17 September 2010). 
"Britain's child slaves: They started at 4am, lived off acorns and had nails 
put through their ears for shoddy work. Yet, says a new book, their misery 
helped forge Britain". dailymail.co.uk (London). Retrieved 19 September 
2010.
Jump up ^ "Testimony Gathered by Ashley's Mines Commission". 2008. 
Retrieved 22 March 2008.
Jump up ^ "The Life of the Industrial Worker in Nineteenth-Century 
England". 2008. Retrieved 22 March 2008.
Jump up ^ "Photographs of Lewis Hine: Documentation of Child Labor". The 
U.S. National Archives and Records Administration.
Jump up ^ General Strike 1842 at the Wayback Machine (archived 9 June 
2007)[dead link] From chartists.net. Retrieved 13 November 2006.
Jump up ^ "Human Population: Urbanization". Population Reference 
Bureau. Archived 26 October 2009 at the Wayback Machine.
Jump up ^ "Human Population: Population Growth: Question and Answer". 
Population Reference Bureau. Archived 8 October 2009 at the Wayback 
Machine.
Jump up ^ Manchester (England, United Kingdom). Encyclop dia Britannica.
Jump up ^ Chris Evans, G ran Ryd n, The Industrial Revolution in Iron; The 
impact of British Coal Technology in Ninenteenth-Century Europe Published 
by Ashgate Publishing, Ltd., Farnham2005, pp. 37 38 ISBN 0-7546-3390-X.
Jump up ^ a word from Walloon origin
Jump up ^ Muriel Neven and Isabelle Devos, 'Breaking stereotypes', in M. 
Neven and I. Devos (editors), 'Recent work in Belgian Historical 
Demography', in Revue belge d'histoire contemporaine, XXXI, 2001, 3 4, 
pages 347 359 FLWI.ugent.be Archived 29 October 2008 at the Wayback 
Machine.
Jump up ^ Philippe Raxhon, Le si cle des forges ou la Wallonie dans le 
creuset belge (1794 1914), in B. Demoulin and JL Kupper (editors), Histoire 
de la Wallonie, Privat, Toulouse, 2004, pages 233 276, p. 246 ISBN 2-7089-
4779-6
Jump up ^ "European Route of Industrial Heritage". En.erih.net. Retrieved 
19 August 2013.
Jump up ^ Michel De Coster, Les enjeux des conflits linguistiques, 
L'Harmattan, Paris, 2007, ISBN 978-2-296-03394-8, pages 122 123
Jump up ^ Muriel Neven and Isabelle Devos, Breaking stereotypes, art. cit., 
pages 315 316
Jump up ^ Jean Marczewski,   Y a-t-il eu un "take-off" en France    , 1961, 
dans les Cahiers de l'ISEA
Jump up ^ Haber 1958
Jump up ^ Allan Mitchell, Great Train Race: Railways and the Franco-
German Rivalry, 1815 1914 (2000)
Jump up ^ Atack, Jeremy; Passell, Peter (1994). A New Economic View of 
American History. New York: W.W. Norton and Co. p. 469. ISBN 0-393-
96315-2.
Jump up ^ Chandler Jr., Alfred D. (1993). The Visible Hand: The 
Management Revolution in American Business. Belknap Press of Harvard 
University Press. ISBN 978-0674940529.
Jump up ^ Taylor, George Rogers (1969). The Transportation Revolution, 
1815 1860. ISBN 978-0873321013.
Jump up ^ Bagnall, William R. The Textile Industries of the United States: 
Including Sketches and Notices of Cotton, Woolen, Silk, and Linen 
Manufacturers in the Colonial Period. Vol. I. The Riverside Press, 1893.
Jump up ^ "Made In Beverly-A History of Beverly Industry", by Daniel J. 
Hoisington. A publication of the Beverly Historic District Commission. 1989.
Jump up ^ Encyclop dia Britannica (1998): Samuel Slater
Jump up ^ "History". Bank of Japan. Retrieved 5 May 2015.
Jump up ^ G.C. Allen, Short Economic History of Modern Japan (1972)
Jump up ^ Morison, Elting E. (1966). Men, Machines and Modern Times. 
Cambridga, Ma and London, UK: The M.I.T Press.
Jump up ^ Karl Marx: Communist as Religious Eschatologist PDF (3.68 MB)
Jump up ^ "BBC   Plague in Tudor and Stuart Britain". bbc.co.uk. Retrieved 
3 November 2008.
Jump up ^ Steven Kreis (11 October 2006). "The Origins of the Industrial 
Revolution in England". Historyguide.org. Retrieved 30 January 2011.
Jump up ^ "Scientific Revolution". Microsoft Encarta Online Encyclopedia 
2009. Archived 31 October 2009. Archived October 28, 2009, at the Wayback 
Machine.
Jump up ^ Hudson, Pat. The Industrial Revolution, Oxford University Press 
US. ISBN 0-7131-6531-6
Jump up ^ Fullerton, Ronald A. (January 1988). "How Modern Is Modern 
Marketing  Marketing's Evolution and the Myth of the "Production Era"". The 
Journal of Marketing (New York City, NY: American Marketing Association) 52 
(1): 108 125. doi:10.2307/1251689. JSTOR 1251689.
Jump up ^ "Technics & Civilization". Lewis Mumford. Retrieved 8 January 
2009.
Jump up ^ Deane, Phyllis. The First Industrial Revolution, Cambridge 
University Press. ISBN 0-521-29609-9 Read it
Jump up ^ Eric Schiff, Industrialisation without national patents: the 
Netherlands, 1869 1912; Switzerland, 1850 1907, Princeton University Press, 
1971.
Jump up ^ Michele Boldrin and David K. Levine, Against Intellectual 
Monopoly, Chapter 1, final online version January 2, 2008 PDF (55 KB), 
page 15. Cambridge University Press, 2008. ISBN 978-0-521-87928-6
Jump up ^ Mott-Smith, Morton (1964) [Unabridged and revised version of the 
book first published by D. Appleton-Century Company in 1934 under the 
former title: The Story of Energy]. The Concept of Energy Simply Explained. 
New York: Dover Publications, Inc. pp. 13 14. ISBN 0-486-21071-5.
Jump up ^ Why No Industrial Revolution in Ancient Greece  J. Bradford 
DeLong, Professor of Economics, University of California at Berkeley, 20 
September 2002. Retrieved January 2007.
Jump up ^ The Origins of the Industrial Revolution in England |The History 
Guide, Steven Kreis, 11 October 2006   Accessed January 2007
Jump up ^ Jackson J. Spielvogel (2009). "Western Civilization: Since 1500". 
p.607.
Jump up ^ Eric Bond, Sheena Gingerich, Oliver Archer-Antonsen, Liam 
Purcell, Elizabeth Macklem (17 February 2003). "The Industrial Revolution   
Causes". Industrialrevolution.sea.ca. Retrieved 30 January 2011.
Jump up ^ Cobb-Douglas in pre-modern Europe1   Simulating early modern 
growth PDF (254 KB) Jan Luiten van Zanden, International Institute of Social 
History/University of Utrecht. May 2005. Retrieved January 2007.
Jump up ^ Merson 1990, pp. 34 5
Jump up ^ How Earth Made Us: Fire by Professor Iain Stewart
Jump up ^ South Asian History -Pages from the history of the Indian 
subcontinent: British rule and the legacy of colonisation. Rajni-Palme Dutt 
India Today (Indian Edition published 1947). Retrieved January 2007. 
Archived 27 January 2007 at the Wayback Machine.
Jump up ^ Julian Hoppit, "The Nation, the State, and the First Industrial 
Revolution," Journal of British Studies (April 2011) 50#2 pp p 307 331
Jump up ^ Kiely, Ray (November 2011). "Industrialization and Development: 
A Comparative Analysis". UGL Press Limited: 25 26.
Jump up ^ Digital History, Steven Mintz. "Was slavery the engine of 
economic growth  Digital History". Digitalhistory.uh.edu. Archived from the 
original on 19 February 2014. Retrieved 30 January 2011.
Jump up ^ The Industrial Revolution by Pat Hudson, pg. 198. 
Books.google.com. 1992. ISBN 978-0-7131-6531-9. Retrieved 30 January 
2011.
Jump up ^ The Royal Navy itself may have contributed to Britain's industrial 
growth. Among the first complex industrial manufacturing processes to arise 
in Britain were those that produced material for British warships. For 
instance, the average warship of the period used roughly 1000 pulley 
fittings. With a fleet as large as the Royal Navy, and with these fittings 
needing to be replaced ever 4 to 5 years, this created a great demand which 
encouraged industrial expansion. The industrial manufacture of rope can 
also be see as a similar factor.
Jump up ^ Barrington Moore, Jr., Social Origins of Dictatorship and 
Democracy: Lord and Peasant in the Making of the Modern World, pp. 29 
30, Boston, Beacon Press, 1966.
Jump up ^ E A Wrigley, Continuity chance and change.
Jump up ^ The Lunar Society at the Wayback Machine (archived 7 February 
2008) at Moreabout, the website of the Birmingham Jewellery Quarter guide, 
Bob Miles.
Jump up ^ Foster, Charles (2004). Capital and Innovation: How Britain 
Became the First Industrial Nation. Northwich: Arley Hall Press. ISBN 0-
9518382-4-5. Argues that capital accumulation and wealth concentration in 
an entrepreneurial culture following the commercial revolution made the 
industrial revolution possible, for example.-2009. TASCHEN 
Books". Taschen.com. Retrieved 2015-09-27.
Jump up ^ "Yes is More. TASCHEN Books". Taschen.com. Retrieved 2015-
09-27.
Jump up ^ October, Pinar (2013-10-13). "Dubai's Futuristic Floating Building 
by Zaha Hadid". My Modern Met. Retrieved 2015-09-27.
Jump up ^ "15 Most Futuristic Architecture Projects of Zaha Hadid". 
Decoist.com. 2013-03-14. Retrieved 2015-09-27.
Jump up ^ "Zaha Hadid Uses Hologram To Reveal Futuristic Design Of 
Miami S One Thousand Museum Tower". archpaper.com. 2013-11-27. 
Archived from the original on February 2, 2014.
Jump up ^ "Futuristic student centre opens doors - SWI". Swissinfo.ch. 
2010-02-22. Retrieved 2015-09-27.
Jump up ^ "Thomas Heatherwick / Conran Foundation Collection : - 
Design/Designer Information". Designmuseum.org. Retrieved 25 September 
2015.
Jump up ^ "Thomas Heatherwick Designs a Futuristic Learning Hub for 
Nanyang University in Singapore Nanyang University Learning Hub Thomas 
Heatherwick   Inhabitat - Sustainable Design Innovation, Eco Architecture, 
Green Building". Inhabitat.com. 2013-07-21. Retrieved 2015-09-27.
Jump up ^ "Futuristic architecture, santiago calatrava, future architecture, 
modern building, white interior". Indulgy.com. Retrieved 25 September 2015.
Jump up ^ "Clashot: earn money taking photos with your phone". 
Clashot.com. Retrieved 25 September 2015.
Jump up ^ "Futurism and Santiago Calatrava". prezi.com. Retrieved 25 
September 2015.
Jump up ^ [3] Archived February 4, 2014, at the Wayback Machine.
Jump up ^ "Culture For Friends - Torre Diagonal Zerozero: A Futuristic 
Landmark In Barcelona". Cultureforfriends.eu. Retrieved 2015-09-27.
Jump up ^ Turner, Yvonne K (2012-03-12). "Yvonne K Turner Studio work 
and Degree show: Anish Kapoor The ultimate City Futurist". 
Yvonnekturner.blogspot.com. Retrieved 2015-09-27.
Jump up ^ "Three futuristic views inside Anish Kapoor at the Grand Palais". 
OLENSKA BLOG. Retrieved 25 September 2015.
Jump up ^ "Theo Jansen: Art In The Form of Science". BOZ UX. Retrieved 
2015-09-27.
Jump up ^ "The Charter of the New Urbanism". Cnu.org. Retrieved 25 
September 2015.
Jump up ^ "Beauty, Humanism, Continuity between Past and Future". 
Traditional Architecture Group. Retrieved 23 March 2014.
Jump up ^ Issue Brief: Smart-Growth: Building Livable Communities. 
American Institute of Architects. Retrieved on 2014-03-23.
Jump up ^ "Driehaus Prize". Together, the $200,000 Driehaus Prize and the 
$50,000 Reed Award represent the most significant recognition for classicism 
in the contemporary built environment.. Notre Dame School of Architecture. 
Retrieved 23 March 2014.
External links[edit]
  Wikimedia Commons has media related to Modern movement.
Six Building Designers Who Are Redefining Modern Architecture, an April 
2011 radio and Internet report by the Special English service of the Voice of 
America.
Famous architects   Biographies of well-known architects, almost all of the 
Modern Movement.
Architecture and Modernism
"Preservation of Modern Buildings" edition of AIA Architect
Brussels50s60s.be, Overview of the architecture of the 1950s and 1960s in 
Brussels
A Grand Design: The Toronto City Hall Design Competition Modernist 
designs from the 1958 international competition
market.[15]


1915 advertisement for "Vulcan" Ink Pencils.
Slavoljub Eduard Penkala, a naturalized Croatian engineer and inventor of 
Polish-Dutch origin from the Kingdom of Croatia-Slavonia in Austria-Hungary, 
became renowned for further development of the mechanical pencil (1906)   
then called an "automatic pencil"   and the first solid-ink fountain pen (1907). 
Collaborating with an entrepreneur by the name of Edmund Moster, he 
started the Penkala-Moster Company and built a pen-and-pencil factory that 
was one of the biggest in the world at the time. This company, now called 
TOZ-Penkala, still exists today. "TOZ" stands for "Tvornica olovaka Zagreb", 
meaning "Zagreb Pencil Factory".


Modern marker pens.
In the 1960s, the fiber or felt-tipped pen was invented by Yukio Horie of the 
Tokyo Stationery Company, Japan.[16] Papermate's Flair was among the first 
felt-tip pens to hit the U.S. market in the 1960s, and it has been the leader 
ever since. Marker pens and highlighters, both similar to felt pens have 
become popular in recent times.

Rollerball pens were introduced in the early 1970s. They make use of a 
mobile ball and liquid ink to produce a smoother line. Technological 
advances achieved during the late 1980s and early 1990s have improved the 
roller ball's overall performance. A porous point pen contains a point that is 
made of some porous material such as felt or ceramic. A high quality drafting 
pen will usually have a ceramic tip, since this wears well and does not 
broaden when pressure is applied while writing.

Although the invention of the typewriter and personal computer with the 
keyboard input method have changed how users write, the pen has not 
been entirely replaced.[17] Higher end pens including types such as 
fountain pens are still a status symbol.[18][19]

Manufacturers
Globe icon.
The examples and perspective in this section may not represent a worldwide 
view of the subject. Please improve this article and discuss the issue on the 
talk page. (November 2009)
United States

Waterman pen and fountain pens made for Air France s Concorde.
Statistics on writing instruments (including pencils and pens) from WIMA 
(the United States Writing Instrument Manufacturers Association) show that 
in 2005, retractable ball point pens were by far the most popular in the 
United States (26%), followed by standard ball point pens (14%). Other 
categories represented very small fractions (3% or less).[20] There is 
however also a thriving industry in luxury pens, often fountain pens, 
sometimes priced at $1000 or more.[21] Pens are also used as 
advertisements for business entrepreneurs. Companies use pens to 
advertise their company names to possible customers.


The rise of an understanding of the body and mind in terms of the nervous 
system led to the emergence of a new wave of music therapy in the 
eighteenth century. Earlier works on the subject, such as Athanasius Kircher 
s Musurgia universalis of 1650 and even early eighteenth-century books 
such as Michael Ernst Ettm ller s 1714 Disputatio effectus musicae in 
hominem (Disputation on the Effect of Music on Man) or Friedrich Erhardt 
Niedten s 1717 Veritophili, still tended to discuss the medical effects of 
music in terms of bringing the soul and body into harmony. But from the 
mid-eighteenth century works on the subject such as Richard Brocklesby s 
1749 Reflections of Antient and Modern Musick, the 1737 Memoires of the 
French Academy of Sciences, or Ernst Anton Nicolai s 1745 Die Verbindung 
der Musik mit der Arzneygelahrheit (The Connection of Music to Medicine), 
stressed the power of music over the nerves.[115]

After 1800 books on music therapy often drew on the Brunonian system of 
medicine, arguing that the stimulation of the nerves caused by music could 
directly improve health. For example, Peter Lichtenthal s influential 1807 
book Der musikalische Arzt (The Musical Doctor) was also explicitly 
Brunonian in its treatment of the effects of music on the body. Lichtenthal, a 
musician, composer and physician with links to the Mozart family, was 
mostly positive about music, talking of doses of music , which should be 
determined by someone who knows the "Brunonian scale."[116]

Music therapy as we know it began in the aftermath of World Wars I and II, 
when, particularly in the United Kingdom, musicians would travel to 
hospitals and play music for soldiers suffering from war-related emotional 
and physical trauma.[117]

Music therapy in the military[edit]
History[edit]
Music therapy finds its roots in the military. The United States Department of 
War issued Technical Bulletin 187 in 1945, which described the use of music 
in the recuperation of military service members in Army hospitals.[118] The 
use of music therapy in military settings started to flourish and develop 
following World War II and research and endorsements from both the United 
States Army and the Surgeon General of the United States. Although these 
endorsements helped music therapy develop, there was still a recognized 
need to assess the true viability and value of music as a medically-based 
therapy. Walter Reed Army Medical Center and the Office of the Surgeon 
General worked together to lead one of the earliest assessments of a music 
therapy program. The goal of the study was to understand whether  music 
presented according to a specific plan  influenced recovery among service 
members with mental and emotional disorders.[119] Eventually, case reports 
in reference to this study relayed not only the importance but also the impact 
of music therapy services in the recovery of military service personnel.

The first university sponsored music therapy course was taught by Margaret 
Anderton in 1919 at Columbia University.[120] Anderton's clinical specialty 
was working with wounded Canadian soldiers during World War II, using 
music-based services to aid in their recovery process.

Today, Operation Enduring Freedom and Operation Iraqi Freedom have both 
presented an array of injuries; however, the two signature injuries are Post-
Traumatic Stress Disorder (PTSD) and Traumatic Brain Injury (TBI). These 
two signature injuries are increasingly common among millennial military 
service members and in music therapy programs.

Methods[edit]
Music therapists work with active duty military personnel, veterans, service 
members in transition, and their families. Music therapists strive to engage 
clients in music experiences that foster trust and complete participation over 
the course of their treatment process. Music therapists use an array of 
music-centered tools, techniques, and activities when working with military-
associated clients, many of which are similar to the techniques used in other 
music therapy settings. These methods include, but are not limited to: group 
drumming, listening, singing, and songwriting. Songwriting is a particularly 
effective tool with military veterans struggling with PTSD and TBI as it 
creates a safe space to, "...work through traumatic experiences, and 
transform traumatic memories into healthier associations."[121]

Programs[edit]
Music therapy in the military is seen in programs on military bases, VA 
healthcare facilities, military treatment facilities, and military communities. 
Music therapy programs have a large outreach because they exist for all 
phases of military life: pre-mobilization, deployment, post-deployment, 
recovery (in the case of injury), and among families of fallen military service 
personnel.[122]

Resounding Joy, Inc., a San Diego, California-based music therapy program, 
is a pioneer for the use of music therapy in the military. Its Semper Sound 
program specializes in providing music therapy services to active duty 
military service members and veterans diagnosed with PTSD, TBI, 
substance abuse, and other trauma-related diagnoses. It features different 
programs such as The Semper Sound Band, based in San Diego, California, 
and the GI Jams Band, based in Chelsea, Massachusetts.[123]

Walter Reed Army Medical Center located in Bethesda, Maryland, is another 
pioneer for the use of music therapy in the military. All patients at the 
medical center are eligible to receive music therapy services; therefore, the 
range of clients is wide: TBI, stroke, psychological diagnoses (anxiety, 
depression, PTSD), autism spectrum disorder, and more.[122]

The Exceptional Family Member Program (EFMP) also exists to provide 
music therapy services to active duty military families who have a family 
member with a developmental, physical, emotional, or intellectual disorder. 
Currently, programs at the Davis-Monthan Air Force Base, Resounding Joy, 
Inc., and the Music Institute of Chicago partner with EFMP services to 
provide music therapy services to eligible military family members.[122]
